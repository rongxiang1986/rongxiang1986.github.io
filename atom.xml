<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>RongXiang</title>
  
  <subtitle>我的烂笔头</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zjrongxiang.github.io/"/>
  <updated>2020-10-19T14:38:16.543Z</updated>
  <id>https://zjrongxiang.github.io/</id>
  
  <author>
    <name>rong xiang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark和Elasticsearch交互实践总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/13/2020-10-13-Spark%E5%92%8CElasticsearch%E4%BA%A4%E4%BA%92%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/13/2020-10-13-Spark和Elasticsearch交互实践总结/</id>
    <published>2020-10-13T13:30:00.000Z</published>
    <updated>2020-10-19T14:38:16.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  环境依赖</li><li>第二部分 交互接口</li><li>第三部分 任务提交</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>为了更好的支持Spark应用和<code>Elasticsearch</code>交互，<code>Elasticsearch</code>官方退出了<code>elasticsearch-hadoop</code>项目。本文将详细介绍Spark Java应用和<code>Elasticsearch</code>的交互细节。</p><h2 id="第一部分-环境依赖"><a href="#第一部分-环境依赖" class="headerlink" title="第一部分 环境依赖"></a>第一部分 环境依赖</h2><h3 id="1-1-配置Maven依赖"><a href="#1-1-配置Maven依赖" class="headerlink" title="1.1 配置Maven依赖"></a>1.1 配置Maven依赖</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.elasticsearch<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>elasticsearch-spark-13_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>6.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>需要注意Spark版本和<code>elasticsearch-hadoop</code>版本的兼容性，参考版本对照表：</p><table><thead><tr><th><code>Spark Version</code></th><th><code>Scala Version</code></th><th><code>ES-Hadoop Artifact ID</code></th></tr></thead><tbody><tr><td>1.0 - 1.2</td><td>2.10</td><td><unsupported></unsupported></td></tr><tr><td>1.0 - 1.2</td><td>2.11</td><td><unsupported></unsupported></td></tr><tr><td>1.3 - 1.6</td><td>2.10</td><td><code>elasticsearch-spark-13_2.10</code></td></tr><tr><td>1.3 - 1.6</td><td>2.11</td><td><code>elasticsearch-spark-13_2.11</code></td></tr><tr><td>2.0+</td><td>2.10</td><td><code>elasticsearch-spark-20_2.10</code></td></tr><tr><td>2.0+</td><td>2.11</td><td><code>elasticsearch-spark-20_2.11</code></td></tr></tbody></table><h3 id="1-2-Spark配置"><a href="#1-2-Spark配置" class="headerlink" title="1.2 Spark配置"></a>1.2 Spark配置</h3><p>关于<code>elasticsearch</code>集群的交互配置，定义在<code>SparkConf</code>中，例如下面的案例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"></span><br><span class="line">SparkConf sparkConf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"JavaSpark"</span>).setMaster(<span class="string">"local"</span>);</span><br><span class="line"><span class="comment">//config elasticsearch</span></span><br><span class="line">sparkConf.set(<span class="string">"es.nodes"</span>,<span class="string">"192.168.31.3:9200"</span>);</span><br><span class="line">sparkConf.set(<span class="string">"es.port"</span>,<span class="string">"9200"</span>);</span><br><span class="line">sparkConf.set(<span class="string">"es.index.auto.create"</span>,<span class="string">"true"</span>);</span><br><span class="line"></span><br><span class="line">JavaSparkContext jsc = <span class="keyword">new</span> JavaSparkContext(sparkConf);</span><br></pre></td></tr></table></figure><ul><li><code>es.nodes</code>，集群节点；</li><li><code>es.port</code>，服务端口；</li><li><code>es.index.auto.create</code>，参数指定<code>index</code>是否自动创建；</li></ul><p>其他配置参考官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/configuration.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/hadoop/master/configuration.html</a></p><h2 id="第二部分-交互接口"><a href="#第二部分-交互接口" class="headerlink" title="第二部分 交互接口"></a>第二部分 交互接口</h2><h3 id="2-1-自定义id的写入"><a href="#2-1-自定义id的写入" class="headerlink" title="2.1 自定义id的写入"></a>2.1 自定义id的写入</h3><p>在业务数据写入<code>elasticsearch</code>集群的时候，需要数据去重。这时候就需要自己指定元数据字段中的<code>_id</code>。<code>elasticsearch</code>在处理<code>_id</code>相同的数据时，会覆盖写入。例如下面的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.spark.rdd.Metadata;</span><br><span class="line"><span class="keyword">import</span> org.elasticsearch.spark.rdd.api.java.JavaEsSpark;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.elasticsearch.spark.rdd.Metadata.ID;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">      ArrayList&lt;Tuple2&lt;HashMap,HashMap&gt;&gt; metaList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    </span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">100</span>;i++) &#123;</span><br><span class="line">         HashMap&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">         map.put(<span class="string">"id"</span>, String.valueOf(i));</span><br><span class="line">         map.put(<span class="string">"name"</span>, <span class="string">"one"</span>);</span><br><span class="line"></span><br><span class="line">         HashMap&lt;Metadata, String&gt; metamap = <span class="keyword">new</span> HashMap&lt;Metadata, String&gt;();</span><br><span class="line">         metamap.put(ID, String.valueOf(i));</span><br><span class="line"></span><br><span class="line">         metaList.add(<span class="keyword">new</span> Tuple2(metamap, map));</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">      JavaPairRDD&lt;?, ?&gt; pairRdd = jsc.parallelizePairs(metaList);</span><br><span class="line">      JavaEsSpark.saveToEsWithMeta(pairRdd,<span class="string">"spark/doc"</span>);</span><br><span class="line"></span><br><span class="line">     &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">        System.out.println(<span class="string">"finish!"</span>);</span><br><span class="line">        jsc.stop();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>例子中我们使用<code>ArrayList&lt;Tuple2&lt;HashMap,HashMap&gt;&gt;</code>数据结构来存储待写入的数据，然后构造<code>RDD</code>，最后使用<code>JavaEsSpark.saveToEsWithMeta</code>方法写入。需要注意这里构造的两个<code>HashMap</code>:</p><ul><li>数据<code>HashMap</code>，数据结构为：<code>HashMap&lt;String, String&gt;</code>，用于存储数据键值对。</li><li>元数据<code>HashMap</code>，数据结构为：<code>HashMap&lt;Metadata, String&gt;</code>，用于存储元数据键值对。例如<code>ID</code>即为<code>_id</code>。</li></ul><p>其他类型读写可以参考官方网站：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html</a></p><h2 id="第三部分-任务提交"><a href="#第三部分-任务提交" class="headerlink" title="第三部分 任务提交"></a>第三部分 任务提交</h2><p>最后编译运行。主要是<code>setMaster()</code>指定运行方式，分为如下几种。</p><table><thead><tr><th>运行模式</th><th>说明</th></tr></thead><tbody><tr><td><code>local</code></td><td>Run Spark locally with one worker thread (i.e. no parallelism at all).</td></tr><tr><td><code>local[K]</code></td><td>Run Spark locally with K worker threads (ideally, set this to the number of cores on your machine).</td></tr><tr><td><code>local[*]</code></td><td>Run Spark locally with as many worker threads as logical cores on your machine.</td></tr><tr><td><code>spark://HOST:PORT</code></td><td>Connect to the given <a href="http://spark.apache.org/docs/1.6.3/spark-standalone.html" target="_blank" rel="noopener">Spark standalone cluster</a> master. The port must be whichever one your master is configured to use, which is 7077 by default.</td></tr><tr><td><code>mesos://HOST:PORT</code></td><td>Connect to the given <a href="http://spark.apache.org/docs/1.6.3/running-on-mesos.html" target="_blank" rel="noopener">Mesos</a> cluster. The port must be whichever one your is configured to use, which is 5050 by default. Or, for a Mesos cluster using ZooKeeper, use <code>mesos://zk://...</code>. To submit with <code>--deploy-mode cluster</code>, the HOST:PORT should be configured to connect to the <a href="http://spark.apache.org/docs/1.6.3/running-on-mesos.html#cluster-mode" target="_blank" rel="noopener">MesosClusterDispatcher</a>.</td></tr><tr><td><code>yarn</code></td><td>Connect to a <a href="http://spark.apache.org/docs/1.6.3/running-on-yarn.html" target="_blank" rel="noopener">YARN </a>cluster in <code>client</code> or <code>cluster</code> mode depending on the value of <code>--deploy-mode</code>. The cluster location will be found based on the <code>HADOOP_CONF_DIR</code> or <code>YARN_CONF_DIR</code> variable.</td></tr><tr><td><code>yarn-client</code></td><td>Equivalent to <code>yarn</code> with <code>--deploy-mode client</code>, which is preferred to <code>yarn-client</code></td></tr><tr><td><code>yarn-cluster</code></td><td>Equivalent to <code>yarn</code> with <code>--deploy-mode cluster</code>, which is preferred to <code>yarn-cluster</code></td></tr></tbody></table><p>除了在eclipse、Intellij中运行local模式的任务，也可以打成jar包，使用spark-submit来进行任务提交。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、 Apache Spark support，链接：<a href="https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html</a></p><p>2、elasticsearch-hadoop项目，链接：<a href="https://github.com/elastic/elasticsearch-hadoop" target="_blank" rel="noopener">https://github.com/elastic/elasticsearch-hadoop</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  环境依赖&lt;/li&gt;
&lt;li&gt;第二部分 交互接口&lt;/li&gt;
&lt;li&gt;第三部分 任务提交&lt;/li
      
    
    </summary>
    
      <category term="Spark" scheme="https://zjrongxiang.github.io/categories/Spark/"/>
    
    
  </entry>
  
  <entry>
    <title>Python中的递归和限制</title>
    <link href="https://zjrongxiang.github.io/2020/10/10/2020-10-10-Python%E4%B8%AD%E7%9A%84%E9%80%92%E5%BD%92%E5%92%8C%E9%99%90%E5%88%B6/"/>
    <id>https://zjrongxiang.github.io/2020/10/10/2020-10-10-Python中的递归和限制/</id>
    <published>2020-10-10T05:30:00.000Z</published>
    <updated>2020-10-10T14:02:36.398Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  </li><li>第二部分 </li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、YARN Application Security，链接：<a href="https://hadoop.apache.org/docs/r2.7.4/hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r2.7.4/hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  &lt;/li&gt;
&lt;li&gt;第二部分 &lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h
      
    
    </summary>
    
      <category term="Yarn" scheme="https://zjrongxiang.github.io/categories/Yarn/"/>
    
    
  </entry>
  
  <entry>
    <title>MapReduce on Yarn机制总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/06/2020-10-06-MapReduce%20on%20Yarn%E6%9C%BA%E5%88%B6%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/06/2020-10-06-MapReduce on Yarn机制总结/</id>
    <published>2020-10-06T05:30:00.000Z</published>
    <updated>2020-10-07T04:43:37.073Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  常用快捷键</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Yarn作为资源统一管理平台是从第一代<code>MapReduce</code>（<code>MRv1</code>）演进而来。在最初的<code>MRv1</code>架构中，主要构成有三部分：</p><ul><li>编程模型，<code>MapReduce API</code>；</li><li>资源管理和作业控制模块，<code>JobTracker</code>（作业跟踪器）、<code>TaskTracker</code>（任务跟踪器）；</li><li>数据处理引擎，<code>MapTask</code>、<code>ReduceTask</code>；</li></ul><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/images/image001.jpg" alt=""></p><p>其中<code>JobTracker</code>单一服务运行在主节点，负责调度集群所有的任务，并监控任务的状态。每个工作节点均运行一个<code>TaskTracker</code>负责执行<code>JobTracker</code>分发的任务。架构上不足有：</p><ul><li><code>JobTracker</code>服务单点故障</li><li><code>JobTracker</code>服务太重，承担了集群的资源管理和任务调度。</li></ul><p>架构上<code>JobTracker</code>承担了集中式调度器角色，将集群中资源分配、任务分配和监控一个人扛，在高并发场景下容易出现负载过重，而产生单点风险。</p><p><code>Yahoo</code>和<code>Hortonworks</code>于2012年在<code>Hadoop 2.0</code>版中引入了<code>YARN</code>，架构上将<code>JobTracker</code>功能进行了拆分。将调度工作拆解为两层：中央调度器和框架调度器。中央调度器管理集群中所有资源的状态，它拥有集群所有的资源信息，它按照一定的策略（如FIFO、Fair、Capacity、Delay、Dominant Resource Fair）将资源粗粒度地分配给框架调度器，各个框架收到资源后再根据作业特性细粒度地将资源分配给容器执行具体的计算任务。双层调度架构大大减轻了中央调度器的负载，这对并发来说有很大提升，资源利用率也得到了提升。</p><p>新的架构就是Yahoo发布的Yarn架构（<strong>Y</strong>et <strong>A</strong>nother <strong>R</strong>esource <strong>N</strong>egotiator）。原来<code>JobTarcker</code>被拆解为：</p><ul><li><p><code>ResourceManger</code>，集群管理器。负责资源管理和调度，承担中央调度器角色。<code>ResourceManager</code>有两个组件构成：</p><p><code>ApplicationManager</code>,主要负责：1.管理监控各个系统的应用，包括启动<code>ApplicaitonMaster</code>，监控<code>ApplicaitonMaster</code>运行状态; 2.跟踪分配给<code>ApplicationMaster</code>的进度和状态。</p><p><code>Scheduler</code>，主要负责分配<code>Container</code>给<code>ApplicaitonMaster</code>，分配算法有多种（公平调度等等）可以根据需求不同选择适合的调度策略。</p></li><li><p><code>ApplicationMaster</code>，负责应用任务内部的调度和监控，承担框架调度器角色。</p><p>用户提交的每个应用都会对应一个<code>ApplicationMaster</code>，主要负责监控应用，任务容错（重启失败的task）等。它同时会和<code>ResourceManager</code>和<code>NodeManager</code>有交互，向<code>ResourceManager</code>申请资源，请求<code>NodeManager</code>启动或停止task。</p></li></ul><p><img src="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/images/image002.jpg" alt=""></p><p><code>Yarn</code>（<code>MRv2</code>）架构上已经不单单支持运行<code>MapReduce</code>任务，架构解耦后可以支持<code>Spark</code>、<code>Flink</code>等多种计算框架的运行。</p><p>本文将详细阐述<code>MapReduce</code>任务在新架构<code>Yarn</code>上运行细节。</p><h2 id="第一部分-角色说明"><a href="#第一部分-角色说明" class="headerlink" title="第一部分 角色说明"></a>第一部分 角色说明</h2><p><code>MapReduce on Yarn</code>运行模式下，主要涉及下面的角色：</p><ul><li><code>ResourceMange</code>，中央调度器角色；</li><li><code>NodeManagers</code>，节点管理器，负责管理<code>Container</code>;</li><li><code>MapReduce ApplicationManager</code>，框架调度器角色。负责协调运行<code>MapReduce</code>任务。</li></ul><p>整个调度过程如下：</p><p><img src="http://sungsoo.github.com/images/mr-yarn.png" alt=""></p><h2 id="第二部分-任务提交"><a href="#第二部分-任务提交" class="headerlink" title="第二部分 任务提交"></a>第二部分 任务提交</h2><h2 id="第三部分-任务初始化"><a href="#第三部分-任务初始化" class="headerlink" title="第三部分 任务初始化"></a>第三部分 任务初始化</h2><h2 id="第四部分-任务分配"><a href="#第四部分-任务分配" class="headerlink" title="第四部分 任务分配"></a>第四部分 任务分配</h2><h2 id="第五部分-任务执行"><a href="#第五部分-任务执行" class="headerlink" title="第五部分 任务执行"></a>第五部分 任务执行</h2><h2 id="第六部分-任务监控"><a href="#第六部分-任务监控" class="headerlink" title="第六部分 任务监控"></a>第六部分 任务监控</h2><h2 id="第七部分-任务完成"><a href="#第七部分-任务完成" class="headerlink" title="第七部分 任务完成"></a>第七部分 任务完成</h2><h2 id="第八部分-总结"><a href="#第八部分-总结" class="headerlink" title="第八部分 总结"></a>第八部分 总结</h2><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Hadoop 新 MapReduce 框架 Yarn 详解，链接：<a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/</a></p><p>2、Hadoop: Writing YARN Applications，链接：<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/WritingYarnApplications.html</a></p><p>3、MapReduce Tutorial，链接：<a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  常用快捷键&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;
      
    
    </summary>
    
      <category term="spark" scheme="https://zjrongxiang.github.io/categories/spark/"/>
    
    
  </entry>
  
  <entry>
    <title>大数据资源调度平台粒度的说明</title>
    <link href="https://zjrongxiang.github.io/2020/10/06/2020-10-06-%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%B9%B3%E5%8F%B0%E7%B2%92%E5%BA%A6%E7%9A%84%E8%AF%B4%E6%98%8E/"/>
    <id>https://zjrongxiang.github.io/2020/10/06/2020-10-06-大数据资源调度平台粒度的说明/</id>
    <published>2020-10-06T05:30:00.000Z</published>
    <updated>2020-10-22T11:27:55.458Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  各种资源调度器粒度</li><li>第二部分 动态分配（Dynamic Allocation）</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们在<code>Yarn</code>资源管理器上提交<code>MapReduce</code>任务的时候发现（<code>Yarn Web</code>控制台），启使用的<code>container</code>数量是变化的。</p><p>其实这是由于<code>MapReduce</code>任务在<code>Yarn</code>上资源分配的粒度是：细粒度的。接下来我们将介绍资源调度管理器的粒度。</p><h2 id="第一部分-各种资源调度器粒度"><a href="#第一部分-各种资源调度器粒度" class="headerlink" title="第一部分 各种资源调度器粒度"></a>第一部分 各种资源调度器粒度</h2><p>Spark最初始没有Yarn和Srandalone模式的，只有Mesos。后来才有了Yarn，最后为了推广产生了Standalone。</p><h3 id="1-1-Mesos集群"><a href="#1-1-Mesos集群" class="headerlink" title="1.1 Mesos集群"></a>1.1 <code>Mesos</code>集群</h3><p><code>Spark on Mesos</code>模式下，同时支持粗粒度（coarse-grained）和细粒度（fine-grained），等到高版本<code>Spark 2.X</code>版本后不再支持细粒度。低版本默认配置是细粒度。</p><blockquote><p>Fine-grained mode is deprecated as of Spark 2.0.0。Consider using <a href="https://spark.apache.org/docs/latest/running-on-mesos.html#dynamic-resource-allocation-with-mesos" target="_blank" rel="noopener">Dynamic Allocation</a> for some of the benefits. For a full explanation see <a href="https://issues.apache.org/jira/browse/SPARK-11857" target="_blank" rel="noopener">SPARK-11857</a></p></blockquote><ul><li>设置为粗粒度</li></ul><p>Spark配置项<code>spark.mesos.coarse</code>设置为<code>true</code>（可以在<code>spark-default.conf</code>配置文件中或者代码配置中）。在粗粒度模式下，可以通过下面3个参数指定静态资源：</p><p>设置<code>spark.cores.max</code>，最大使用CPU资源；</p><p>设置<code>spark.executor.memory</code>，每个executor的内存资源；</p><p>设置<code>spark.executor.cores</code>，每个executor的CPU资源；</p><ul><li>设置为细粒度</li></ul><p>注释<code>spark-default.conf</code>文件中的配置参数：<code>spark.mesos.coarse</code>，或者将其设置为<code>false</code>。</p><p>在细粒度模式下，Spark执行器中的每个Spark任务都作为单独的Mesos任务运行。这允许Spark的多个实例（和其他框架）以非常精细的粒度共享内核，其中每个应用程序在逐步增加和减少时将获得或多或少的内核，但是在启动每个任务时会带来额外的开销。此模式可能不适用于低延迟要求。</p><p>在<code>Spark 2.x</code>版本后，取消了对<code>Mesos</code>细粒度的支持，而是引入： <a href="https://spark.apache.org/docs/latest/running-on-mesos.html#dynamic-resource-allocation-with-mesos" target="_blank" rel="noopener">Dynamic Allocation</a></p><h3 id="1-2-Yarn集群"><a href="#1-2-Yarn集群" class="headerlink" title="1.2 Yarn集群"></a>1.2 Yarn集群</h3><h4 id="1-2-1-细粒度"><a href="#1-2-1-细粒度" class="headerlink" title="1.2.1 细粒度"></a>1.2.1 细粒度</h4><p><code>MapReduce</code>任务在Yarn上是细粒度模式。资源按需动态分配，每一个task均可以去申请资源，使用完后立即释放回收。提高集群计算资源的高效利用。</p><p>但是如果task任务轻而多，那么就会出现task实际使用计算资源时间短，但是申请数量多，这就导致大量运行时间其实是花费在资源申请分配和释放上。</p><h4 id="1-2-2-粗粒度"><a href="#1-2-2-粗粒度" class="headerlink" title="1.2.2 粗粒度"></a>1.2.2 粗粒度</h4><p>Spark on Yarn是粗粒度模式。资源静态分配。Spark Application在运行前就已经分配好需要的计算资源，没有task申请资源的时间延迟。但是资源释放上需要等待所有的task均执行完毕，才会触发所有资源的释放回收。特列极端的例子就是，一个job有100个task，完成了99个，还有一个没完成，那么所有资源就会闲置在那里等待那个task完成后才释放 。</p><h3 id="1-3-Standalone集群"><a href="#1-3-Standalone集群" class="headerlink" title="1.3 Standalone集群"></a>1.3 Standalone集群</h3><p>Spark自身的Standalone集群也是粗粒度，和Spark on Yarn的粗粒度类似。</p><h2 id="第二部分-动态-分配（Dynamic-Allocation）"><a href="#第二部分-动态-分配（Dynamic-Allocation）" class="headerlink" title="第二部分 动态 分配（Dynamic Allocation）"></a>第二部分 动态 分配（Dynamic Allocation）</h2><p>Spark在2.x开始抛弃在Mesos集群上对细粒度模式的支持，而是转而在粗粒度模式下提供动态分配机制（Dynamic Allocation）。</p><p>其实Spark在1.2版本后，在Spark on Yarn上就已经提供对动态分配机制（Dynamic Allocation）的支持。所以动态分配机制是未来架构的反向，可以补充粗粒度在资源有效利用方面的不足。</p><p>我们将在其他文章中介绍这种资源调度模式。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、<code>Running Spark on Mesos</code>，链接：<a href="https://spark.apache.org/docs/latest/running-on-mesos.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-mesos.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  各种资源调度器粒度&lt;/li&gt;
&lt;li&gt;第二部分 动态分配（Dynamic Allocatio
      
    
    </summary>
    
      <category term="spark" scheme="https://zjrongxiang.github.io/categories/spark/"/>
    
    
  </entry>
  
  <entry>
    <title>Pyspark实现原理总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/06/2020-10-06-Pyspark%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/06/2020-10-06-Pyspark实现原理总结/</id>
    <published>2020-10-06T05:30:00.000Z</published>
    <updated>2020-10-06T04:09:47.973Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  常用快捷键</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="http://sharkdtu.com/posts/pyspark-internal.html" target="_blank" rel="noopener">http://sharkdtu.com/posts/pyspark-internal.html</a></p><p>但是在大数据场景下，JVM和Python进程间频繁的数据通信导致其性能损耗较多，恶劣时还可能会直接卡死，所以建议对于大规模机器学习或者Streaming应用场景还是慎用PySpark，尽量使用原生的Scala/Java编写应用程序，对于中小规模数据量下的简单离线任务，可以使用PySpark快速部署提交。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Job Scheduling，链接：<a href="https://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  常用快捷键&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;
      
    
    </summary>
    
      <category term="spark" scheme="https://zjrongxiang.github.io/categories/spark/"/>
    
    
  </entry>
  
  <entry>
    <title>监控Yarn资源调度平台资源状态</title>
    <link href="https://zjrongxiang.github.io/2020/10/06/2020-10-06-%E7%9B%91%E6%8E%A7Yarn%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%B9%B3%E5%8F%B0%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81/"/>
    <id>https://zjrongxiang.github.io/2020/10/06/2020-10-06-监控Yarn资源调度平台资源状态/</id>
    <published>2020-10-06T05:30:00.000Z</published>
    <updated>2020-10-25T06:42:13.070Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  Yarn状态数据接口</li><li>第二部分  Java实现</li><li>第三部分 总结</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>目前国内大部分企业级的大数据平台资源调度系统都是基于Yarn集群。生产环境上，各种大数据计算框架运行在Yarn上，就需要对Yarn平台的资源情况进行实时监控。虽然Yarn本身提供一个Web管理界面展示平台资源使用情况，但是这些运行状态数据需要实时获取和监控。随着智能化运维推进，需要对监控数据能实时分析、异常检测、自动故障处理。这些场景都需要能实时获取到Yarn平台的状态监控数据。</p><p>本文将详细介绍各种监控实现的方法，并重点介绍Java实现。</p><h2 id="第一部分-Yarn状态数据接口"><a href="#第一部分-Yarn状态数据接口" class="headerlink" title="第一部分 Yarn状态数据接口"></a>第一部分 Yarn状态数据接口</h2><h3 id="1-1-命令行方式"><a href="#1-1-命令行方式" class="headerlink" title="1.1 命令行方式"></a>1.1 命令行方式</h3><p><code>yarn</code>命令在<code>{hadoop_home}/bin</code>路径下，对于部署<code>hadoop</code>客户端的客户端需要加载命令环境变量。</p><ul><li>参看任务信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看所有任务信息</span></span><br><span class="line">yarn application -list</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看正在运行的任务信息（带过滤参数appStates）</span></span><br><span class="line">yarn application -list -appStates RUNNING</span><br></pre></td></tr></table></figure><p>这里参数<code>appStates</code>的状态有：<code>ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUNNING,FINISHED,FAILED,KILLED</code></p><p>另外还可以指定计算框架的类型，例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 参看所有MapReduce任务</span></span><br><span class="line">yarn application -list -appTypes MAPREDUCE</span><br></pre></td></tr></table></figure><ul><li>参看指定任务状态信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn application -status application_1575989345612_32134</span><br></pre></td></tr></table></figure><h3 id="1-2-Restful-Api接口"><a href="#1-2-Restful-Api接口" class="headerlink" title="1.2 Restful Api接口"></a>1.2 <code>Restful Api</code>接口</h3><p><code>ResourceManager</code>允许用户通过<code>REST API</code>获取有关群集的信息：群集上的状态、群集上的指标、调度程序信息，另外还有群集中节点的信息以及集群上应用程序的运行信息。</p><ul><li>查询整个集群指标</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET http://http address:port/ws/v1/cluster/metrics</span><br></pre></td></tr></table></figure><ul><li>查询集群调度器详情</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET http://http address:port/ws/v1/cluster/scheduler</span><br></pre></td></tr></table></figure><ul><li>监控任务</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl http://http address:port/ws/v1/cluster/apps/state</span><br><span class="line">GET http://http address:port/ws/v1/cluster/apps/state</span><br></pre></td></tr></table></figure><ul><li>查看指定任务</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET http://http address:port/ws/v1/cluster/apps/</span><br></pre></td></tr></table></figure><ul><li>查看指定任务的详细信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://http address:port/proxy/ws/v2/mapreduce/info</span><br></pre></td></tr></table></figure><ul><li>杀死任务</li></ul><p><em>yarn application -kill application_id</em></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -v -X PUT -d '&#123;"state": "KILLED"&#125;' http://http address:port&gt;/ws/v1/cluster/apps/</span><br><span class="line">PUT http://http address:port/ws/v1/cluster/apps/state</span><br></pre></td></tr></table></figure><h3 id="1-2-JMX-Metrics监控"><a href="#1-2-JMX-Metrics监控" class="headerlink" title="1.2 JMX Metrics监控"></a>1.2 <code>JMX Metrics</code>监控</h3><p>首先需要开启<code>jmx</code>，编辑<code>{hadoop_home}/etc/hadoop/yarn-env.sh</code>配置文件，最后天下下面三行配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">YARN_OPTS="$YARN_OPTS -Dcom.sun.management.jmxremote.authenticate=false"</span><br><span class="line">YARN_OPTS="$YARN_OPTS -Dcom.sun.management.jmxremote.port=8001"</span><br><span class="line">YARN_OPTS="$YARN_OPTS -Dcom.sun.management.jmxremote.ssl=false"</span><br></pre></td></tr></table></figure><p>其中<code>8001</code>是服务监听端口。<code>jmx</code>提供了<code>Cluster、Queue、Jvm、FSQueue</code>等<code>Metrics</code>信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取YARN相关的jmx</span></span><br><span class="line">http://http address:8088/jmx</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果想获取NameNode的jmx</span></span><br><span class="line">http://http address:50070/jmx</span><br></pre></td></tr></table></figure><p>上面的方式会获取服务所有的信息(<code>json</code>格式)。如果需要精准获得准确信息，<code>org.apache.hadoop.jmx.JMXJsonServlet</code>类支持三个参数：<code>callback</code>、<code>qry</code>、<code>get</code>。其中<code>qry</code>用于过滤，下面的<code>url</code>用于查询<code>Yarn</code>上<code>spark</code>用户在<code>default</code>队列上任务信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.1.2:8088/jmx?qry=Hadoop:service=ResourceManager,name=QueueMetrics,q0=root,q1=default,user=spark</span><br></pre></td></tr></table></figure><p>更详细的信息参考官网：<a href="https://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/jmx/JMXJsonServlet.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/jmx/JMXJsonServlet.html</a></p><h3 id="1-3-Python-Api接口"><a href="#1-3-Python-Api接口" class="headerlink" title="1.3 Python Api接口"></a>1.3 <code>Python Api</code>接口</h3><p>对于<code>Python</code>有第三方包支持和<code>yarn</code>进行交互，<code>github</code>地址为:<code>https://github.com/CODAIT/hadoop-yarn-api-python-client</code></p><p>案例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> yarn_api_client <span class="keyword">import</span> ApplicationMaster, HistoryServer, NodeManager, ResourceManager</span><br><span class="line"></span><br><span class="line">rm = ResourceManager(address=<span class="string">'192.168.1.2'</span>, port=<span class="number">8088</span>)</span><br><span class="line"><span class="comment"># 获取到ResourceManager的所有apps的信息</span></span><br><span class="line">rm.cluster_applications().data</span><br><span class="line"><span class="comment"># 获取到ResourceManager的具体任务的信息</span></span><br><span class="line">rm.cluster_application(<span class="string">'application_1437445095118_265798'</span>).data</span><br></pre></td></tr></table></figure><p>对于<code>Hadoop</code>安全集群，还需要部署认证包<code>requests_kerberos</code>。具体可以参考说明文档：<a href="https://python-client-for-hadoop-yarn-api.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">https://python-client-for-hadoop-yarn-api.readthedocs.io/en/latest/index.html</a></p><h2 id="第二部分-Java实现"><a href="#第二部分-Java实现" class="headerlink" title="第二部分 Java实现"></a>第二部分 Java实现</h2><h3 id="2-1-maven依赖"><a href="#2-1-maven依赖" class="headerlink" title="2.1 maven依赖"></a>2.1 maven依赖</h3><p>根据<code>Hadoop</code>的版本添加下面的依赖包：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-yarn-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-yarn-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="2-2-接口实现"><a href="#2-2-接口实现" class="headerlink" title="2.2 接口实现"></a>2.2 接口实现</h3><p>我们将相关配置文件放在<code>resources/conf</code>路径下面，涉及的文件有：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 集群配置文件</span></span><br><span class="line">core-site.xml</span><br><span class="line">hdfs-site.xml</span><br><span class="line">yarn-site.xml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安全认证文件</span></span><br><span class="line">user.keytab</span><br><span class="line">krb5.conf</span><br></pre></td></tr></table></figure><p>下面是案例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.main.yarnmonitor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Sets;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.security.UserGroupInformation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationReport;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.ContainerReport;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.api.records.YarnApplicationState;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.client.api.YarnClient;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.yarn.exceptions.YarnException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.EnumSet;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@program</span>: yarnmonitor</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>:</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: rongxiang</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-03-27 16:44</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">yarnmonitor</span> </span>&#123;</span><br><span class="line">    <span class="comment">//配置文件路径</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span>  String confPath = Thread.currentThread().getContextClassLoader().getResource(<span class="string">""</span>).getPath()+ File.separator + <span class="string">"conf"</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration configuration = initConfiguration(confPath);</span><br><span class="line">        <span class="comment">//初始化安全集群Kerberos配置</span></span><br><span class="line">        initKerberosENV(configuration);</span><br><span class="line">        <span class="comment">//初始化Yarn 客户端</span></span><br><span class="line">        YarnClient yarnClient = YarnClient.createYarnClient();</span><br><span class="line">        yarnClient.init(configuration);</span><br><span class="line">        yarnClient.start();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获得运行的任务应用清单</span></span><br><span class="line">            List&lt;ApplicationReport&gt; applications = yarnClient.getApplications(EnumSet.of(YarnApplicationState.RUNNING));</span><br><span class="line">            <span class="comment">//存储需要关注的任务信息</span></span><br><span class="line">            HashMap&lt;String, ArrayList&lt;String&gt;&gt; applicationInformation = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (ApplicationReport application:applications) &#123;</span><br><span class="line">                String applicationType = application.getApplicationType();</span><br><span class="line">                <span class="comment">// 只关注CPU核数资源使用超过500的任务</span></span><br><span class="line">                <span class="keyword">if</span> (getApplicationInfo(application).get(<span class="number">1</span>)&gt;=<span class="number">500</span>) &#123;</span><br><span class="line">                    applicationInformation.put(String.valueOf(application.getApplicationId()), <span class="keyword">new</span> ArrayList&lt;String&gt;()&#123;&#123;</span><br><span class="line">                        add(String.valueOf(application.getName()));</span><br><span class="line">                        add(String.valueOf(application.getApplicationType()));</span><br><span class="line">                        add(String.valueOf(application.getQueue()));</span><br><span class="line">                        add(String.valueOf(getApplicationInfo(application).get(<span class="number">0</span>)));</span><br><span class="line">                        add(String.valueOf(getApplicationInfo(application).get(<span class="number">1</span>)));</span><br><span class="line">                        add(String.valueOf(getApplicationInfo(application).get(<span class="number">2</span>)));</span><br><span class="line">                    &#125;&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(applicationInformation);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//设置监控信息发送邮件</span></span><br><span class="line">            <span class="keyword">if</span>(!applicationInformation.isEmpty())&#123;</span><br><span class="line">                <span class="comment">//发送邮件</span></span><br><span class="line">                sendMailYarn();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (YarnException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从ApplicationReport获取信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> applicationInfo</span></span><br><span class="line"><span class="comment">     */</span>    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ArrayList&lt;Integer&gt; <span class="title">getApplicationInfo</span><span class="params">(ApplicationReport Application)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;Integer&gt; applicationInfo = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        ApplicationResourceUsageReport resourceReport = Application.getApplicationResourceUsageReport();</span><br><span class="line">        <span class="keyword">if</span> (resourceReport != <span class="keyword">null</span>) &#123;</span><br><span class="line">            Resource usedResources = resourceReport.getUsedResources();</span><br><span class="line">            <span class="keyword">int</span> allocatedMb = usedResources.getMemory();</span><br><span class="line">            <span class="keyword">int</span> allocatedVcores = usedResources.getVirtualCores();</span><br><span class="line">            <span class="keyword">int</span> runningContainers = resourceReport.getNumUsedContainers();</span><br><span class="line">            <span class="comment">//赋值</span></span><br><span class="line">            applicationInfo.add(allocatedMb);</span><br><span class="line">            applicationInfo.add(allocatedVcores);</span><br><span class="line">            applicationInfo.add(runningContainers);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> applicationInfo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化YARN Configuration</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> configuration</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Configuration <span class="title">initConfiguration</span><span class="params">(String confPath)</span> </span>&#123;</span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.out.println(confPath + File.separator + <span class="string">"core-site.xml"</span>);</span><br><span class="line">        configuration.addResource(<span class="keyword">new</span> Path(confPath + File.separator + <span class="string">"core-site.xml"</span>));</span><br><span class="line">        configuration.addResource(<span class="keyword">new</span> Path(confPath + File.separator + <span class="string">"hdfs-site.xml"</span>));</span><br><span class="line">        configuration.addResource(<span class="keyword">new</span> Path(confPath + File.separator + <span class="string">"yarn-site.xml"</span>));</span><br><span class="line">        <span class="keyword">return</span> configuration;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 安全集群配置（如果非安全集群这无需该方法）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initKerberosENV</span><span class="params">(Configuration conf)</span> </span>&#123;</span><br><span class="line">        System.setProperty(<span class="string">"java.security.krb5.conf"</span>, confPath+File.separator+<span class="string">"krb5.conf"</span>);</span><br><span class="line">        System.setProperty(<span class="string">"javax.security.auth.useSubjectCredsOnly"</span>, <span class="string">"false"</span>);</span><br><span class="line">        System.setProperty(<span class="string">"sun.security.krb5.debug"</span>, <span class="string">"false"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            UserGroupInformation.setConfiguration(conf);</span><br><span class="line">            UserGroupInformation.loginUserFromKeytab(<span class="string">"user@HADOOP.COM"</span>, confPath+File.separator+<span class="string">"user.keytab"</span>);</span><br><span class="line">            System.out.println(UserGroupInformation.getCurrentUser());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Yarn客户端<code>YarnClient</code>中定义了方法<code>getApplications</code>，获取到正在运行的任务清单，返回数据类型是：<code>List&lt;ApplicationReport&gt;</code>，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;ApplicationReport&gt; applications = yarnClient.getApplications(EnumSet.of(YarnApplicationState.RUNNING));</span><br></pre></td></tr></table></figure><p>对于数据类型<code>ApplicationReport</code>具有方法<code>getApplicationResourceUsageReport()</code>获得每个Yarn任务的<code>ApplicationResourceUsageReport</code>(任务资源报告)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ApplicationResourceUsageReport resourceReport = Application.getApplicationResourceUsageReport();</span><br></pre></td></tr></table></figure><p><code>ApplicationResourceUsageReport</code>提供了获取各类资源的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Resource usedResources = resourceReport.getUsedResources();</span><br><span class="line"><span class="comment">//任务使用的内存资源</span></span><br><span class="line"><span class="keyword">int</span> allocatedMb = usedResources.getMemory();</span><br><span class="line"><span class="comment">//任务使用的CPU资源</span></span><br><span class="line"><span class="keyword">int</span> allocatedVcores = usedResources.getVirtualCores();</span><br><span class="line"><span class="comment">//任务使用的容器的数量</span></span><br><span class="line"><span class="keyword">int</span> runningContainers = resourceReport.getNumUsedContainers();</span><br></pre></td></tr></table></figure><h2 id="第三部分-总结"><a href="#第三部分-总结" class="headerlink" title="第三部分 总结"></a>第三部分 总结</h2><p>Java的案例中我们使用了<code>HashMap</code>(<code>applicationInformation</code>)数据类型存储关注的任务信息，然后使用邮件接口发出。在实际使用中可以根据需要存储在<code>elasticsearch</code>集群。</p><p>另外对于其他方法，作者没有实际使用，可能存在部分信息未涵盖，可以参考官网文档使用。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、<code>YARN Application Security</code>，链接：<a href="https://hadoop.apache.org/docs/r2.7.4/hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r2.7.4/hadoop-yarn/hadoop-yarn-site/YarnApplicationSecurity.html</a></p><p>2、<code>ApplicationResourceUsageReport</code>接口，链接：<a href="http://hadoop.apache.org/docs/r2.7.0/api/org/apache/hadoop/yarn/api/records/ApplicationResourceUsageReport.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.0/api/org/apache/hadoop/yarn/api/records/ApplicationResourceUsageReport.html</a></p><p>3、<code>ResourceManager REST API’s</code>，链接：<a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html</a></p><p>4、基于<code>Yarn API</code>的Spark程序监控，链接:<a href="https://yq.aliyun.com/articles/710902" target="_blank" rel="noopener">https://yq.aliyun.com/articles/710902</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  Yarn状态数据接口&lt;/li&gt;
&lt;li&gt;第二部分  Java实现&lt;/li&gt;
&lt;li&gt;第三部分
      
    
    </summary>
    
      <category term="Yarn" scheme="https://zjrongxiang.github.io/categories/Yarn/"/>
    
    
  </entry>
  
  <entry>
    <title>Spark on Yarn任务动态伸缩机制介绍</title>
    <link href="https://zjrongxiang.github.io/2020/10/06/2020-10-06-Spark%20on%20Yarn%E4%BB%BB%E5%8A%A1%E5%8A%A8%E6%80%81%E4%BC%B8%E7%BC%A9%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D/"/>
    <id>https://zjrongxiang.github.io/2020/10/06/2020-10-06-Spark on Yarn任务动态伸缩机制介绍/</id>
    <published>2020-10-06T05:30:00.000Z</published>
    <updated>2020-10-06T03:18:22.660Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  常用快捷键</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Spark1.2之后，对于On Yarn模式，已经支持动态资源分配（Dynamic Resource Allocation），这样，就可以根据Application的负载（Task情况），动态的增加和减少executors。</p><h2 id="第一部分-实现原理"><a href="#第一部分-实现原理" class="headerlink" title="第一部分 实现原理"></a>第一部分 实现原理</h2><p>Dynamic Resource Allocation</p><p>Spark provides a mechanism to dynamically adjust the resources your application occupies based on the workload. This means that your application may give resources back to the cluster if they are no longer used and request them again later when there is demand. This feature is particularly useful if multiple applications share resources in your Spark cluster.</p><p>This feature is disabled by default and available on all coarse-grained cluster managers, i.e. <a href="https://spark.apache.org/docs/latest/spark-standalone.html" target="_blank" rel="noopener">standalone mode</a>, <a href="https://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank" rel="noopener">YARN mode</a>, and <a href="https://spark.apache.org/docs/latest/running-on-mesos.html#mesos-run-modes" target="_blank" rel="noopener">Mesos coarse-grained mode</a>.</p><h2 id="第二部分-配置动态伸缩"><a href="#第二部分-配置动态伸缩" class="headerlink" title="第二部分 配置动态伸缩"></a>第二部分 配置动态伸缩</h2><p><a href="https://cloud.tencent.com/developer/article/1195244" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1195244</a></p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Job Scheduling，链接：<a href="https://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  常用快捷键&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;
      
    
    </summary>
    
      <category term="spark" scheme="https://zjrongxiang.github.io/categories/spark/"/>
    
    
  </entry>
  
  <entry>
    <title>监控Kafka的Topic数据</title>
    <link href="https://zjrongxiang.github.io/2020/10/05/2020-10-05-%E7%9B%91%E6%8E%A7Kafka%E7%9A%84Topic%E6%95%B0%E6%8D%AE/"/>
    <id>https://zjrongxiang.github.io/2020/10/05/2020-10-05-监控Kafka的Topic数据/</id>
    <published>2020-10-05T05:30:00.000Z</published>
    <updated>2020-10-05T12:09:20.554Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分实现原理</li><li>第二部分 实现源码</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>业务上需要实现对Kafka的Topic中数据进行监控。业务正常下，Kafka生产者是持续生产数据的。如果一段时间出现Kafka中指定Topic没有新的数据，那么说明业务生产者可能出现异常。</p><h2 id="第一部分-实现原理"><a href="#第一部分-实现原理" class="headerlink" title="第一部分 实现原理"></a>第一部分 实现原理</h2><h3 id="1-1-Kafka生产者的写入原理"><a href="#1-1-Kafka生产者的写入原理" class="headerlink" title="1.1 Kafka生产者的写入原理"></a>1.1 Kafka生产者的写入原理</h3><p>Kafka每个Topic在创建时，划分为若干个Partition。消息在写入的时候，分布式写入指定的多个Partitions中。对于每个Partition，消息是顺序写入的。Topic在创建时，每个Partition的Offset是0，当消息顺序写入后逐步累加Offset值。</p><p>Kafka中Offset变量定义是一个长整型（Long），这个值最大为：9223372036854775807。那么逐步累加会不会用完呢？多虑了哈，这是一个天文级别的数值哈。</p><h3 id="1-2-监控原理"><a href="#1-2-监控原理" class="headerlink" title="1.2 监控原理"></a>1.2 监控原理</h3><p>既然Offset记录了每个Topic的每个Partition的消息量，最朴素的方法就是监控这个值的变化来判断是否有新的数据写入。</p><p>编写语言我们选择Python，而且对于处理Offset这个超大数据，Python是天然支持。</p><p>那么可行性是没问题的。</p><h2 id="第二部分-实现源码"><a href="#第二部分-实现源码" class="headerlink" title="第二部分 实现源码"></a>第二部分 实现源码</h2><h3 id="1-1-Python-Api-接口"><a href="#1-1-Python-Api-接口" class="headerlink" title="1.1 Python Api 接口"></a>1.1 Python Api 接口</h3><p>与Kafka交互的Python包我们使用：<code>Kafka-Python</code>。对于消费者有下面的函数方法：</p><p><code>end_offsets</code>(<em>partitions</em>)<a href="https://kafka-python.readthedocs.io/en/master/_modules/kafka/consumer/group.html#KafkaConsumer.end_offsets" target="_blank" rel="noopener">[source]</a></p><p>Get the last offset for the given partitions. The last offset of a partition is the offset of the upcoming message, i.e. the offset of the last available message + 1.</p><p>This method does not change the current consumer position of the partitions.</p><p>Note</p><p>This method may block indefinitely if the partition does not exist.</p><table><thead><tr><th style="text-align:left">Parameters:</th><th><strong>partitions</strong> (<em>list</em>) – List of TopicPartition instances to fetch offsets for.</th></tr></thead><tbody><tr><td style="text-align:left">Returns:</td><td>int}<code></code>: The end offsets for the given partitions.</td></tr><tr><td style="text-align:left">Return type:</td><td><a href="https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html#id3" target="_blank" rel="noopener"><code></code></a>{TopicPartition</td></tr><tr><td style="text-align:left">Raises:</td><td><code>UnsupportedVersionError</code> – If the broker does not support looking up the offsets by timestamp.<code>KafkaTimeoutError</code> – If fetch failed in request_timeout_ms</td></tr></tbody></table><p>我们写一个简单的测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer, TopicPartition</span><br><span class="line"><span class="comment"># Kafka配置</span></span><br><span class="line">BOOTSTRAP=<span class="string">"192.168.1.1:9092"</span></span><br><span class="line">TOPIC=<span class="string">"test"</span></span><br><span class="line"><span class="comment"># 定义消费者</span></span><br><span class="line">consumer = KafkaConsumer(bootstrap_servers=[BOOTSTRAP])</span><br><span class="line"><span class="comment"># 获取指定Topic的Partitions</span></span><br><span class="line">PARTITIONS = []</span><br><span class="line"><span class="keyword">for</span> partition <span class="keyword">in</span> consumer.partitions_for_topic(TOPIC):</span><br><span class="line">    PARTITIONS.append(TopicPartition(TOPIC, partition))</span><br><span class="line"><span class="comment"># 获取Offset信息</span></span><br><span class="line">partitions = consumer.end_offsets(PARTITIONS)</span><br><span class="line">print(partitions)</span><br><span class="line"><span class="comment">#&#123;TopicPartition(topic='test', partition=0): 4759, TopicPartition(topic='test', partition=1): 4823&#125;</span></span><br></pre></td></tr></table></figure><p>接口比较简洁。案例中，我们创建了一个Topic，取名为test。一共2个分区，1个副本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Topic:testPartitionCount:2ReplicationFactor:1Configs:</span><br><span class="line">Topic: testPartition: 0Leader: 0Replicas: 0Isr: 0</span><br><span class="line">Topic: testPartition: 1Leader: 0Replicas: 0Isr: 0</span><br></pre></td></tr></table></figure><p>所以回显分别显示了目前Topic的两个Partition的Offset值。</p><p>另外我们还可以使用<code>kafka-consumer-groups.sh</code>脚本查看一下目前某个group的offset情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@deeplearning:/data/kafka/kafka_2.12-2.1.0/bin# ./kafka-consumer-groups.sh --bootstrap-server 192.168.1.1:9092 --describe --group my-group</span><br><span class="line">Consumer group 'my-group' has no active members.</span><br><span class="line"></span><br><span class="line">TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID</span><br><span class="line">test            1          4827            4835            8               -               -               -</span><br><span class="line">test            0          4763            4772            9               -               -               -</span><br></pre></td></tr></table></figure><p>其中回显：</p><ul><li>CURRENT-OFFSET，目前group-id名称为’my-group’的消费群组Offset；</li><li>LOG-END-OFFSET，目前topic的的Offset，也就是我们的监控对象；</li><li>LAG，这是LOG-END-OFFSET-CURRENT-OFFSET的差，即’my-group’群组还有多少消息未消费；</li></ul><h3 id="1-2-完整的代码"><a href="#1-2-完整的代码" class="headerlink" title="1.2 完整的代码"></a>1.2 完整的代码</h3><p>实现对多个Topic的监控：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Copyright 2020 RongXiang.</span></span><br><span class="line"><span class="string">Licensed under the terms of the Apache 2.0 license.</span></span><br><span class="line"><span class="string">Please see LICENSE file in the project root for terms.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaProducer, KafkaConsumer, TopicPartition</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># Kafka 配置</span></span><br><span class="line">BOOTSTRAP = [<span class="string">"192.168.31.3:9092"</span>]</span><br><span class="line">MONITORTOPIC = [<span class="string">"test"</span>, <span class="string">"testTopic"</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">monitoroffset</span><span class="params">(bootstrap, topicList)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        consumer = KafkaConsumer(bootstrap_servers=bootstrap)</span><br><span class="line">        topicoffset = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> topic <span class="keyword">in</span> topicList:</span><br><span class="line">            PARTITIONS = []</span><br><span class="line">            <span class="keyword">for</span> partition <span class="keyword">in</span> consumer.partitions_for_topic(topic):</span><br><span class="line">                PARTITIONS.append(TopicPartition(topic, partition))</span><br><span class="line">            partitions = consumer.end_offsets(PARTITIONS)</span><br><span class="line">            print(partitions)</span><br><span class="line">            topicoffset[topic] = sum([partitions[item] <span class="keyword">for</span> item <span class="keyword">in</span> partitions])</span><br><span class="line">        consumer.close()</span><br><span class="line">        <span class="keyword">return</span> topicoffset</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">diffdict</span><span class="params">(dictFirst, dictEnd)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">       diffdict = &#123;&#125;</span><br><span class="line">       <span class="keyword">for</span> item <span class="keyword">in</span> dictFirst:</span><br><span class="line">           diffdict[item] = dictEnd[item]-dictFirst[item]</span><br><span class="line">       <span class="keyword">return</span> diffdict</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sendMessage</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    logging.basicConfig(level=logging.INFO)</span><br><span class="line">    logger = logging.getLogger(__name__)</span><br><span class="line">    firstOffset = monitoroffset(BOOTSTRAP, MONITORTOPIC)</span><br><span class="line">    time.sleep(<span class="number">300</span>)</span><br><span class="line">    secondOffset = monitoroffset(BOOTSTRAP, MONITORTOPIC)</span><br><span class="line">    print(diffdict(firstOffset, secondOffset))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;'test': 4, 'testTopic': 0&#125;</span><br></pre></td></tr></table></figure><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、<code>kafka-python API</code>介绍，链接：<a href="https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html" target="_blank" rel="noopener">https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分实现原理&lt;/li&gt;
&lt;li&gt;第二部分 实现源码&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/
      
    
    </summary>
    
      <category term="Kafka" scheme="https://zjrongxiang.github.io/categories/Kafka/"/>
    
    
  </entry>
  
  <entry>
    <title>Elasticsearch中的GC以及监控</title>
    <link href="https://zjrongxiang.github.io/2020/10/05/2020-10-05-Elasticsearch%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0-Elasticsearch%E4%B8%AD%E7%9A%84GC%E4%BB%A5%E5%8F%8A%E7%9B%91%E6%8E%A7/"/>
    <id>https://zjrongxiang.github.io/2020/10/05/2020-10-05-Elasticsearch系列文章-Elasticsearch中的GC以及监控/</id>
    <published>2020-10-05T05:30:00.000Z</published>
    <updated>2020-10-05T12:39:34.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分实现原理</li><li>第二部分 实现源码</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>garbage collection</p><h2 id="第一部分-实现原理"><a href="#第一部分-实现原理" class="headerlink" title="第一部分 实现原理"></a>第一部分 实现原理</h2><h2 id="第二部分-实现源码"><a href="#第二部分-实现源码" class="headerlink" title="第二部分 实现源码"></a>第二部分 实现源码</h2><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、<code>Nodes stats API</code>介绍，链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html</a></p><p><a href="https://mincong.io/2020/08/30/gc-in-elasticsearch/" target="_blank" rel="noopener">https://mincong.io/2020/08/30/gc-in-elasticsearch/</a></p><p><a href="https://discuss.elastic.co/t/frequent-gc-in-elasticsearch/57681" target="_blank" rel="noopener">https://discuss.elastic.co/t/frequent-gc-in-elasticsearch/57681</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分实现原理&lt;/li&gt;
&lt;li&gt;第二部分 实现源码&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/
      
    
    </summary>
    
      <category term="Elasticsearch" scheme="https://zjrongxiang.github.io/categories/Elasticsearch/"/>
    
    
  </entry>
  
  <entry>
    <title>使用Dockerfile定制docker镜像总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/03/2020-10-03-Docker%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0-Dockerfile%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/03/2020-10-03-Docker系列文章-Dockerfile总结/</id>
    <published>2020-10-03T11:30:00.000Z</published>
    <updated>2020-10-05T13:50:15.967Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><li>背景</li><li>第一部分 Hive 性能瓶颈根源</li><li>Hive 配置优化</li><li>Hive 语句优化</li><li>总结</li></ul><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>构建Docker镜像通常有两种方式：</p><ul><li>基于容器制作；</li><li>通过Dockerfile；</li></ul><p>Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。</p><h2 id="第一部分-Dockerfile文件规范"><a href="#第一部分-Dockerfile文件规范" class="headerlink" title="第一部分 Dockerfile文件规范"></a>第一部分 Dockerfile文件规范</h2><h3 id="Docker镜像的分层"><a href="#Docker镜像的分层" class="headerlink" title="Docker镜像的分层"></a>Docker镜像的分层</h3><ol><li>Dockerfile中的每个指令都会创建一个新的镜像层</li><li>镜像层将被缓存和复用</li><li>当Dockerfile的指令被修改了，复制的文件变化了，或者构建镜像时指定的变量不同了，对应的镜像层缓存就会失效</li><li>某一层的镜像缓存失效后，其之后的镜像层缓存都会随之失效</li><li>镜像层是不可变的，如果在某一层中添加一个文件，然后在下一层中删除则镜像中依然会包含该文件</li></ol><h3 id="Dockerfile编写规则"><a href="#Dockerfile编写规则" class="headerlink" title="Dockerfile编写规则"></a>Dockerfile编写规则</h3><p>Dockerfile中是基于其指令进行编写的，其规则可以参考下面的表格，当然，在编写Dockerfile时，其格式是需要严格遵循的：</p><p>除注释外，第一行必须使用FROM指令所基于的镜像名称；之后使用MAINTAINER指明维护信息；然后就是一系列镜像操作指令，如RUN、 ADD等；最后便是CMD指令来指定启动容器时要运行的命令操作。其中RUN指令可以使用多条，CMD只有最后一条可以生效！</p><h2 id="第二部分-Dockerfile文件组成"><a href="#第二部分-Dockerfile文件组成" class="headerlink" title="第二部分 Dockerfile文件组成"></a>第二部分 Dockerfile文件组成</h2><h3 id="2-1-注释"><a href="#2-1-注释" class="headerlink" title="2.1 注释"></a>2.1 注释</h3><h3 id="2-2-FROM命令"><a href="#2-2-FROM命令" class="headerlink" title="2.2 FROM命令"></a>2.2 FROM命令</h3><h2 id="第三部分-编译Dcokerfile文件"><a href="#第三部分-编译Dcokerfile文件" class="headerlink" title="第三部分 编译Dcokerfile文件"></a>第三部分 编译Dcokerfile文件</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分 Hive 性能瓶颈根源&lt;/li&gt;
&lt;li&gt;Hive 配置优化&lt;/li&gt;
&lt;li&gt;Hive 语句
      
    
    </summary>
    
      <category term="docker" scheme="https://zjrongxiang.github.io/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>使用Dockerfile定制docker镜像总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/03/2020-10-03-Docker%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0-Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <id>https://zjrongxiang.github.io/2020/10/03/2020-10-03-Docker系列文章-Docker常用命令汇总/</id>
    <published>2020-10-03T11:30:00.000Z</published>
    <updated>2020-10-03T03:09:50.129Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><li>背景</li><li>第一部分 Hive 性能瓶颈根源</li><li>Hive 配置优化</li><li>Hive 语句优化</li><li>总结</li></ul><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>构建Docker镜像通常有两种方式：</p><ul><li>基于容器制作；</li><li>通过Dockerfile；</li></ul><p>Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。</p><h2 id="第一部分-Dockerfile文件规范"><a href="#第一部分-Dockerfile文件规范" class="headerlink" title="第一部分 Dockerfile文件规范"></a>第一部分 Dockerfile文件规范</h2><h3 id="Docker镜像的分层"><a href="#Docker镜像的分层" class="headerlink" title="Docker镜像的分层"></a>Docker镜像的分层</h3><ol><li>Dockerfile中的每个指令都会创建一个新的镜像层</li><li>镜像层将被缓存和复用</li><li>当Dockerfile的指令被修改了，复制的文件变化了，或者构建镜像时指定的变量不同了，对应的镜像层缓存就会失效</li><li>某一层的镜像缓存失效后，其之后的镜像层缓存都会随之失效</li><li>镜像层是不可变的，如果在某一层中添加一个文件，然后在下一层中删除则镜像中依然会包含该文件</li></ol><h3 id="Dockerfile编写规则"><a href="#Dockerfile编写规则" class="headerlink" title="Dockerfile编写规则"></a>Dockerfile编写规则</h3><p>Dockerfile中是基于其指令进行编写的，其规则可以参考下面的表格，当然，在编写Dockerfile时，其格式是需要严格遵循的：</p><p>除注释外，第一行必须使用FROM指令所基于的镜像名称；之后使用MAINTAINER指明维护信息；然后就是一系列镜像操作指令，如RUN、 ADD等；最后便是CMD指令来指定启动容器时要运行的命令操作。其中RUN指令可以使用多条，CMD只有最后一条可以生效！</p><h2 id="第二部分-Dockerfile文件组成"><a href="#第二部分-Dockerfile文件组成" class="headerlink" title="第二部分 Dockerfile文件组成"></a>第二部分 Dockerfile文件组成</h2><h3 id="2-1-注释"><a href="#2-1-注释" class="headerlink" title="2.1 注释"></a>2.1 注释</h3><h3 id="2-2-FROM命令"><a href="#2-2-FROM命令" class="headerlink" title="2.2 FROM命令"></a>2.2 FROM命令</h3><h2 id="第三部分-编译Dcokerfile文件"><a href="#第三部分-编译Dcokerfile文件" class="headerlink" title="第三部分 编译Dcokerfile文件"></a>第三部分 编译Dcokerfile文件</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分 Hive 性能瓶颈根源&lt;/li&gt;
&lt;li&gt;Hive 配置优化&lt;/li&gt;
&lt;li&gt;Hive 语句
      
    
    </summary>
    
      <category term="docker" scheme="https://zjrongxiang.github.io/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>Hive中静态分区和动态分区总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/02/2020-10-02-Hive%E4%B8%AD%E9%9D%99%E6%80%81%E5%88%86%E5%8C%BA%E5%92%8C%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/02/2020-10-02-Hive中静态分区和动态分区总结/</id>
    <published>2020-10-02T13:30:00.000Z</published>
    <updated>2020-10-21T12:08:05.398Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  静态分区</li><li>第二部分 动态分区</li><li>第三部分 两者的比较</li><li>第四部分 动态分区使用的问题</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在<code>Hive</code>中有两种类型的分区：静态分区(Static Partitioning)和动态分区(Dynamic Partitioning)。</p><ul><li><strong>静态分区</strong>。对于静态分区，从字面就可以理解：表的分区数量和分区值是固定的。</li><li><strong>动态分区</strong>。会根据数据自动的创建新的分区。</li></ul><p>本文会详细介绍两种分区方法、使用场景以及生产中常见问题和解决方法。</p><h2 id="第一部分-静态分区"><a href="#第一部分-静态分区" class="headerlink" title="第一部分 静态分区"></a>第一部分 静态分区</h2><p>静态分区的使用场景主要是分区的数量是确定的。例如人力资源信息表中使用“部门”作为分区字段，通常一段时间是静态不变的。例如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> employee_dept (</span><br><span class="line">    emp_id <span class="built_in">INT</span>,</span><br><span class="line">    emp_name <span class="keyword">STRING</span></span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (</span><br><span class="line">    dept_name <span class="keyword">STRING</span></span><br><span class="line">    )</span><br><span class="line">location <span class="string">'/user/employee_dept'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> <span class="keyword">LOCAL</span> INPATH <span class="string">'hr.txt'</span></span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> employee_dept</span><br><span class="line"><span class="keyword">PARTITION</span> (dept_name=<span class="string">'HR'</span>);</span><br></pre></td></tr></table></figure><p>上面的外部表以<code>dept_name</code>字段为分区字段，然后导入数据需要指定分区。</p><h2 id="第二部分-动态分区"><a href="#第二部分-动态分区" class="headerlink" title="第二部分 动态分区"></a>第二部分 动态分区</h2><p>通常在生产业务场景中，我们使用的都是灵活的动态分区。例如我们使用时间字段（天、小时）作为分区字段。新的数据写入会自动根据最新的时间创建分区并写入对应的分区。例如下面的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive &gt; insert overwrite table order_partition partition (year,month) select order_id, order_date, order_status, substr(order_date,1,4) year, substr(order_date,5,2) month from orders;</span><br><span class="line"></span><br><span class="line">FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off <span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict</span><br></pre></td></tr></table></figure><p>写入报错。这是因为Hive默认配置不启用动态分区，需要使用前开启配置。开启的方式有两种：</p><ul><li><p>在hive服务配置文件中全局配置；</p></li><li><p>每次交互时候进行配置（只影响本次交互）；</p></li></ul><p>通常我们生产环境使用第二种。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure><p>其中参数<code>hive.exec.dynamic.partition.mode</code>表示动态分区的模式。默认是<code>strict</code>，表示必须指定至少一个分区为静态分区，<code>nonstrict</code>模式表示允许所有的分区字段都可以使用动态分区。</p><h2 id="第三部分-两者的比较"><a href="#第三部分-两者的比较" class="headerlink" title="第三部分 两者的比较"></a>第三部分 两者的比较</h2><p>两种分区模式都有各自的使用场景，我们总结如下：</p><table><thead><tr><th></th><th>静态分区(Static Partitioning)</th><th>动态分区（Dynamic Partitioning）</th></tr></thead><tbody><tr><td>分区创建</td><td>数据插入分区之前，需要手动创建每个分区</td><td>根据表的输入数据动态创建分区</td></tr><tr><td>适用场景</td><td>需要提前知道所有分区。适用于分区定义得早且数量少的用例</td><td>有很多分区，无法提前预估新分区，动态分区是合适的</td></tr></tbody></table><p>另外动态分区的值是<code>MapReduce</code>任务在<code>reduce</code>运行阶段确定的，也就是所有的记录都会<code>distribute by</code>，相同字段(分区字段)的<code>map</code>输出会发到同一个<code>reduce</code>节点去处理，如果数据量大，这是一个很弱的运行性能。而静态分区在编译阶段就确定了，不需要<code>reduce</code>任务处理。所以如果实际业务场景静态分区能解决的，尽量使用静态分区即可。</p><h2 id="第四部分-动态分区使用的问题"><a href="#第四部分-动态分区使用的问题" class="headerlink" title="第四部分 动态分区使用的问题"></a>第四部分 动态分区使用的问题</h2><p>Hive表中分区架构使得数据按照分区分别存储在<code>HDFS</code>文件系统的各个目录中，查询只要针对指定的目录集合进行查询，而不需要全局查找，提高查询性能。</p><p>但是分区不是”银弹”，如果分区数据过多，就会在<code>HDFS</code>文件系统中创建大量的目录和文件，对于集群<code>NameNode</code>服务是有性能压力的，<code>NameNode</code>需要将大量元数据信息保留在内存中。另外大分区表在用户查询时候由于分析<code>size</code>太大，也容易造成<code>Metastore</code>服务出现<code>OMM</code>报错。</p><p>上面两个现象均在生产环境发生，分别造成<code>NameNode</code>和<code>Metastore</code>不可用。</p><p>事实上，Hive为了防止异常生产大量分区，甚至默认动态分区是关闭的。另外对于生成动态分区的数量也做了性能默认限制。</p><h3 id="4-1-动态分区创建限制"><a href="#4-1-动态分区创建限制" class="headerlink" title="4.1 动态分区创建限制"></a>4.1 动态分区创建限制</h3><p>当我们在一个<code>Mapreduce</code>任务（<code>hive</code>写入会编译成<code>mapreduce</code>任务）中创建大量分区的时候，经常会遇到下面的报错信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2015-06-15 17:27:44,614 ERROR [LocalJobRunner Map Task Executor #0]: mr.ExecMapper (ExecMapper.java:map(171)) - org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error while processing row ....</span><br><span class="line">Caused by: org.apache.hadoop.hive.ql.metadata.HiveFatalException: [Error 20004]: Fatal error occurred when node tried to create too many dynamic partitions. The maximum number of dynamic partitions is controlled by hive.exec.max.dynamic.partitions and hive.exec.max.dynamic.partitions.pernode. Maximum was set to: 256... 10 more</span><br></pre></td></tr></table></figure><p>这个报错就是因为Hive对于动态分区创建的限制，涉及的参数有：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.dynamic.partitions = 1000;</span><br><span class="line">hive.exec.max.dynamic.partitions.pernode = 100;</span><br><span class="line">hive.exec.max.created.files = 10000</span><br></pre></td></tr></table></figure><ul><li><code>hive.exec.max.dynamic.partitions.pernode</code>，参数限制<code>MapReduce</code>任务单个任务(mapper或reducer任务)创建的分区数量为100；</li><li><code>hive.exec.max.dynamic.partitions</code>，参数限制单次整体任务创建分区的数量上限为1000个；</li><li><code>hive.exec.max.created.files</code>，参数限制所有单次整体map和reduce任务创建的最大文件数量上限为10000个；</li></ul><p>以上三个阀值超过就会触发错误，集群会杀死任务。为了解决报错，我们通常将两个参数调大。但是也需要用户对自己的Hive表的分区数量进行合理规划，避免过多的分区。</p><h3 id="4-2-特殊分区"><a href="#4-2-特殊分区" class="headerlink" title="4.2 特殊分区"></a>4.2 特殊分区</h3><p>如果动态分区列输入的值为NULL或空字符串，则Hive将该行将放入一个特殊分区，其名称由参数<code>hive.exec.default.partition.name</code>控制。默认值为<code>__HIVE_DEFAULT_PARTITION__</code>。</p><p>用户可以使用（查看表分区）命令进行查看：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> <span class="string">'table名称'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># process_date=20160208</span></span><br><span class="line"><span class="comment">#process_date=__HIVE_DEFAULT_PARTITION__</span></span><br></pre></td></tr></table></figure><p>有时候异常生产这些分区数据，需要进行清理。如果使用下面的语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> Table_Name <span class="keyword">DROP</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> <span class="keyword">PARTITION</span>(process_date=<span class="string">'__HIVE_DEFAULT_PARTITION__'</span>);</span><br></pre></td></tr></table></figure><p>这时候Hive会报错：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Error while compiling statement: FAILED: SemanticException Unexpected unknown partitions for (process_date = null) (state=42000,code=40000)</span><br></pre></td></tr></table></figure><p>这是Hive一个已知bug（编号：<a href="https://issues.apache.org/jira/browse/HIVE-11208" target="_blank" rel="noopener">HIVE-11208</a>），在<code>Hive 2.3.0</code>版本修复。</p><p>但是有个有修复方法（不建议在生产环境中实施）：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- update the column to be "string"</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="keyword">test</span> <span class="keyword">PARTITION</span> <span class="keyword">COLUMN</span> (p1 <span class="keyword">string</span>);</span><br><span class="line"><span class="comment">-- remove the default partition</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="keyword">test</span> <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> (p1 = <span class="string">'__HIVE_DEFAULT_PARTITION__'</span>);</span><br><span class="line"><span class="comment">-- then revert the column back to "int" type</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="keyword">test</span> <span class="keyword">PARTITION</span> <span class="keyword">COLUMN</span> (p1 <span class="built_in">int</span>);</span><br></pre></td></tr></table></figure><p>链接：<a href="https://cloudera.ericlin.me/2015/07/how-to-drop-hives-default-partition-__hive_default_partition__-with-int-partition-column/" target="_blank" rel="noopener">https://cloudera.ericlin.me/2015/07/how-to-drop-hives-default-partition-__hive_default_partition__-with-int-partition-column/</a></p><h3 id="4-3-乱码分区字段"><a href="#4-3-乱码分区字段" class="headerlink" title="4.3 乱码分区字段"></a>4.3 乱码分区字段</h3><p>有时候表分区字段由于处理不当，会出现乱码分区，例如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hp_stat_time=r_ready%3D91;r_load%3D351</span><br></pre></td></tr></table></figure><p>原因是Hive会自动对一些<code>UTF-8</code>字符编码成<code>Unicode</code>（类似网址中中文字符和一些特殊字符的编码处理）。此处<code>%3D</code>解码后是’=’。可以使用在线转换进行解码：<a href="https://www.matools.com/code-convert-utf8。" target="_blank" rel="noopener">https://www.matools.com/code-convert-utf8。</a></p><p>最后使用解码后的字段即可（注意分号转义）：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> dpdw_traffic_base <span class="keyword">drop</span> <span class="keyword">partition</span>(hp_stat_time=<span class="string">'r_ready=91\;r_load=351'</span>);</span><br></pre></td></tr></table></figure><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、动态分区，链接：<a href="https://cwiki.apache.org/confluence/display/Hive/DynamicPartitions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/DynamicPartitions</a></p><p>2、Hive Tutorial，链接：<a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Tutorial</a></p><p>3、Apache Hive 中文手册，链接：<a href="https://www.docs4dev.com/docs/zh/apache-hive/3.1.1/reference" target="_blank" rel="noopener">https://www.docs4dev.com/docs/zh/apache-hive/3.1.1/reference</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  静态分区&lt;/li&gt;
&lt;li&gt;第二部分 动态分区&lt;/li&gt;
&lt;li&gt;第三部分 两者的比较&lt;/l
      
    
    </summary>
    
      <category term="Hive" scheme="https://zjrongxiang.github.io/categories/Hive/"/>
    
    
  </entry>
  
  <entry>
    <title>Mysql的两种连接方式总结</title>
    <link href="https://zjrongxiang.github.io/2020/10/02/2020-10-01-Mysql%E7%9A%84%E4%B8%A4%E7%A7%8D%E8%BF%9E%E6%8E%A5%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/10/02/2020-10-01-Mysql的两种连接方式总结/</id>
    <published>2020-10-02T05:30:00.000Z</published>
    <updated>2020-10-02T04:53:19.258Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  <code>TCP/IP Socket</code></li><li>第二部分 <code>UNIX Domain Socket</code></li><li>第三部分 <code>Mysql</code>的两种连接方式</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们在使用<code>Mysql</code>客户端和<code>Mysql</code>交互的时候，如果客户端是远程（非本机）那么底层是通过<code>TCP/IP</code>的<code>Socket</code>方式进行交互。但是如果客户端和数据库在同一台服务器上时，<code>Mysql</code>支持通过<code>UNIX Domain Socket</code>方式交互。</p><p><code>Mysql</code>客户端和<code>Mysql</code>数据库服务通信，不管是本机还是远程，其本质是两个计算机进程之间的通信。根据位置的不同分为：本机进程通信和网络间进程通信。</p><ul><li>本机进程通信。Linux通常有：管道、信号量、消息队列、信号、共享内存、<code>UNIX Domain Socket</code>套接字。</li><li>网络间进程通信。 <code>TCP/IP Socket</code></li></ul><p>本文将介绍将介绍这两种交互方式。</p><h2 id="第一部分-TCP-IP-Socket"><a href="#第一部分-TCP-IP-Socket" class="headerlink" title="第一部分 TCP/IP Socket"></a>第一部分 <code>TCP/IP Socket</code></h2><p>提到通信，那么首先需要解决是身份识别问题。对于本机进程，不同的进程都有操作系统分配的进程号(process ID)作为唯一标识。但是网络间进程通信时候，<code>PID</code>就不能作为唯一标识了，另外操作系统支持的网络协议不同。所以网络间进程通信需要解决唯一身份标识和网络协议识别问题。</p><p>这时候出现的<code>TCP/IP</code>协议中，<code>IP</code>层的<code>ip</code>地址可以唯一标识网络计算机身份，传输层的“协议+端口”可以唯一标识进程。这样就有”三元坐标”:(<code>IP</code>地址，协议，端口)，这个坐标可以唯一标识网络中进程。</p><p>在网络编程中，<code>TCP/IP</code>和<code>Socket</code>两个概念没有必然的联系。Socket编程接口在设计的时候，也能支持其他的网络协议。所以，<code>socket</code>的出现只是可以更方便的使用<code>TCP/IP</code>协议栈而已，其对<code>TCP/IP</code>进行了抽象封装，形成了几个最基本的函数接口。例如create，listen，accept，connect，read和write等等。</p><h2 id="第二部分-UNIX-Domain-Socket"><a href="#第二部分-UNIX-Domain-Socket" class="headerlink" title="第二部分 UNIX Domain Socket"></a>第二部分 <code>UNIX Domain Socket</code></h2><p>对于本机中进程通信，也是可以使用<code>TCP/IP Socket</code>方式，通过回环地址(<code>loopback</code>)地址 <code>127.0.0.1</code>,但是对于本机这是繁琐的，接着就发展出了<code>Unix domain socket</code>方式，又称<code>IPC(inter-process communication</code>进程间通信) socket。</p><p><code>UNIX domain socket</code> 用于本机进程通信更有效率。不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号、路由和应答等，只是将应用层数据从一个进程拷贝到另一个进程。<code>UNIX domain socket</code>与 <code>TCP/IP Socket</code>相比较，在同一台主机的传输速度前者是后者的两倍。</p><p><code>UNIX domain socket</code> 与<code>TCP/IP Socket</code> 最明显的不同在于地址格式不同，<code>TCP/IP Socket</code> 的 socket 地址是<code>IP</code>地址加端口号，而<code>UNIX domain socket</code>的地址是一个 socket 类型的文件在文件系统中的路径。</p><p>另外下面的命令可以查看当前操作系统中<code>UNIX domain socket</code>通信清单：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -a -p --unix</span><br></pre></td></tr></table></figure><h2 id="第三部分-Mysql的两种连接方式"><a href="#第三部分-Mysql的两种连接方式" class="headerlink" title="第三部分 Mysql的两种连接方式"></a>第三部分 <code>Mysql</code>的两种连接方式</h2><h3 id="3-1-UNIX-Domain-Socket方式"><a href="#3-1-UNIX-Domain-Socket方式" class="headerlink" title="3.1 UNIX Domain Socket方式"></a>3.1 <code>UNIX Domain Socket</code>方式</h3><p>客户端部署在<code>Mysql</code>本机，配置好环境变量，就可以使用下面的命令登录<code>Mysql</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql ~]# mysql -uroot -P*****</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 1</span><br><span class="line">Server version: 5.5.46-log MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</span><br><span class="line"></span><br><span class="line"><span class="meta">root@[(none)]&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure><p>这时候就是通过<code>UNIX Domain Socket</code>方式和<code>Mysql</code>进行交互的。只是这时候我们没有指定参数<code>–socket</code>，这个参数指定就是<code>UNIX Domain Socket</code>依赖的socket 类型的文件。<code>Mysql</code>默认这个参数为：<code>–socket=/tmp/mysql.sock</code>。如果安装<code>Mysql</code>时候，配置文件<code>my.cnf</code>中下面配置错误或文件丢失，就会报错。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[client] </span><br><span class="line">socket=/tmp/mysql.sock</span><br></pre></td></tr></table></figure><p>报错找不到<code>sock</code>文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql ~]# mysql -uroot -P*****</span><br><span class="line">ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2)</span><br></pre></td></tr></table></figure><p>遇到这种报错的处理方法：</p><ul><li><p>使用<code>find</code>命令查找文件路径，调整配置，使其归位。如果文件不再配置文件指定位置，这时候需要在命令中指定具体的路径，命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql ~]# mysql -uroot -P*****  -S /path/of/mysql.scok</span><br></pre></td></tr></table></figure></li><li><p>重新创建。可以简单地通过重启<code>Mysql</code>服务重新创建得到它。因为服务在启动时重新创建它。</p></li></ul><p>另外可以通过查看<code>Mysql</code>变量信息来查看这个文件路径配置路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> SHOW VARIABLES LIKE <span class="string">'socket'</span>;</span></span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| Variable_name | Value           |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| socket        | /tmp/mysql.sock |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line">mysql -uroot -S/tmp/mysql.sock</span><br></pre></td></tr></table></figure><h3 id="3-2-TCP-IP-Socket方式"><a href="#3-2-TCP-IP-Socket方式" class="headerlink" title="3.2 TCP/IP Socket方式"></a>3.2 <code>TCP/IP Socket</code>方式</h3><p>在本机使用<code>UNIX Domain Socket</code>方式无法登陆时候，还可以使用<code>TCP/IP Socket</code>方式。命令需要指定<code>IP</code>信息，如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql ~]# mysql -h192.1.1.20</span><br><span class="line">ERROR 2003 (HY000): Can't connect to MySQL server on '192.1.1.20' (111)</span><br><span class="line"></span><br><span class="line">[root@mysql ~]# mysql -h192.1.1.20 -P3307</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.5.46-log MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</span><br><span class="line"></span><br><span class="line"><span class="meta">root@[(none)]&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure><p>那么如果本机中同时指定两个参数时候，<code>Mysql</code>会默认使用<code>TCP/IP Socket</code>的方式连接。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql ~]# mysql -h192.1.1.20 -P3306 -S /path/of/mysql.scok</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.5.46-log MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</span><br><span class="line"></span><br><span class="line"><span class="meta">root@[(none)]&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure><p>对于和远程<code>Mysql</code>服务交互，需要指定远程<code>Mysql</code>服务监听<code>IP</code>和端口即可，不再赘述。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Linux进程间通信方式有哪些？，链接：<a href="https://zhuanlan.zhihu.com/p/63916424" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63916424</a></p><p>2、UNIX Domain Socket IPC，链接：<a href="http://docs.linuxtone.org/ebooks/C&amp;CPP/c/ch37s04.html" target="_blank" rel="noopener">http://docs.linuxtone.org/ebooks/C&amp;CPP/c/ch37s04.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  &lt;code&gt;TCP/IP Socket&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;第二部分 &lt;code
      
    
    </summary>
    
      <category term="Mysql" scheme="https://zjrongxiang.github.io/categories/Mysql/"/>
    
    
  </entry>
  
  <entry>
    <title>Spark任务依赖jar包总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/27/2020-09-27-%E9%9D%9Eroot%E7%94%A8%E6%88%B7%E9%83%A8%E7%BD%B2keeplived%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/27/2020-09-27-非root用户部署keeplived总结/</id>
    <published>2020-09-27T05:30:00.000Z</published>
    <updated>2020-09-27T16:11:57.856Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  常用快捷键</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://blog.csdn.net/ohaozy/article/details/106355222" target="_blank" rel="noopener">https://blog.csdn.net/ohaozy/article/details/106355222</a></p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Running Spark on YARN，链接：<a href="https://spark.apache.org/docs/1.5.1/running-on-yarn.html" target="_blank" rel="noopener">https://spark.apache.org/docs/1.5.1/running-on-yarn.html</a></p><p>2、解决jar包冲突新思路 - maven-shade-plugin，链接：<a href="https://zhuanlan.zhihu.com/p/62796806" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62796806</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  常用快捷键&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;
      
    
    </summary>
    
      <category term="Java" scheme="https://zjrongxiang.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>Spark任务依赖jar包总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/27/2020-09-27-Spark%E4%BB%BB%E5%8A%A1%E4%BE%9D%E8%B5%96jar%E5%8C%85%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/27/2020-09-27-Spark任务依赖jar包总结/</id>
    <published>2020-09-27T05:30:00.000Z</published>
    <updated>2020-10-12T14:33:42.271Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  常用快捷键</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>编写了Spark批任务（Java），使用maven打包成jar包，提交到Yarn集群，报jar包冲突的错误。查阅资料了解一下背后的原理。</p><p><a href="https://stackoverflow.com/questions/16222748/building-a-fat-jar-using-maven" target="_blank" rel="noopener">https://stackoverflow.com/questions/16222748/building-a-fat-jar-using-maven</a></p><h2 id="第一部分-Spark任务加载jar包原理"><a href="#第一部分-Spark任务加载jar包原理" class="headerlink" title="第一部分 Spark任务加载jar包原理"></a>第一部分 Spark任务加载jar包原理</h2><p>Spark任务运行默认加载的配置从默认的配置文件中获取，如果配置参数用户重新定义，那么参数将会覆盖默认配置文件中加载的配置。</p><p>spark-defaults.conf</p><p><a href="https://exceptionshub.com/add-jars-to-a-spark-job-spark-submit.html" target="_blank" rel="noopener">https://exceptionshub.com/add-jars-to-a-spark-job-spark-submit.html</a></p><p>原因是本地的jar包被SPARK_HOME/lib中的jar覆盖。spark程序在提交到yarn时，除了上传用户程序的jar，还会上传SPARK_HOME的lib目录下的所有jar包（参考附录2 )。如果你程序用到的jar与SPARK_HOME/lib下的jar发生冲突，那么默认会优先加载SPARK_HOME/lib下的jar，而不是你程序的jar，所以会发生“ NoSuchMethodError”。</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">mvn </span>dependency:tree -Dverbose</span><br></pre></td></tr></table></figure><p>参数<code>spark.yarn.jars</code></p><p>官方文档的解释：</p><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List <span class="keyword">of</span> libraries containing Spark code <span class="keyword">to</span> distribute <span class="keyword">to</span> YARN containers. By <span class="keyword">default</span>, Spark <span class="keyword">on</span> YARN will <span class="keyword">use</span> Spark jars installed locally, but the Spark jars can also be <span class="keyword">in</span> a world-readable location <span class="keyword">on</span> HDFS. This allows YARN <span class="keyword">to</span> cache it <span class="keyword">on</span> nodes so that it doesn<span class="symbol">'t</span> need <span class="keyword">to</span> be distributed each <span class="built_in">time</span> an application runs. <span class="keyword">To</span> point <span class="keyword">to</span> jars <span class="keyword">on</span> HDFS, <span class="keyword">for</span> example, set this <span class="keyword">configuration</span> <span class="keyword">to</span> hdfs:///some/path. Globs are allowed.</span><br></pre></td></tr></table></figure><p>参数（1.5.1）：</p><p><strong>spark.driver.extraClassPath</strong></p><p><strong>spark.executor.extraClassPath</strong></p><p>附加到driver的classpath的额外的classpath实体。</p><p>附加到executors的classpath的额外的classpath实体。这个设置存在的主要目的是Spark与旧版本的向后兼容问题。用户一般不用设置这个选项</p><p>额外的classpath条目需预先添加到驱动程序 classpath中。 注意 : 在客户端模式下，这一套配置不能通过 SparkConf 直接在应用在应用程序中，因为 JVM 驱动已经启用了。相反，请在配置文件中通过设置 –driver-class-path 选项或者选择默认属性。</p><p>目录使用hdfs文件</p><p>参数：</p><p>spark.driver.extraLibraryPath</p><p>spark.executor.extraLibraryPath</p><p>指定启动driver的JVM时用到的库路径</p><p>参数：（2.1.0版本后）</p><p>spark.driver.userClassPathFirst</p><p>spark.executor.userClassPathFirst</p><p>(实验性)当在driver中加载类时，是否用户添加的jar比Spark自己的jar优先级高。这个属性可以降低Spark依赖和用户依赖的冲突。它现在还是一个实验性的特征。</p><p>（实验）在驱动程序加载类库时，用户添加的 Jar 包是否优先于 Spark 自身的 Jar 包。这个特性可以用来缓解冲突引发的依赖性和用户依赖。目前只是实验功能。这是仅用于集群模式。</p><p>参数：</p><p>spark.yarn.dist.jars</p><h2 id="第二部分-解决jar包冲突"><a href="#第二部分-解决jar包冲突" class="headerlink" title="第二部分 解决jar包冲突"></a>第二部分 解决jar包冲突</h2><h3 id="第四种方式"><a href="#第四种方式" class="headerlink" title="第四种方式"></a>第四种方式</h3><p><strong>操作：更改Spark的配置信息:SPARK_CLASSPATH, 将第三方的jar文件添加到SPARK_CLASSPATH环境变量中</strong></p><p>注意事项：要求Spark应用运行的所有机器上必须存在被添加的第三方jar文件</p><p><a href="javascript:void(0" target="_blank" rel="noopener"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>;)</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A.创建一个保存第三方jar文件的文件夹:</span><br><span class="line"> 命令：$ mkdir external_jars</span><br><span class="line">B.修改Spark配置信息</span><br><span class="line"> 命令：$ vim conf/spark-env.sh</span><br><span class="line">修改内容：SPARK_CLASSPATH=$<span class="symbol">SPARK_CLASSPATH:</span>/opt/cdh-<span class="number">5.3</span>.<span class="number">6</span>/spark/external_jars/*</span><br><span class="line">C.将依赖的jar文件copy到新建的文件夹中</span><br><span class="line">命令：$ cp /opt/cdh-<span class="number">5.3</span>.<span class="number">6</span>/hive/<span class="class"><span class="keyword">lib</span>/<span class="title">mysql</span>-<span class="title">connector</span>-<span class="title">java</span>-5.1.27-<span class="title">bin</span>.<span class="title">jar</span> ./<span class="title">external_jars</span>/</span></span><br></pre></td></tr></table></figure><h2 id="备注：（只针对spark-on-yarn-cluster-模式）"><a href="#备注：（只针对spark-on-yarn-cluster-模式）" class="headerlink" title="备注：（只针对spark on yarn(cluster)模式）"></a>备注：（只针对spark on yarn(cluster)模式）</h2><h3 id="spark-on-yarn-cluster-，如果应用依赖第三方jar文件"><a href="#spark-on-yarn-cluster-，如果应用依赖第三方jar文件" class="headerlink" title="spark on yarn(cluster)，如果应用依赖第三方jar文件"></a>spark on yarn(cluster)，如果应用依赖第三方jar文件</h3><h3 id="最终解决方案：将第三方的jar文件copy到-HADOOP-HOME-share-hadoop-common-lib文件夹中-Hadoop集群中所有机器均要求copy"><a href="#最终解决方案：将第三方的jar文件copy到-HADOOP-HOME-share-hadoop-common-lib文件夹中-Hadoop集群中所有机器均要求copy" class="headerlink" title="最终解决方案：将第三方的jar文件copy到${HADOOP_HOME}/share/hadoop/common/lib文件夹中(Hadoop集群中所有机器均要求copy)"></a>最终解决方案：将第三方的jar文件copy到${HADOOP_HOME}/share/hadoop/common/lib文件夹中(Hadoop集群中所有机器均要求copy)</h3><p><a href="https://blog.csdn.net/ifenggege/article/details/108327167" target="_blank" rel="noopener">https://blog.csdn.net/ifenggege/article/details/108327167</a></p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Running Spark on YARN，链接：<a href="https://spark.apache.org/docs/1.5.1/running-on-yarn.html" target="_blank" rel="noopener">https://spark.apache.org/docs/1.5.1/running-on-yarn.html</a></p><p>2、解决jar包冲突新思路 - maven-shade-plugin，链接：<a href="https://zhuanlan.zhihu.com/p/62796806" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62796806</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  常用快捷键&lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;
      
    
    </summary>
    
      <category term="Java" scheme="https://zjrongxiang.github.io/categories/Java/"/>
    
    
  </entry>
  
  <entry>
    <title>布隆过滤算法总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/12/2020-09-12-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/12/2020-09-12-布隆过滤算法总结/</id>
    <published>2020-09-12T05:30:00.000Z</published>
    <updated>2020-09-19T11:44:21.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分   </li><li>第二部分 </li><li>第三部分 </li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在数据处理中，我们经常有这样的需求，判断某个元素是否在一个指定集合中。最朴素的处理方法是首先存储指定集合中数据，然后查找集合中数据，如有数据和查找元素相等即归属于该集合。</p><p>在数学中，如果只利用集合的定义属性，查找只能通过穷举遍历。如果集合元素较大，势必会影响查找的性能。</p><p>这时候对于集合数据类型使用特殊的数据架构实现，这就是Hash表（散列表）。集合数据结构由三个部分组成：</p><ul><li>数据坐标集合B。</li><li>原始数据集合A。</li><li>Hash Function。hash函数是原始集合A到坐标集合的映射。</li></ul><p><img src="https://img-blog.csdnimg.cn/2019120520321867.jpg" alt="https://img-blog.csdnimg.cn/2019120520321867.jpg"></p><p>在这种数据结构下，判断元素是否属于指定集合，只需要计算该元素在hash函数作用下的坐标值。而这个坐标设置为数组的坐标，通过数组坐标就可以获取这个地址空间存储的值，最后判断是否和元素相等。</p><blockquote><p>上面是最朴素的原理，在实际中由于hash函数的特点，存在集合A中不同值在hash函数映射下，坐标值可能是相同的，这就是hash冲突。具体细节后续介绍。</p></blockquote><p>Hash表的实现本质思想是“空间换取时间”，对于特别大的集合，这种换取需要海量的内存存储空间。例如经常列举的案例就是垃圾邮件过滤场景。</p><p>引用自吴军的《数学之美》。<code>Yahoo</code>, <code>Hotmail</code> 和 <code>Gmail</code> 等公众电子邮件提供商，需要过滤垃圾邮件。一个办法就是记录下那些发垃圾邮件的 email 地址。由于那些发送者不停地在注册新的地址，全世界少说也有几十亿个发垃圾邮件的地址，将他们都存起来则需要大量的存储。如果用哈希表，每存储一亿 个 email 地址， 就需要 1.6 GB 的内存（用哈希表实现的具体办法是将每一个 email 地址对应成一个八字节的信息指纹， 然后将这些信息指纹存入哈希表，由于哈希表的存储效率一般只有 50%，因此一个 email 地址需要占用十六个字节。一亿个地址大约要 1.6 GB内存资源）。因此存储几十亿个邮件地址可能需要上百 GB 的内存。</p><p>那么我们重新分析一下我们业务场景，实际核心需求是：<strong>判断元素是否重复，并不需要存储集合中具体数据</strong>。</p><p>数据坐标集合B，在数学中我们有很多实现方式（空间坐标等）。但是在计算机科学中，我们需要使用基础数据结构和运算方式。布隆（Burton Howard Bloom）在1970年提出布隆过滤器算法，算法中使用位阵列（Bit Array）作为坐标集合。接下来我们将详细介绍。</p><h2 id="第一部分-Hash函数"><a href="#第一部分-Hash函数" class="headerlink" title="第一部分 Hash函数"></a>第一部分 Hash函数</h2><h3 id="1-1-Hash函数定义"><a href="#1-1-Hash函数定义" class="headerlink" title="1.1 Hash函数定义"></a>1.1 Hash函数定义</h3><p>Hash函数，通常音译为哈希函数（也有翻译成：散列函数）。Hash函数首先是数学意义上的函数：<br>$$<br>Hash\ Function\ F：A-&gt;B<br>$$<br>其中定义域集合A是不等长的字符串集合，而值域集合B中字符串是固定长度。</p><p>理论上满足这样的函数的海量的，我们在挑选好的Hash函数时，通常有下面的标准：</p><ul><li>Hash函数在计算值域的时候是高效的（对于长度为n的字符串计算时间复杂度应为O(n)）。</li><li>确定性。对于任何给定的输入，哈希函数必须始终给出相同的结果。即函数值的确定性。</li><li>Hash碰撞概率低。由于值域集合中字符串是固定长度的，那么肯定是一个有限集合。例如<code>SHA256</code>算法值域大小（集合的势）为<code>2^256</code>。在我们进行<code>2^256+1</code>次输入时，必然会发生一次碰撞（$$x!=y,F(x)=F(y)$$）。所以选取的Hash函数针对具体场景，需要具有较低的碰撞概率。</li><li>隐蔽性。通俗的讲就是不能通过函数值F(x)，反向计算出x。这就是计算理论和密码学中单向函数概念。由于这个特性Hash函数大量应用于加密场景。</li><li>值域集合分布均匀。谈到分布那么值域空间就引入了距离的概念。通俗的讲就是点与点之间打散在空间中，没有聚集现象。</li></ul><p>Hash函数将一个空间A中的数据映射到另一个空间B（坐标空间）中数据，通常集合B小于集合A（集合的势）。数据空间A定义成Hash表，在数据初始化和插入过程需要计算Hash坐标，并存储。这就完成了将计算时间（或计算消耗）转换成存储空间的思想。</p><h3 id="1-2-Hash函数种类"><a href="#1-2-Hash函数种类" class="headerlink" title="1.2 Hash函数种类"></a>1.2 Hash函数种类</h3><p>通常按照Hash函数的实现原理分为：加法Hash、位运算Hash、乘法Hash、除法Hash、查表Hash、混合Hash。</p><h4 id="1-2-1-加法Hash"><a href="#1-2-1-加法Hash" class="headerlink" title="1.2.1 加法Hash"></a>1.2.1 加法Hash</h4><p>Hash将字符串字符相加并处理后形成结果。下面案例同余质数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    System.out.println(additiveHash(<span class="string">"Secure Hash Algorit"</span>,<span class="number">19</span>));</span><br><span class="line">    <span class="comment">// 输出3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">additiveHash</span><span class="params">(String key, <span class="keyword">int</span> prime)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> hash,i;</span><br><span class="line">    <span class="keyword">for</span>(hash=key.length(),i=<span class="number">0</span>;i&lt;key.length();i++)&#123;</span><br><span class="line">        hash+=key.charAt(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> hash%prime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-2-2-位运算Hash"><a href="#1-2-2-位运算Hash" class="headerlink" title="1.2.2 位运算Hash"></a>1.2.2 位运算Hash</h4><p>这类型Hash函数通过利用各种位运算（常见的是移位和异或等）来充分的变换输入元素。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    System.out.println(rotatingHash(<span class="string">"Secure Hash Algorit"</span>,<span class="number">19</span>));</span><br><span class="line">    <span class="comment">//6</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">rotatingHash</span><span class="params">(String key,<span class="keyword">int</span> prime)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> hash,i;</span><br><span class="line">    <span class="keyword">for</span>(hash = key.length(),i=<span class="number">0</span>;i&lt;key.length();i++)&#123;</span><br><span class="line">        hash=(hash&lt;&lt;<span class="number">1</span>)^(hash&gt;&gt;<span class="number">10</span>)^key.charAt(i)&amp;key.charAt(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> hash%prime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-2-3-乘法Hash"><a href="#1-2-3-乘法Hash" class="headerlink" title="1.2.3 乘法Hash"></a>1.2.3 乘法Hash</h4><p>这种类型的Hash函数利用了乘法的不相关性.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    System.out.println(bernstein(<span class="string">"Secure Hash Algorit"</span>));</span><br><span class="line">    <span class="comment">//361558494</span></span><br><span class="line">&#125;    </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">bernstein</span><span class="params">(String key)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> hash=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;key.length();i++)&#123;</span><br><span class="line">        hash=hash*<span class="number">10</span>+key.charAt(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="1-2-4-除法Hash"><a href="#1-2-4-除法Hash" class="headerlink" title="1.2.4 除法Hash"></a>1.2.4 除法Hash</h4><p>因为除法太慢，这种方式几乎找不到真正的应用。</p><h4 id="1-2-5-查表Hash"><a href="#1-2-5-查表Hash" class="headerlink" title="1.2.5 查表Hash"></a>1.2.5 查表Hash</h4><p>查表Hash中有名的例子有：Universal Hashing和Zobrist Hashing。他们的表格都是随机生成的。</p><h4 id="1-2-6-混合Hash"><a href="#1-2-6-混合Hash" class="headerlink" title="1.2.6 混合Hash"></a>1.2.6 混合Hash</h4><p>混合Hash算法利用了以上各种方式。各种常见的Hash算法，比如MD5、Tiger都属于这个范围。它们一般很少在面向查找的Hash函数里面使用。</p><h3 id="1-3-Hash函数应用"><a href="#1-3-Hash函数应用" class="headerlink" title="1.3 Hash函数应用"></a>1.3 Hash函数应用</h3><p>Hash函数主要应用有：</p><ul><li><p><strong>安全加密</strong></p><p>密钥加密通常使用MD5和SHA系列算法。SHA系列有五个算法，分别是 SHA-1、SHA-224、SHA-256、SHA-384，和SHA-512。后四者有时并称为 SHA-2。SHA-1在许多安全协定中广为使用，包括 TLS/SSL 等，是 MD5 的后继者。</p><p>SHA-256可能是所有加密哈希函数中最著名的，因为它已在区块链技术中广泛使用。中本聪的原始比特币协议中使用了它。</p></li><li><p><strong>唯一标识</strong></p><p>文件之类的二进制数据做 md5 处理，作为唯一标识，这样判定重复文件的时候更快捷。</p></li><li><p><strong>数据校验</strong></p><p>比如从网上下载的很多文件（尤其是P2P站点资源），都会包含一个 MD5 值，用于校验下载数据的完整性，避免数据在中途被劫持篡改。</p></li><li><p><strong>分布式缓存</strong></p><p>分布式缓存和其他机器或数据库的分布式不一样，因为每台机器存放的缓存数据不一致，每当缓存机器扩容时，需要对缓存存放机器进行重新索引（或者部分重新索引），这里应用到的也是哈希算法的思想。</p></li><li><p><strong>负载均衡</strong></p><p>对于同一个客户端上的请求，尤其是已登录用户的请求，需要将其会话请求都路由到同一台机器，以保证数据的一致性，这可以借助哈希算法来实现，通过用户 ID 尾号对总机器数取模（取多少位可以根据机器数定），将结果值作为机器编号。</p></li></ul><h2 id="第二部分-布隆过滤"><a href="#第二部分-布隆过滤" class="headerlink" title="第二部分 布隆过滤"></a>第二部分 布隆过滤</h2><h3 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h3><p>前文我们讨论了“判断某个元素是否在一个指定集合中”问题的实现思路。在数据量较小的情况下，我们可以使用经典的<code>HashMap</code>数据结构。对于大量数据场景下，布隆（Burton Howard Bloom）在1970年提出布隆过滤器算法。</p><h3 id="2-2-Java实现"><a href="#2-2-Java实现" class="headerlink" title="2.2 Java实现"></a>2.2 Java实现</h3><h3 id="2-2-布隆过滤的应用"><a href="#2-2-布隆过滤的应用" class="headerlink" title="2.2 布隆过滤的应用"></a>2.2 布隆过滤的应用</h3><p>Google 著名的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数［3］。</p><p>Squid 网页代理缓存服务器在 <a href="http://wiki.squid-cache.org/SquidFaq/CacheDigests" target="_blank" rel="noopener">cache digests </a>中使用了也布隆过滤器［4］。</p><p>Venti 文档存储系统也采用布隆过滤器来检测先前存储的数据［5］。</p><p>SPIN 模型检测器也使用布隆过滤器在大规模验证问题时跟踪可达状态空间［6］。</p><p>Google Chrome浏览器使用了布隆过滤器加速安全浏览服务［7］。</p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、数学之美二十一：布隆过滤器（Bloom Filter）：<a href="http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html" target="_blank" rel="noopener">http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分   &lt;/li&gt;
&lt;li&gt;第二部分 &lt;/li&gt;
&lt;li&gt;第三部分 &lt;/li&gt;
&lt;li&gt;参考文献及
      
    
    </summary>
    
      <category term="算法" scheme="https://zjrongxiang.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>布隆过滤算法总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/12/2020-09-13-HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/12/2020-09-13-HDFS小文件合并总结/</id>
    <published>2020-09-12T05:30:00.000Z</published>
    <updated>2020-09-13T14:34:57.503Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分   </li><li>第二部分 </li><li>第三部分 </li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://github.com/confluentinc/kafka-connect-hdfs/issues/271" target="_blank" rel="noopener">https://github.com/confluentinc/kafka-connect-hdfs/issues/271</a></p><p><a href="https://stackoverflow.com/questions/49375691/spark-streaming-to-hive-too-many-small-files-per-partition" target="_blank" rel="noopener">https://stackoverflow.com/questions/49375691/spark-streaming-to-hive-too-many-small-files-per-partition</a></p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、数学之美二十一：布隆过滤器（Bloom Filter）：<a href="http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html" target="_blank" rel="noopener">http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分   &lt;/li&gt;
&lt;li&gt;第二部分 &lt;/li&gt;
&lt;li&gt;第三部分 &lt;/li&gt;
&lt;li&gt;参考文献及
      
    
    </summary>
    
      <category term="算法" scheme="https://zjrongxiang.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>布隆过滤算法总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/12/2020-09-13-Yarn%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/12/2020-09-13-Yarn集群调度原理总结/</id>
    <published>2020-09-12T05:30:00.000Z</published>
    <updated>2020-09-13T15:32:06.504Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分   </li><li>第二部分 </li><li>第三部分 </li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><a href="https://blog.csdn.net/zhanyuanlin/article/details/78799341" target="_blank" rel="noopener">https://blog.csdn.net/zhanyuanlin/article/details/78799341</a></p><p><a href="https://blog.csdn.net/zhanyuanlin/article/details/78799131" target="_blank" rel="noopener">https://blog.csdn.net/zhanyuanlin/article/details/78799131</a></p><p><a href="https://blog.csdn.net/u010770993/article/details/70312473" target="_blank" rel="noopener">https://blog.csdn.net/u010770993/article/details/70312473</a></p><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、数学之美二十一：布隆过滤器（Bloom Filter）：<a href="http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html" target="_blank" rel="noopener">http://www.google.com.hk/ggblog/googlechinablog/2007/07/bloom-filter_7469.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分   &lt;/li&gt;
&lt;li&gt;第二部分 &lt;/li&gt;
&lt;li&gt;第三部分 &lt;/li&gt;
&lt;li&gt;参考文献及
      
    
    </summary>
    
      <category term="算法" scheme="https://zjrongxiang.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>Maven项目中读取properties配置文件总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/03/2020-09-03-Maven%E9%A1%B9%E7%9B%AE%E4%B8%AD%E8%AF%BB%E5%8F%96properties%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/03/2020-09-03-Maven项目中读取properties配置文件总结/</id>
    <published>2020-09-03T05:30:00.000Z</published>
    <updated>2020-10-01T06:26:59.474Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  读取<code>properties</code>配置文件方法</li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在<code>java</code>开发中，通常将配置信息存储在特定的配置文件中，而不是内嵌在程序代码中。即代码可配置化。<code>properties</code>文件以<code>key=value</code>键值对形式表达，结构比较简单，但是难以表达层次，适合小型项目。本文总结汇总了读取<code>properties</code>配置文件方法。</p><h2 id="第一部分-读取properties配置文件方法"><a href="#第一部分-读取properties配置文件方法" class="headerlink" title="第一部分 读取properties配置文件方法"></a>第一部分 读取<code>properties</code>配置文件方法</h2><p>为了讲解方便，我们在<code>maven</code>项目的资源目录<code>resources</code>中创建配置文件<code>application.properties</code>。文件内容为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">username=app</span><br><span class="line">password=password123</span><br></pre></td></tr></table></figure><h3 id="1-1-基于ClassLoder的getResourceAsStream方法读取配置文件"><a href="#1-1-基于ClassLoder的getResourceAsStream方法读取配置文件" class="headerlink" title="1.1 基于ClassLoder的getResourceAsStream方法读取配置文件"></a>1.1 基于<code>ClassLoder</code>的<code>getResourceAsStream</code>方法读取配置文件</h3><p>本方法基于<code>ClassLoder</code>的<code>getResourceAsStream</code>方法，通过类加载器来定位资源，返回<code>InputStream</code>后用<code>Properties</code>对象进行加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        InputStream in = configRead.class</span><br><span class="line">            .getClassLoader().getResourceAsStream(<span class="string">"application.properties"</span>);</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.load(in);</span><br><span class="line">        System.out.println(properties.getProperty(<span class="string">"username"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-2-基于getResourceAsStream-方法读取配置文件"><a href="#1-2-基于getResourceAsStream-方法读取配置文件" class="headerlink" title="1.2 基于getResourceAsStream()方法读取配置文件"></a>1.2 基于<code>getResourceAsStream()</code>方法读取配置文件</h3><p>利用<code>class</code>的<code>getResourceAsStream</code>方法来定位资源文件，并且直接返回<code>InputStream</code>对象，然后通过<code>Properties</code>进行加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      InputStream In =configRead.class</span><br><span class="line">         .getResourceAsStream(<span class="string">"application.properties"</span>);</span><br><span class="line">      Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">      properties.load(in);</span><br><span class="line">      System.out.println(properties.getProperty(<span class="string">"username"</span>));</span><br><span class="line">      <span class="comment">//app</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-3-基于ClassLoader类的getSystemResourceAsStream-静态方法读取配置文件"><a href="#1-3-基于ClassLoader类的getSystemResourceAsStream-静态方法读取配置文件" class="headerlink" title="1.3 基于ClassLoader类的getSystemResourceAsStream()静态方法读取配置文件"></a>1.3 基于<code>ClassLoader</code>类的<code>getSystemResourceAsStream()</code>静态方法读取配置文件</h3><p>使用<code>ClassLoader</code>的<code>getSystemResourceAsStream()</code>静态方法来定位资源，并且返回<code>InputStream</code>，最后用<code>Properties</code>来加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        InputStream in = ClassLoader</span><br><span class="line">            .getSystemResourceAsStream(<span class="string">"application.properties"</span>);</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.load(in);</span><br><span class="line">        System.out.println(properties.getProperty(<span class="string">"username"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-4-基于FileInputStream读取配置文件"><a href="#1-4-基于FileInputStream读取配置文件" class="headerlink" title="1.4 基于FileInputStream读取配置文件"></a>1.4 基于<code>FileInputStream</code>读取配置文件</h3><p>这种方法通过类的路径来定位<code>properties</code>文件资源的路径，然后通过<code>FileInputStream</code>读取流，最后通过<code>java.util.Properties</code>类的<code>load()</code>方法来加载数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        URL url = configRead.class.getClassLoader()</span><br><span class="line">            .getResource(<span class="string">"application.properties"</span>);</span><br><span class="line">        <span class="keyword">if</span> (url != <span class="keyword">null</span>) &#123;</span><br><span class="line">            String fileName = url.getFile();</span><br><span class="line">            InputStream in = <span class="keyword">new</span> BufferedInputStream(</span><br><span class="line">                <span class="keyword">new</span> FileInputStream(fileName));</span><br><span class="line">            Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">            properties.load(in);</span><br><span class="line">            System.out.println(properties.getProperty(<span class="string">"username"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-5-基于ResourceBundle读取配置文件"><a href="#1-5-基于ResourceBundle读取配置文件" class="headerlink" title="1.5 基于ResourceBundle读取配置文件"></a>1.5 基于<code>ResourceBundle</code>读取配置文件</h3><p>利用<code>ResourceBundle</code>来读取<code>properties</code>文件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        ResourceBundle resourceBundle = ResourceBundle</span><br><span class="line">            .getBundle(<span class="string">"application.properties"</span>, locale1);</span><br><span class="line">        System.out.println(resourceBundle.getString(<span class="string">"username"</span>));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-6-基于PropertyResourceBundle读取配置文件"><a href="#1-6-基于PropertyResourceBundle读取配置文件" class="headerlink" title="1.6 基于PropertyResourceBundle读取配置文件"></a>1.6 基于<code>PropertyResourceBundle</code>读取配置文件</h3><p><code>PropertyResourceBundle</code>是<code>ResourceBundle</code>的子类，同样我们也可以利用<code>PropertyResourceBundle</code>来加载配置文件的数据，具体的示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">configRead</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        URL url = configRead.class.getClassLoader().getResource(<span class="string">"application.properties"</span>);</span><br><span class="line">        <span class="keyword">if</span> (url != <span class="keyword">null</span>) &#123;</span><br><span class="line">            InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(url.getFile()));</span><br><span class="line">            ResourceBundle resourceBundle = <span class="keyword">new</span> PropertyResourceBundle(in);</span><br><span class="line">            System.out.println(resourceBundle.getString(<span class="string">"username"</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Properties files，链接：<a href="https://commons.apache.org/proper/commons-configuration/userguide/howto_properties.html" target="_blank" rel="noopener">https://commons.apache.org/proper/commons-configuration/userguide/howto_properties.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  读取&lt;code&gt;properties&lt;/code&gt;配置文件方法&lt;/li&gt;
&lt;li&gt;参考文献及
      
    
    </summary>
    
      <category term="Maven" scheme="https://zjrongxiang.github.io/categories/Maven/"/>
    
    
  </entry>
  
  <entry>
    <title>Spring框架下Kafka交互总结</title>
    <link href="https://zjrongxiang.github.io/2020/09/03/2020-10-01-Java%E4%B8%AD%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E6%80%BB%E7%BB%93/"/>
    <id>https://zjrongxiang.github.io/2020/09/03/2020-10-01-Java中日志处理总结/</id>
    <published>2020-09-03T05:30:00.000Z</published>
    <updated>2020-10-01T09:17:30.976Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>背景</li><li>第一部分  </li><li>参考文献及资料</li></ul><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="https-www-cnblogs-com-qlqwjy-p-9275415-html"><a href="#https-www-cnblogs-com-qlqwjy-p-9275415-html" class="headerlink" title="https://www.cnblogs.com/qlqwjy/p/9275415.html"></a><a href="https://www.cnblogs.com/qlqwjy/p/9275415.html" target="_blank" rel="noopener">https://www.cnblogs.com/qlqwjy/p/9275415.html</a></h3><h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Spring for Apache Kafka，链接：<a href="https://spring.io/projects/spring-kafka" target="_blank" rel="noopener">https://spring.io/projects/spring-kafka</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;第一部分  &lt;/li&gt;
&lt;li&gt;参考文献及资料&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="Java" scheme="https://zjrongxiang.github.io/categories/Java/"/>
    
    
  </entry>
  
</feed>
