<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">



  
  
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="目录 背景 第一部分   Kafka集群加密传输 第二部分   Kafka集群权限认证 第三部分   加密认证集群的客户端 第四部分   加密认证集群的性能压测 第五部分  总结 参考文献及资料  背景Kafka在0.9.0.0版本前没有安全机制功能。Kafka Client程序可以直接获取到Kafka集群元数据信息和Kafka Broker地址后，连接到Kafka集群，然后完全操作集群上的所有t">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka系列文章（第五篇 Kafka安全集群）">
<meta property="og:url" content="https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/index.html">
<meta property="og:site_name" content="RongXiang">
<meta property="og:description" content="目录 背景 第一部分   Kafka集群加密传输 第二部分   Kafka集群权限认证 第三部分   加密认证集群的客户端 第四部分   加密认证集群的性能压测 第五部分  总结 参考文献及资料  背景Kafka在0.9.0.0版本前没有安全机制功能。Kafka Client程序可以直接获取到Kafka集群元数据信息和Kafka Broker地址后，连接到Kafka集群，然后完全操作集群上的所有t">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-10-25T05:13:53.089Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka系列文章（第五篇 Kafka安全集群）">
<meta name="twitter:description" content="目录 背景 第一部分   Kafka集群加密传输 第二部分   Kafka集群权限认证 第三部分   加密认证集群的客户端 第四部分   加密认证集群的性能压测 第五部分  总结 参考文献及资料  背景Kafka在0.9.0.0版本前没有安全机制功能。Kafka Client程序可以直接获取到Kafka集群元数据信息和Kafka Broker地址后，连接到Kafka集群，然后完全操作集群上的所有t">



  <link rel="alternate" href="/atom.xml" title="RongXiang" type="application/atom+xml">




  <link rel="canonical" href="https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Kafka系列文章（第五篇 Kafka安全集群） | RongXiang</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-113063423-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-113063423-1');
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <!-- <a href="https://github.com/zjrongxiang"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png" alt="Fork me on GitHub"></a> -->
    <a href="https://github.com/zjrongxiang"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_green_007200.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">RongXiang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">我的烂笔头</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>日程表</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="rong xiang">
      <meta itemprop="description" content="Keep a Pure Curiosity">
      <meta itemprop="image" content="/images/avatar/person.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RongXiang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kafka系列文章（第五篇 Kafka安全集群）

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-03-02 13:30:00" itemprop="dateCreated datePublished" datetime="2020-03-02T13:30:00+08:00">2020-03-02</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2020-10-25 13:13:53" itemprop="dateModified" datetime="2020-10-25T13:13:53+08:00">2020-10-25</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/#comments" itemprop="discussionUrl">
                
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">106k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">1:36</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>背景</li>
<li>第一部分   Kafka集群加密传输</li>
<li>第二部分   Kafka集群权限认证</li>
<li>第三部分   加密认证集群的客户端</li>
<li>第四部分   加密认证集群的性能压测</li>
<li>第五部分  总结</li>
<li>参考文献及资料</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Kafka在0.9.0.0版本前没有安全机制功能。Kafka Client程序可以直接获取到Kafka集群元数据信息和Kafka Broker地址后，连接到Kafka集群，然后完全操作集群上的所有topic数据资源。另外集群节点间通讯、broker和zookeeper通讯、客户端和集群的网络层通信都是无加密模式。集群的数据存在极大的安全风险。</p>
<p>自0.9.0.0版本开始，Kafka社区逐步添加了较多功能用于提高Kafka群集的安全性。目前Kafka安全集群安全机制主要有三个方面的设置：通信加密（encryption）、身份认证（authentication）和授权（authorization）。</p>
<p>本文重点介绍生产安全集群的一种配置方案。数据通讯传输配置SSL，认证配置SASL，授权通过ACL接口命令来完成的，即：<strong>SSL+SASL/SCRAM+ACL</strong>。</p>
<h2 id="第一部分-Kafka集群加密传输"><a href="#第一部分-Kafka集群加密传输" class="headerlink" title="第一部分   Kafka集群加密传输"></a>第一部分   Kafka集群加密传输</h2><h3 id="1-1-背景知识介绍"><a href="#1-1-背景知识介绍" class="headerlink" title="1.1 背景知识介绍"></a>1.1 背景知识介绍</h3><p>涉及的技术知识不做详细介绍。</p>
<h4 id="1-1-1-密码学基础"><a href="#1-1-1-密码学基础" class="headerlink" title="1.1.1 密码学基础"></a>1.1.1 密码学基础</h4><p>加密算法分为两类：</p>
<ul>
<li><p>对称密钥算法（Symmetric Cryptography）：数据加密和解密时使用相同的密钥。例如常用的DES就是对称加密算法。</p>
</li>
<li><p>非对称密钥算法（Asymmetric Cryptography）：数据加密和解密时使用不同的密钥，分为：公开的公钥（public key）和用户保存的私钥（private key），私钥和公钥在数学上是相关的。利用公钥（或私钥）加密的数据只能用相应的私钥（或公钥）才能解密。举一个例子：客户在银行网银上做一笔交易，首先向银行申请公钥，银行分发公钥给用户，用户使用公钥对请求数据进行加密。银行收到加密数据后通过银行侧保存的私钥进行解密处理，并处理后更新后台数据库。这个通讯过程中银行不需要通过互联网分发私钥。因此保证了私钥的安全。目前最常用的非对称加密算法是RSA算法。</p>
<blockquote>
<p>非对称密钥算法中，私钥来解密公钥加密的数据，公钥来解密私钥加密的数据。</p>
</blockquote>
</li>
</ul>
<p>两种加密算法的比较：</p>
<ul>
<li><p>对称密钥的强度和密钥长度成正比，但是解密效率和密钥长度成反比。另外私钥的分发存在安全风险。</p>
</li>
<li><p>非对称加密保证了私钥的安全性，但是加密和解密的效率比对称加密低。</p>
</li>
</ul>
<p>所以通常加密场景是两种密钥结合使用。使用数据主体使用对称秘钥算法，但是私钥的传输使用非对称算法在互联网环境分发非对称密钥。最常见的就是SSL/TLS。</p>
<h4 id="1-1-2-CA数字证书"><a href="#1-1-2-CA数字证书" class="headerlink" title="1.1.2 CA数字证书"></a>1.1.2 CA数字证书</h4><p>对于非对称密钥算法存在一个安全风险点，那就是公钥的分发存在中间人攻击。还是以客户和银行的通信为例（例子简单化处理）。客户和银行分别有自己的公钥和私钥，私钥各自保留本地。公钥通过互联网分发给对方。那么公钥就是有安全风险的。存在被黑客截取风险。客户向银行申请银行公钥，结果被黑客截取，黑客伪装成银行，返回给用户自己的黑客公钥，用户收到黑客公钥后，将信息加密发给黑客。黑客用黑客私钥进行解密，获取到真实信息。这时候黑客伪装成客户用相同的方法完成和银行的数据交互。这就是中间人攻击的案例。</p>
<p>所以非对称加密算法的公钥传输同样存在风险。当然如果使用原始的离线方式交换密钥是安全的，但是随着互联网通信的爆炸式增长，这是落后低效的。为了保证公钥的真实性和安全性，这时候我们引入第三个角色：公开密钥认证（Public key certificate，简称CA），又称数字证书（digital certificate）或身份证书（identity certificate）。</p>
<p>通常CA是一家第三方权威机构。负责管理和签发证书。整个实现原理也是非对称加密算法：</p>
<ul>
<li>机构将自己的公钥以及身份信息交给CA机构（安全的），CA使用自己的私钥对各机构的公钥进行加密。这个过程称为验签。输出的加密后的公钥及身份信息称为数字证书。</li>
<li>当其他机构请求A机构公钥的时候，返回的是A机构的数字证书。其他机构可以使用CA的公钥对该数字证书中加密公钥进行解密获取A机构的通信公钥。</li>
</ul>
<p>那么新得安全问题又来了，如何保证CA机构的公钥不被伪造？通常CA的公钥是集成在浏览器或者操作系统中，并且被很好的保护起来。</p>
<blockquote>
<p>当然CA证书还涉及更多的安全细节设计（Hash算法防篡改、信任链等大量细节），这里只是简单的介绍。详细介绍可以查看：维基（<a href="https://zh.wikipedia.org/zh-hans/%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84" target="_blank" rel="noopener">证书颁发机构</a>）</p>
</blockquote>
<p>对于企业内部的应用系统就没必要花钱购买CA机构的证书服务了，可以自建 Root CA，自己给自己颁发证书，充当内网的CA机构。当然这时候客户端就需要导入CA的证书了（浏览器和操作系统没有自建的CA证书）。</p>
<h4 id="1-1-3-SSL-TLS加密协议"><a href="#1-1-3-SSL-TLS加密协议" class="headerlink" title="1.1.3 SSL/TLS加密协议"></a>1.1.3 SSL/TLS加密协议</h4><p>SSL（<strong>S</strong>ecure <strong>S</strong>ockets <strong>L</strong>ayer）是一种安全协议，目的是为保障互联网上数据传输安全，利用数据加密技术，确保数据在网络上之传输过程中不会被截取。</p>
<p>从网络协议层看，SSL协议位于TCP/IP协议与应用层协议之间，为数据通讯提供安全支持。SSL协议自身可分为两层： </p>
<ul>
<li>SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 </li>
<li>SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。例如HTTPS就是在HTTP应用层上增加了SSL加密协议支持（HTTP over SSL）。</li>
</ul>
<p>TLS(Transport Layer Security，传输层安全协议)，同样用于两个应用程序之间提供保密性和数据完整性。 TLS 1.0建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本，可以理解为SSL 3.1，即是SSL的升级版。TLS的主要目标是使SSL更安全，并使协议的规范更精确和完善。另外,TLS版本号也与SSL的不同(TLS的版本1.0使用的版本号为SSLv3.1)</p>
<p>SSL通过握手过程在client和server之间协商会话參数，并建立会话。一共有三种方式：</p>
<ul>
<li>仅仅验证server的SSL握手过程（单向SSL）</li>
<li>验证server和client的SSL握手过程（双向SSL）</li>
<li>恢复原有会话的SSL握手过程</li>
</ul>
<p><strong>第一种：</strong>单向SSL通信过程如下（SSL 客户端和SSL 服务端通信）：</p>
<p>(1)SSL客户端向SSL服务端发起请求，请求信息包括SSL版本号、加密算法、密钥交换算法、MAC算法等信息；</p>
<p>(2)SSL服务端确定本次通话的SSL版本和加密套件后，将携带公钥信息的证书回给客户端。如果通话可从重用，还会返回会话ID；</p>
<p>(3)SSL服务端发送Server Hello Done消息。通知SSL客户端版本号和加密套件协商结束，开始进行密钥交换；</p>
<p>(4)SSL客户端对CA证书进行验证，证书合法则继续、不成功弹出选择页面；</p>
<p>(5)SSL客户端生产随机私有对称密钥key，并使用服务端公开密钥进行加密后，发给服务端；</p>
<p>(6)SSL服务端使用自己的私钥解密，获取对称密钥key；</p>
<p>(7)最后SSL客户端与SSL服务端将使用该对称密钥key进行加密通信。</p>
<p><strong>第二种：</strong>单向认证，仅仅是客户端需要检验服务端证书是否是正确的。双向SSL和单向认证几乎一样，只是在客户端认证完服务器证书后，客户端会将自己的证书传给服务器。服务器验证通过后，才开始秘钥协商。</p>
<p><strong>第三种：</strong>协商会话参数、建立会话的过程中，需要使用非对称密钥算法来加密密钥、验证通信对端的身份，计算量较大，占用了大量的系统资源。为了简化SSL握手过程，SSL允许重用已经协商过的会话。即可以重用会话ID。这就是第三种建立会话方式。</p>
<h4 id="1-1-4-Openssl工具"><a href="#1-1-4-Openssl工具" class="headerlink" title="1.1.4 Openssl工具"></a>1.1.4 Openssl工具</h4><p>对于企业内部（内部局域网）的应用系统通讯，如果需要CA证书服务，可以使用Openssl自建CA，并完成证书签发。</p>
<p>先说一下常用密钥类文件的规范：</p>
<ul>
<li><p>后缀名规范</p>
<p>通常约定后缀含义：crt或者cert 表示证书, key表示私钥, req和csr表示请求文件。</p>
</li>
<li><p>文件格式</p>
<p>pem表示pem格式（经过加密的文本文件），der表示der格式（经过加密的二进制文件）。所有证书和私钥可以是pem,也可以是der格式，取决于需要。两个格式可以转换。</p>
</li>
</ul>
<p>Openssl的配置文件（<code>openssl.cnf</code>）定义CA的默认参数，例如<code>ubuntu</code>系统中配置文件位置在<code>/usr/lib/ssl/openssl.cnf</code>。如果不适用默认参数需要在命令中重新指定。</p>
<ul>
<li><p>CA证书的制作</p>
<p>首先生成CA的私钥，使用下面的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl genrsa -out private/ca.key.pem 2048</span></span><br></pre></td></tr></table></figure>
<p><code>private/ca.key.pem</code>是CA私钥,格式为pem，长度（加密位数）为2048。</p>
<blockquote>
<p>前面密码学知识知道CA使用一对密钥的（私钥和公钥），并且两个密钥是数学相关的。公钥可以通过私钥算出来。</p>
</blockquote>
</li>
<li><p>CA证书自签发</p>
<p>参考命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl req -new -x509 -key private/ca.key.pem -out certs/ca.cert.pem</span></span><br></pre></td></tr></table></figure>
<p> <code>certs/ca.cert.pem</code> 即CA的自签证书。部署导入到客户端（例如浏览器）。</p>
</li>
<li><p>用户证书签发</p>
<p>用户证书的签发和CA自签相同，用户证书由CA私钥签发。用户需要提供请求文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl ca -<span class="keyword">in</span> app.csr -out app.crt -days 365</span></span><br></pre></td></tr></table></figure>
<p><code>app.crt</code>为签发的证书。部署在应用服务器上。</p>
</li>
</ul>
<h4 id="1-1-5-Keytool工具介绍"><a href="#1-1-5-Keytool工具介绍" class="headerlink" title="1.1.5 Keytool工具介绍"></a>1.1.5 Keytool工具介绍</h4><p>在密钥证书管理时，通常使用JAVA的Keytool工具程序。Keytool 是一个JAVA数据证书的管理工具 ,Keytool 将密钥（key）和证书（certificates）存在一个称为keystore的文件中，通常称为密钥库文件。文件的扩展名通常使用：jks，全名java key store file。</p>
<p>Keytool是一个Java数据证书的管理工具，所以节点需要配置JAVA_HOME环境变量。</p>
<p>这里列举了命令支持的参数含义及注意点（供后续使用查阅）：</p>
<ul>
<li>keystore 参数指定保存证书的文件（密钥库二进制文件）。密钥库文件包含证书的私钥，必须对其进行安全保存。</li>
<li>validity 参数指定密钥有效期，单位是天。默认为90天。</li>
<li>keyalg 参数指定密钥使用的加密算法（例如RSA，如果不指定默认采用DSA）。</li>
<li>keysize 参数指定密钥的长度。该参数是选项参数，默认长度是1024位。为了保证密钥安全强度，建议密码长度设置为2048位。</li>
<li>keypass 参数指定生成密钥的密码（私钥密码）。</li>
<li>storepass 指定密钥库的密码(获取keystore信息所需的密码)。另外密钥库创建后，要对其做任何修改都必须提供该密码，以便访问密钥库。</li>
<li>alias 参数指定密钥别名。每个密钥文件有一个唯一的别名，别名不区分大小写。</li>
<li>dname 参数指定证书拥有者信息。例如： “CN=名字与姓氏,OU=组织单位名称,O=组织名称,L=城市或区域名称,ST=州或省份名称,C=单位的两字母国家代码”。</li>
<li>list 参数显示密钥库中的证书信息。keytool -list -v -keystore 指定keystore -storepass 密码</li>
<li>v 参数显示密钥库中的证书详细信息。</li>
<li>export 将别名指定的证书导出到文件。keytool -export -alias 需要导出的别名 -keystore 指定keystore -file 指定导出的证书位置及证书名称 -storepass 密码。</li>
<li>file  参数指定导出到文件的文件名。</li>
<li>delete   删除密钥库中某条目。keytool -delete -alias 指定需删除的别名 -keystore 指定keystore -storepass 密码</li>
<li>printcert  查看导出的证书信息。keytool -printcert -file yushan.crt</li>
<li>keypasswd   修改密钥库中指定条目口令。keytool -keypasswd -alias 需修改的别名 -keypass 旧密码 -new 新密码 -storepass keystore密码 -keystore sage</li>
<li>storepasswd 修改keystore口令。keytool -storepasswd -keystore e:/yushan.keystore(需修改口令的keystore) -storepass 123456(原始密码) -new newpasswd(新密码)</li>
<li>import   将已签名数字证书导入密钥库。keytool -import -alias 指定导入条目的别名 -keystore 指定keystore -file 需导入的证书</li>
</ul>
<blockquote>
<p>关于Keytool工具的详细介绍，可以参考<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html" target="_blank" rel="noopener">oracle的官网</a>。</p>
</blockquote>
<h3 id="1-2-Kafka集群配置SSL加密"><a href="#1-2-Kafka集群配置SSL加密" class="headerlink" title="1.2 Kafka集群配置SSL加密"></a>1.2 Kafka集群配置SSL加密</h3><p>Apache Kafka允许客户端通过SSL连接。默认情况下，SSL是禁用的，可以根据需要打开。</p>
<h4 id="1-2-1-集群环境准备"><a href="#1-2-1-集群环境准备" class="headerlink" title="1.2.1 集群环境准备"></a>1.2.1 集群环境准备</h4><p>为了后文讲解方便，我们部署了Kafka集群（3节点）和Zookeeper集群（3节点）测试环境。其中zookeeper和kafka混合部署。</p>
<table>
<thead>
<tr>
<th>节点编号</th>
<th>hostname</th>
<th>IP地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>kafka.app.node1</td>
<td>192.168.1.5</td>
</tr>
<tr>
<td>2</td>
<td>kafka.app.node2</td>
<td>192.168.1.6</td>
</tr>
<tr>
<td>3</td>
<td>kafka.app.node3</td>
<td>192.168.1.7</td>
</tr>
</tbody>
</table>
<p>Kafka集群节点对外服务端口为：9092；Zookeeper集群节点对外服务端口为：2181。</p>
<h4 id="1-2-2-配置主机名验证"><a href="#1-2-2-配置主机名验证" class="headerlink" title="1.2.2 配置主机名验证"></a>1.2.2 配置主机名验证</h4><p>从Kafka 2.0.0版开始，默认会为客户端连接以及broker之间的连接启用服务器的主机名验证（SSL端点识别算法），以防止中间人攻击。可以通过设置参数<code>ssl.endpoint.identification.algorithm</code>为空字符串来禁用服务器主机名验证。例如:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssl.endpoint.identification.algorithm=</span><br></pre></td></tr></table></figure>
<p>另外高版本支持不停集群服务下，进行动态配置，使用脚本<code>kafka-configs.sh</code>，参考命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-configs.sh --bootstrap-server localhost:9093 --entity-type brokers --entity-name 0 --alter --add-config "listener.name.internal.ssl.endpoint.identification.algorithm="</span><br></pre></td></tr></table></figure>
<p>对于较旧的Kafka版本，<code>ssl.endpoint.identification.algorithm</code>默认情况下未定义，因此不会启用主机名验证。若该属性设置<code>HTTPS</code>，则启用主机名验证，例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssl.endpoint.identification.algorithm=HTTPS</span><br></pre></td></tr></table></figure>
<p>需要注意的是，一旦启用主机名验证，客户端将根据以下两个字段之一验证服务器的完全限定域名（FQDN）：</p>
<ul>
<li><p>通用名称（CN，Common Name）</p>
</li>
<li><p>主题备用名称（SAN，Subject Alternative Name）</p>
</li>
</ul>
<p>两个字段都有效，但RFC-2818建议使用SAN。 SAN也更灵活，允许声明多个DNS条目。 另一个优点是，CN可以设置为更有意义的值用于授权。如要添加SAN字段，需要将以下参数<code>-ext SAN = DNS：{FQDN}</code>添加到<code>keytool</code>命令中，例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore server.keystore.jks -<span class="built_in">alias</span> localhost -validity &#123;validity&#125; -genkey -keyalg RSA -ext SAN=DNS:&#123;FQDN&#125;</span></span><br></pre></td></tr></table></figure>
<p>更通俗一点讲，SSL 握手期间验证主机名时，它会检查服务器证书是否具有 SAN 集。如果检测到 SAN 集，那么只使用 SAN 集中的名称或 IP 地址。如果未检测到 SAN 集，那么只使用主题专有名称 (DN) 最重要的属性，通常是通用名称(CN)。将该值与客户端尝试连接的服务器启的主机名进行比较。如果它们相同，主机名验证成功，允许建立连接。</p>
<h4 id="1-2-3-生成SSL密钥和证书（密钥库）"><a href="#1-2-3-生成SSL密钥和证书（密钥库）" class="headerlink" title="1.2.3 生成SSL密钥和证书（密钥库）"></a>1.2.3 生成SSL密钥和证书（密钥库）</h4><p>为了方便管理证书密钥，我们使用统一的路径保存。例如统一放在<code>/usr/ca</code>作为文件目录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir -p /usr/ca/&#123;root,server,client,trust&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里各文件夹的功能是：root：存储CA私钥和证书；server：存储服务端的私钥和证书；client：存储客户端私钥和证书；trust：存储信任库文件；</p>
</blockquote>
<ul>
<li><strong>节点1（kafka.app.node1）</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> kafka.app -validity 3650 -genkey -keypass app123 -keyalg RSA -dname <span class="string">"CN=kafka.app.node1,OU=depart,O=org,L=shanghai,S=shanghai,C=cn"</span> -storepass app123 -ext SAN=DNS:kafka.app.node1</span></span><br></pre></td></tr></table></figure>
<p>  其中<code>dname</code>参数的含义参考<code>Keytool</code>工具介绍，文件名为：<code>server.keystore.jks</code>，这是密钥库。</p>
<ul>
<li><strong>节点2（kafka.app.node2）</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> kafka.app -validity 3650 -genkey -keypass app123 -keyalg RSA -dname <span class="string">"CN=kafka.app.node1,OU=depart,O=org,L=shanghai,S=shanghai,C=cn"</span> -storepass app123 -ext SAN=DNS:kafka.app.node2</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>节点3（kafka.app.node3）</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> kafka.app -validity 3650 -genkey -keypass app123 -keyalg RSA -dname <span class="string">"CN=kafka.app.node1,OU=depart,O=org,L=shanghai,S=shanghai,C=cn"</span> -storepass app123 -ext SAN=DNS:kafka.app.node3</span></span><br></pre></td></tr></table></figure>
<p>证书生成后可以通过下面的命令进行查询（需要输入密钥库管理密码，即<code>keypass</code>的参数）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -list -v -keystore server.keystore.jks</span></span><br></pre></td></tr></table></figure>
<h4 id="1-2-4-创建Kafka集群CA证书"><a href="#1-2-4-创建Kafka集群CA证书" class="headerlink" title="1.2.4 创建Kafka集群CA证书"></a>1.2.4 创建Kafka集群CA证书</h4><p>集群中每个服务节点都有一对公钥和私钥，以及用于标识该节点的证书。但这个证书是未签名的，存在中间者攻击的风险。所以需要证书颁发机构（CA）负责签署颁发证书，使用<code>openssl</code>工具实现。</p>
<p>同一个集群的所有节点共用一个CA证书，所以只需要在集群的一个节点（集群外节点均可）生成CA证书，然后分发给集群其他节点。例如在<code>kafka.app.node1</code>节点上创建CA证书，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl req -new -x509 -keyout /usr/ca/root/ca.key.pem -out /usr/ca/root/ca.cert.pem -days 3650 -passout pass:app123 -subj <span class="string">"/C=cn/ST=shanghai/L=shanghai/O=org/OU=depart/CN=kafka.app.node1"</span></span></span><br></pre></td></tr></table></figure>
<p>然后使用<code>scp</code>命令分发给其他节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> scp /usr/ca/root/* root@kafka.app.node2:/usr/ca/root/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> scp /usr/ca/root/* root@kafka.app.node3:/usr/ca/root/</span></span><br></pre></td></tr></table></figure>
<p>生成两个文件，分别是私钥（ca.key.pem）和证书（ca.cert.pem），它用来签署其他证书。</p>
<h4 id="1-2-5-集群服务节点签署证书"><a href="#1-2-5-集群服务节点签署证书" class="headerlink" title="1.2.5 集群服务节点签署证书"></a>1.2.5 集群服务节点签署证书</h4><p>首先给集群各服务节点签发证书（即签名）。步骤如下：</p>
<ul>
<li>第一步 从密钥容器中提取和导出服务端证书（输出文件：server.cert-file，未签名）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> kafka.itdw -certreq -file /usr/ca/server/server.cert-file -storepass app123</span></span><br></pre></td></tr></table></figure>
<ul>
<li>第二步 给服务端证书签名（输出文件：server.cert-signed，已签名）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl x509 -req -CA /usr/ca/root/ca.cert.pem -CAkey /usr/ca/root/ca.key.pem -<span class="keyword">in</span> /usr/ca/server/server.cert-file -out /usr/ca/server/server.cert-signed -days 365 -CAcreateserial -passin pass:app123</span></span><br></pre></td></tr></table></figure>
<ul>
<li>第三步 将CA证书导入服务端密钥容器中</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> CARoot -import -file /usr/ca/root/ca.cert.pem -storepass app123</span></span><br></pre></td></tr></table></figure>
<ul>
<li>第四步 将已签名的证书导入密钥容器中</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/server/server.keystore.jks -<span class="built_in">alias</span> kafka.app -import -file /usr/ca/server/server.cert-signed -storepass app123</span></span><br></pre></td></tr></table></figure>
<p>需要注意集群上每个服务节点均需要签署。</p>
<h4 id="1-2-6-生成服务端信任库"><a href="#1-2-6-生成服务端信任库" class="headerlink" title="1.2.6 生成服务端信任库"></a>1.2.6 生成服务端信任库</h4><p>如果kafka集群中配置中的参数<code>ssl.client.auth</code>设置为： <code>requested</code>或<code>required</code>，需要为集群节点提供一个信任库，这个库中需要包含所有CA证书。</p>
<p>使用下面的命令将CA证书导入服务端信任库，输出为信任库文件：<code>server.truststore.jks</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/trust/server.truststore.jks -<span class="built_in">alias</span> CARoot -import -file /usr/ca/root/ca.cert.pem -storepass app123</span></span><br></pre></td></tr></table></figure>
<p>将CA证书导入服务端信任库，意味着信任该CA证书签名的所有证书。此属性称为信任链，在大型Kafka群集上部署SSL时特别有用。您可以使用单个CA对群集中的所有证书进行签名，并使所有计算机共享信任该CA的同一信任库。这样，所有计算机都可以对所有其他计算机进行身份验证。</p>
<h4 id="1-2-7-配置Kafka-Brokers"><a href="#1-2-7-配置Kafka-Brokers" class="headerlink" title="1.2.7 配置Kafka Brokers"></a>1.2.7 配置Kafka Brokers</h4><p>Kafka Broker节点支持侦听多个端口上的连接。在server.properties中配置，多个端口类型使用逗号分隔，我们以集群中<code>kafka.app.node1</code>为例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listeners=SSL://kafka.app.node1:9092</span><br></pre></td></tr></table></figure>
<p>代理端需要以下SSL配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssl.keystore.location=/usr/ca/server/server.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/server.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br></pre></td></tr></table></figure>
<p>其他可选配置设置：</p>
<ul>
<li><p><code>ssl.client.auth</code>（可选）</p>
<p>参数控制SSL认证模式。默认参数值为<code>requested</code>，默认使用单向认证，即客户端认证Kafka brokers。此时，没有证书的客户端仍然可以连接集群。参数值为<code>required</code>，指定开启双向验证(2-way authentication)。Kafka服务器同时会验证客户端证书。生成集群建议开始双向认证。</p>
</li>
<li><p><code>ssl.cipher.suites</code>（可选）</p>
<p>密码套件是认证，加密，MAC和密钥交换算法的命名组合，用于协商使用TLS或SSL网络协议的网络连接的安全设置。（默认为空列表）</p>
</li>
<li><p><code>ssl.enabled.protocols</code></p>
<p>建议参数值为<code>TLSv1.2,TLSv1.1,TLSv1</code>。列出支持的SSL协议。生成环境不建议使用SSL，建议使用TLS。</p>
</li>
<li><p><code>ssl.keystore.type</code>和<code></code>ssl.truststore.type`</p>
<p>文件格式：<code>JKS</code></p>
</li>
<li><p><code>security.inter.broker.protocol</code>参数</p>
<p>kafka集群节点（brokers）之间启用<code>SSL</code>通讯，需要配置该配置参数为：<code>SSL</code>。</p>
</li>
</ul>
<p>最后我们总结合并一下所有的配置参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">listeners=SSL://kafka.app.node1:9092</span><br><span class="line">ssl.keystore.location=/usr/ca/server/server.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/server.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br><span class="line">ssl.client.auth=required</span><br><span class="line">ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1</span><br><span class="line">ssl.keystore.type=JKS </span><br><span class="line">ssl.truststore.type=JKS </span><br><span class="line">ssl.endpoint.identification.algorithm=HTTPS</span><br><span class="line">security.inter.broker.protocol=SSL</span><br></pre></td></tr></table></figure>
<h4 id="1-2-8-初步验证"><a href="#1-2-8-初步验证" class="headerlink" title="1.2.8 初步验证"></a>1.2.8 初步验证</h4><p>正常启动集群的Zookeeper集群，然后依次启动集群的所有节点。使用下面的命令检查：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl s_client -debug -connect kafka.app.node1:9092 -tls1</span></span><br></pre></td></tr></table></figure>
<p>该命令检查服务器的密钥库和信任库是否正确设置。命令中<code>tls1</code>必须是集群配置参数<code>ssl.enabled.protocols</code>所支持的协议。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">Certificate chain</span><br><span class="line">（省略）</span><br><span class="line">---</span><br><span class="line">Server certificate</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">（省略）</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line">subject=（省略）</span><br><span class="line">issuer=（省略）</span><br><span class="line">---</span><br><span class="line">No client certificate CA names sent</span><br><span class="line">---</span><br><span class="line">SSL handshake has read 2029 bytes and written 264 bytes</span><br><span class="line">---</span><br><span class="line">New, TLSv1/SSLv3, Cipher is ECDHE-RSA-DES-CBC3-SHA</span><br><span class="line">Server public key is 2048 bit</span><br><span class="line">Secure Renegotiation IS supported</span><br><span class="line">Compression: NONE</span><br><span class="line">Expansion: NONE</span><br><span class="line">SSL-Session:</span><br><span class="line">    Protocol  : TLSv1</span><br><span class="line">    Cipher    : ECDHE-RSA-DES-CBC3-SHA</span><br><span class="line">    Session-ID: 5E580D610AEB5DDD8BCD0D31E88180F45391109792CA3CDD1E861EB87C704261</span><br><span class="line">    Session-ID-ctx: </span><br><span class="line">    Master-Key: E544FF34B993B2C3B7F7CB28D8166213F8D3A9864A82247F6948E33B319CD1A8943127DDF9B528EA73435EBC73B0DD55</span><br><span class="line">    Key-Arg   : None</span><br><span class="line">    Start Time: 1582828897</span><br><span class="line">    Timeout   : 7200 (sec)</span><br><span class="line">    Verify return code: 7 (certificate signature failure)</span><br><span class="line">---</span><br><span class="line">（省略）</span><br></pre></td></tr></table></figure>
<p>如果证书未显示或有其他错误消息，则说明设置不正确。</p>
<blockquote>
<p>另外对于’OpenSSL 0.9.8j-fips 07 Jan 2009’版本的openssl版本，由于这个版本不能自己检测出ssl的版本。会报下面的错误信息。</p>
<p>1816:error:1408E0F4:SSL routines:SSL3_GET_MESSAGE:unexpected message:s3_both.c:463:</p>
</blockquote>
<h3 id="1-3-配置kafka客户端"><a href="#1-3-配置kafka客户端" class="headerlink" title="1.3 配置kafka客户端"></a>1.3 配置kafka客户端</h3><p>kafka集群需要支持集群内外的客户端交互访问。安全集群的客户端同样需要进行相关安全配置。这里客户端指的是Console客户端。</p>
<h4 id="1-3-1-签发客户端证书"><a href="#1-3-1-签发客户端证书" class="headerlink" title="1.3.1 签发客户端证书"></a>1.3.1 签发客户端证书</h4><p>类似集群内部服务端的证书签发步骤，客户端证书签发过程入下：</p>
<ul>
<li><p>生成客户端SSL密钥和证书，输出密钥容器：<code>client.keystore.jks</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/client/client.keystore.jks -<span class="built_in">alias</span> kafka.app</span></span><br><span class="line">.node1 -validity 365 -genkey -keypass app123 -keyalg RSA -dname "CN=kafka.app.node1,OU=dccsh,O=icbc,L=shanghai,S=shanghai,C=cn" -ext SAN=DNS:kafka.app.node1 -storepass app123</span><br></pre></td></tr></table></figure>
</li>
<li><p>从密钥容器中提取和导出客户端证书（输出文件：client.cert-file，未签名）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/client/client.keystore.jks -<span class="built_in">alias</span> kafka.app.node1 -certreq -file /usr/ca/client/client.cert-file -storepass app123</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>给客户端证书签名（输出文件：client.cert-signed，已签名）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl x509 -req -CA /usr/ca/root/ca.cert.pem -CAkey /usr/ca/root/ca.key.pem -<span class="keyword">in</span> /usr/ca/client/client.cert-file -out /usr/ca/client/client.cert-signed -days 365 -CAcreateserial -passin pass:app123</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将CA证书导入客户端密钥容器中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/client/client.keystore.jks -<span class="built_in">alias</span> CARoot -import -file /usr/ca/root/client.cert-file -storepass app123</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将已签名的证书导入密钥容器中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/client/client.keystore.jks -<span class="built_in">alias</span> kafka.app.node1 -import -file /usr/ca/client/client.cert-signed -storepass app123</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="1-3-2-生成客户端信任库"><a href="#1-3-2-生成客户端信任库" class="headerlink" title="1.3.2 生成客户端信任库"></a>1.3.2 生成客户端信任库</h4><p>使用下面的命令将CA证书导入客户端信任库，输出为信任库文件：<code>client.truststore.jks</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -keystore /usr/ca/trust/client.truststore.jks -<span class="built_in">alias</span> CARoot -import -file /usr/ca/root/ca.cert.pem -storepass app123</span></span><br></pre></td></tr></table></figure>
<h4 id="1-3-3-配置客户端"><a href="#1-3-3-配置客户端" class="headerlink" title="1.3.3 配置客户端"></a>1.3.3 配置客户端</h4><p>客户端的console-producer和console-consumer命令需要添加相关安全配置。</p>
<p>如果kafka集群不需要客户端身份验证，只需配置下面的配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SSL</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/client.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br></pre></td></tr></table></figure>
<p>如果需要客户端身份验证，还需要补充下面的配置信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssl.keystore.location=/usr/ca/client/client.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br></pre></td></tr></table></figure>
<p>根据我们的要求和代理配置，可能还需要其他配置设置：</p>
<ol>
<li>ssl.provider（可选）。用于SSL连接的安全提供程序的名称。</li>
<li>ssl.cipher.suites（可选）。密码套件是认证，加密，MAC和密钥交换算法的命名组合，用于协商使用TLS或SSL网络协议的网络连接的安全设置。</li>
<li>ssl.enabled.protocols = TLSv1.2，TLSv1.1，TLSv1。它应列出在代理方配置的至少一种协议</li>
<li>ssl.truststore.type = JKS</li>
<li>ssl.keystore.type = JKS</li>
</ol>
<p>最后我们总结合并一下所有的配置参数（编辑文件名为：<code>client-ssl.properties</code>）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SSL</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/client.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br><span class="line">ssl.keystore.location=/usr/ca/client/client.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br></pre></td></tr></table></figure>
<h4 id="1-3-4-消费者生产者"><a href="#1-3-4-消费者生产者" class="headerlink" title="1.3.4 消费者生产者"></a>1.3.4 消费者生产者</h4><p>使用console-producer的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list kafka.app.node1:9092,kafka.app.node2:9092,kafka.app.node3:9092 --topic test --producer.config client-ssl.properties</span><br></pre></td></tr></table></figure>
<p>使用console-consumer的命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server kafka.app.node1:9092,kafka.app.node2:9092,kafka.app.node3:9092 --topic test --new-consumer --consumer.config client-ssl.properties</span><br></pre></td></tr></table></figure>
<p>这里<code>test</code>为<code>topic</code>名称，在只有SSL通信加密集群中，topic的创建、删除、生产、消费并没有权限管理，依然存在安全问题。所以kafka集群需要进一步配置权限管理。</p>
<h2 id="第二部分-Kafka集群权限认证"><a href="#第二部分-Kafka集群权限认证" class="headerlink" title="第二部分 Kafka集群权限认证"></a>第二部分 Kafka集群权限认证</h2><p>Kafka集群的权限认证管理主要涉及：</p>
<ul>
<li>身份认证（Authentication）。对客户端与服务器的连接进行身份认证，brokers和zookeeper之间的连接进行Authentication（producer 和 consumer）、其他 brokers、tools与 brokers 之间连接的认证。</li>
<li>权限控制（Authorization）。实现对于消息级别的权限控制，客户端的读写操作进行Authorization（生产、消费）管理。</li>
</ul>
<p>通俗的讲，身份认证解决的是证明你是谁，而权限控制解决的是你能干什么。在Kafka中身份认证和权限控制是两套独立的安全配置。</p>
<h3 id="2-1-集群权限认证策略"><a href="#2-1-集群权限认证策略" class="headerlink" title="2.1 集群权限认证策略"></a>2.1 集群权限认证策略</h3><p>Kafka从0.9.0.0版本后开始支持下面的SASL安全策略管理。这些安全功能为Kafka通信安全、多租户管理、集群云化提供了安全保障。截止目前Kafka 2.3版本，一共支持5种SASL方式。</p>
<table>
<thead>
<tr>
<th>验证方式</th>
<th>版本</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>SASL/PLAIN</td>
<td>0.10.0.0</td>
<td>不能动态增加用户</td>
</tr>
<tr>
<td>SASL/SCRAM</td>
<td>0.10.2.0</td>
<td>可以动态增加用户。有两种方式：SASL/SCRAM-SHA-256 和SASL/SCRAM-SHA-512</td>
</tr>
<tr>
<td>SASL/GSSAPI</td>
<td>0.9.0.0</td>
<td>需要独立部署验证服务（即Kerberos服务）</td>
</tr>
<tr>
<td>SASL/OAUTHBEARER</td>
<td>2.0.0</td>
<td>需自己实现接口实现token的创建和验证，需要额外Oauth服务</td>
</tr>
<tr>
<td>SASL/Delegation Token</td>
<td>1.1.0</td>
<td>补充现有 SASL 机制的轻量级认证机制</td>
</tr>
</tbody>
</table>
<p>对于生产环境，SASL/PLAIN方式有个缺点：只能在JAAS文件KafkaServer参数中配置用户，集群运行期间无法动态新增用户（需要重启重新加载JAAS文件），这对维护管理带来不便。而SASL/SCRAM方式，将认证数据存储在Zookeeper中，可以动态新增用户并分配权限。</p>
<p>SASL/GSSAPI方式需要依赖Kerberos服务。对于一些已经部署了集中式的Kerberos服务的大厂，只需要申请一个principal即可。如果生产Kerberos认证中出现TGT分发性能瓶颈，可以使用SASL/Delegation Token模式。使用 Kafka 提供的 API 去获取对应的 Delegation Token。Broker 和客户端在做认证的时候，可以直接使用这个 token，不用每次都去 KDC 获取对应的 ticket（Kerberos 认证），减少性能压力。</p>
<p>同样SASL/OAUTHBEARER方式需要Oauth服务。</p>
<p>各种方式引入版本不同，使用依赖各有差异，需要结合自身业务特点选择合适的架构方式。</p>
<h3 id="2-2-SASL-SCRAM策略配置介绍"><a href="#2-2-SASL-SCRAM策略配置介绍" class="headerlink" title="2.2 SASL/SCRAM策略配置介绍"></a>2.2 SASL/SCRAM策略配置介绍</h3><p>SASL/SCRAM方式将身份认证和权限控制的凭证（credential）数据均存储在Zookeeper中，需要对Zookeeper进行安全配置。</p>
<h4 id="2-2-1-Zookeeper集群侧配置"><a href="#2-2-1-Zookeeper集群侧配置" class="headerlink" title="2.2.1 Zookeeper集群侧配置"></a>2.2.1 Zookeeper集群侧配置</h4><p>对Zookeeper集群中所有节点更新下面的策略后，重启集群生效。</p>
<ul>
<li><p>配置<code>zoo.cfg</code>文件</p>
<p>文件尾部追加下面的配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider</span><br><span class="line">requireClientAuthScheme=sasl</span><br><span class="line">jaasLoginRenew=3600000</span><br></pre></td></tr></table></figure>
</li>
<li><p>新增<code>zk_server_jaas.conf</code>文件</p>
<p>配置文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Server &#123;</span><br><span class="line">org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">username="admin"</span><br><span class="line">password="admin-secret"</span><br><span class="line">user_admin="admin-secret;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中<code>username</code>和<code>password</code>定义的用户和密钥，用于Zookeeper与Kafka集群进行认证。配置项<code>user_admin=&quot;admin-secret&quot;</code> 中 admin为用户名，admin-secret为密码，用于Zookeeper集群外客户端和集群内进行认证。</p>
</li>
<li><p>拷贝依赖包</p>
<p>将kafka文件系统中<code>kafka/libs</code>目录下的jar包拷贝到<code>zookeeper/lib</code>目录。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-clients-2.1.1.jar</span><br><span class="line">lz4-java-1.5.0.jar</span><br><span class="line">osgi-resource-locator-1.0.1.jar</span><br><span class="line">slf4j-api-1.7.25.jar</span><br><span class="line">snappy-java-1.1.7.2.jar</span><br></pre></td></tr></table></figure>
<blockquote>
<p>若没有引入依赖包，启动时会报找不到org.apache.kafka.common.security.plain.PlainLoginModule包的错误。</p>
</blockquote>
</li>
<li><p>修改zookeeper启动参数</p>
<p>修改<code>bin/zkEnv.sh</code>文件, 在文件尾追加下面的配置内容。该配置完成引入的包的加载。变量<code>CLASSPATH</code>和<code>SERVER_JVMFLAGS</code>都会在Zookeeper启动时传给<code>JVM</code>虚拟机。</p>
<blockquote>
<p>下面的配置中<code>$ZOOKEEPER_HOME</code>是zookeeper的环境变量，如果没有配置，使用绝对路径即可。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in $ZOOKEEPER_HOME/lib/*.jar; do</span><br><span class="line">   CLASSPATH="$i:$CLASSPATH"</span><br><span class="line">done</span><br><span class="line">SERVER_JVMFLAGS=" -Djava.security.auth.login.config=$ZOOKEEPER_HOME/conf/zk_server_jaas.conf"</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="2-2-2-kafka集群侧配置"><a href="#2-2-2-kafka集群侧配置" class="headerlink" title="2.2.2 kafka集群侧配置"></a>2.2.2 kafka集群侧配置</h4><p>kafka集群中每一台节点均需要更新下面的配置。</p>
<ul>
<li><p>新增<code>kafka_server_scram_jaas.conf</code>文件（在<code>config</code>目录中）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">KafkaServer &#123;</span><br><span class="line">org.apache.kafka.common.security.scram.ScramLoginModule required</span><br><span class="line">username="admin"</span><br><span class="line">password="admin-secret";</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自定义用户：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> user_admin=<span class="string">"admin-secret"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> user_alice=<span class="string">"alice-secret"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> user_reader=<span class="string">"reader-secret"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> user_writer=<span class="string">"writer-secret"</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其中配置<code>username</code>和<code>password</code>为Kafka集群之间通讯的SCRAM凭证，用户名为<code>admin</code>，密码为<code>admin-secret</code>。</p>
<p>  配置中类似<code>user_XXX</code>格式的配置项为自定义用户。如果是SASL/PLAIN方式，用户只能在该文件中定义，不能动态新增。我们使用SASL/SCRAM方式，可以后续动态声明admin用户，不再此处进行配置。</p>
<ul>
<li><p>更新Kafka的配置文件<code>server.properties</code>（在<code>config</code>目录中）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">SASL CONFIG</span></span><br><span class="line">listeners=SASL_SSL://kafka.app.node1:9092</span><br><span class="line">sasl.enabled.mechanisms=SCRAM-SHA-512</span><br><span class="line">sasl.mechanism.inter.broker.protocol=SCRAM-SHA-512</span><br><span class="line">authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer</span><br><span class="line"><span class="meta">#</span><span class="bash">allow.everyone.if.no.acl.found=<span class="literal">true</span></span></span><br><span class="line">super.users=User:admin</span><br><span class="line"><span class="meta">#</span><span class="bash">SSL CINFIG</span></span><br><span class="line">ssl.keystore.location=/usr/ca/server/server.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/server.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br><span class="line">ssl.client.auth=required</span><br><span class="line">ssl.enabled.protocols=TLSv1.2,TLSv1.1,TLSv1</span><br><span class="line">ssl.keystore.type=JKS</span><br><span class="line">ssl.truststore.type=JKS</span><br><span class="line">ssl.endpoint.identification.algorithm=HTTPS</span><br><span class="line">security.inter.broker.protocol=SASL_SSL</span><br></pre></td></tr></table></figure>
<p>需要注意参数<code>allow.everyone.if.no.acl.found</code>，如果开启参数开关，当客户端和集群交互时候未找到ACL策略时，允许所有类型的访问操作。建议该参数关闭（false）。</p>
<p>参数<code>security.inter.broker.protocol</code>指定集群brokers之间的通讯协议。不加密协议有：SASL_SSL、SASL_PLAINTEXT、PLAINTEXT；加密协议有：SSL。为了提高节点之间的交互性能，内部网络环境建议使用非加密协议。这里使用加密的<code>SASL_SSL</code>协议。</p>
<p>参数<code>super.users</code>指定了集群的超级用户为：<code>admin</code>。注意如果指定多个超级用户，每个用户使用分号隔开，例如：<code>super.users=User:admin;User:alice</code></p>
<p>参数<code>sasl.enabled.mechanisms</code>列出支持的认证方式。即可以支持多种。</p>
<p>参数<code>sasl.mechanism.inter.broker.protocol</code>指定集群内部的认证方式。Kafka仅支持最小迭代次数为4096的强哈希函数SHA-256和SHA-512。所以有SCRAM-SHA-512和SCRAM-SHA-256两种方式。</p>
</li>
<li><p>配置kafka启动环境变量（<code>bin</code>目录下面的<code>kafka-run-class.sh</code>）</p>
<p>为 Kafka 添加 java.security.auth.login.config 环境变量（配置文件路径）。并且在启动模式中添加<code>KAFKA_SASL_OPTS</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 截取配置文件片段：</span></span><br><span class="line">KAFKA_SASL_OPTS='-Djava.security.auth.login.config=/opt/software/kafka/config/kafka_server_scram_jaas.conf'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Launch mode</span></span><br><span class="line">if [ "x$DAEMON_MODE" = "xtrue" ]; then</span><br><span class="line">  nohup $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_SASL_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@" &gt; "$CONSOLE_OUTPUT_FILE" 2&gt;&amp;1 &lt; /dev/null &amp;</span><br><span class="line">else</span><br><span class="line">  exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_SASL_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="2-2-3-SCRAM认证管理"><a href="#2-2-3-SCRAM认证管理" class="headerlink" title="2.2.3 SCRAM认证管理"></a>2.2.3 SCRAM认证管理</h4><p>在集群的配置文件<code>kafka_server_scram_jaas.conf</code>中，定义了集群内部的认证用户。对于客户端和集群之间认证可以使用<code>kafka-configs.sh</code>来动态创建。</p>
<ul>
<li><p>创建用户SCRAM凭证</p>
<p>例如集群中的超级用户<code>admin</code>用户，使用下面的命令创建：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kafka-configs.sh --zookeeper kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --alter --add-config <span class="string">'SCRAM-SHA-256=[password=admin-secret],SCRAM-SHA-512=[password=admin-secret]'</span> --entity-type users --entity-name admin</span></span><br></pre></td></tr></table></figure>
<p>创建自定义普通用户<code>alice</code>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kafka-configs.sh --zookeeper kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --alter --add-config <span class="string">'SCRAM-SHA-256=[iterations=8192,password=alice-secret],SCRAM-SHA-512=[password=alice-secret]'</span> --entity-type users --entity-name alice</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看SCARM凭证</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kafka-configs.sh --zookeeper kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --describe --entity-type users --entity-name admin</span></span><br></pre></td></tr></table></figure>
<ul>
<li>删除SCRAM凭证</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kafka-configs.sh --zookeeper kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --alter --delete-config <span class="string">'SCRAM-SHA-512'</span> --entity-type users --entity-name alice</span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-Kafka客户端配置"><a href="#2-3-Kafka客户端配置" class="headerlink" title="2.3 Kafka客户端配置"></a>2.3 Kafka客户端配置</h3><p>Kafka集群配置了认证，那么对于Console客户端访问集群自然需要配置认证信息。可集群节点内部通讯凭证的认知，同样需要定义JAAS文件。加入我们自定义了用户<code>alice</code>，JAAS文件名为：<code>kafka_console_client_jaas.conf</code>，配置内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">KafkaClient &#123;</span><br><span class="line">org.apache.kafka.common.security.scram.ScramLoginModule required</span><br><span class="line">username="alice"</span><br><span class="line">password="alice-secret";</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>然后更新<code>kafka-console-producer.sh</code>脚本和<code>kafka-console-consumer.sh</code>脚本的启动参数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 文件截取更新部分：</span></span><br><span class="line"></span><br><span class="line">if [ "x$KAFKA_OPTS" ]; then</span><br><span class="line">export KAFKA_OPTS="-Djava.security.auth.login.config=/opt/software/kafka/config/kafka_write_jaas.conf"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>在配置SSL时候，我们新建了<code>client-ssl.properties</code>配置文件，作为Console客户端启动配置。在集群启用<code>SASL_SSL</code>后，我们同步更新如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">security.protocol=SASL_SSL</span><br><span class="line">ssl.truststore.location=/usr/ca/trust/client.truststore.jks</span><br><span class="line">ssl.truststore.password=app123</span><br><span class="line">ssl.keystore.location=/usr/ca/client/client.keystore.jks</span><br><span class="line">ssl.keystore.password=app123</span><br><span class="line">ssl.key.password=app123</span><br></pre></td></tr></table></figure>
<p>至此Console客户端已经配置完毕，但目前Console客户端还不能通过命令方式和集群进行交互，因为我们指定的用户对于集群的资源还没有任何权限。需要对用户进行集群资源的ACL控制设置，赋予相关权限。</p>
<h3 id="2-4-ACL控制"><a href="#2-4-ACL控制" class="headerlink" title="2.4 ACL控制"></a>2.4 ACL控制</h3><p>Kafka权限资源包含Topic、Group、Cluster、TransactionalId（事务id），每个资源涉及的权限内容如下：</p>
<table>
<thead>
<tr>
<th>资源类型</th>
<th style="text-align:left">权限类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>Topic</td>
<td style="text-align:left">Read,Write,Describe,Delete,DescribeConfigs,AlterConfigs,All</td>
</tr>
<tr>
<td>Group</td>
<td style="text-align:left">Read,Describe,All</td>
</tr>
<tr>
<td>Cluster</td>
<td style="text-align:left">Create,ClusterAction,DescribeConfigs,AlterConfigs,IdempotentWrite,Alter,Describe,All</td>
</tr>
<tr>
<td>TransactionalId</td>
<td style="text-align:left">Describe,Write,All</td>
</tr>
</tbody>
</table>
<p>对于常用类型进行说明：</p>
<table>
<thead>
<tr>
<th>权限</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read</td>
<td>读取topic、group信息</td>
</tr>
<tr>
<td>Write</td>
<td>写topic、TransactionalId（存储在内部topic）</td>
</tr>
<tr>
<td>Delete</td>
<td>删除topic</td>
</tr>
<tr>
<td>Create</td>
<td>创建topic</td>
</tr>
<tr>
<td>ALTER</td>
<td>修改topic</td>
</tr>
<tr>
<td>Describe</td>
<td>获取topic、group、TransactionalId信息</td>
</tr>
<tr>
<td>ALL</td>
<td>所有权限</td>
</tr>
</tbody>
</table>
<p>Kafka提供ACL管理脚本：<code>kafka-acls.sh</code>。</p>
<h4 id="2-4-1-更新脚本配置"><a href="#2-4-1-更新脚本配置" class="headerlink" title="2.4.1 更新脚本配置"></a>2.4.1 更新脚本配置</h4><p>认证数据均存储在Zookeeper集群中，需要和Zookeeper交互自然需要配置相关认证信息。</p>
<p>首先需要新建JAAS文件，文件名为：<code>zk_client_jaas.conf</code>。这里的用户已经在Zookeeper集群中进行定义。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Client &#123;</span><br><span class="line">org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">username="admin"</span><br><span class="line">password="admin-secret";</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>最后更新<code>kafka-acls.sh</code>脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 截取更新部分</span></span><br><span class="line"></span><br><span class="line">if [ "x$KAFKA_OPTS" ]; then</span><br><span class="line">export KAFKA_OPTS="-Djava.security.auth.login.config=/opt/software/kafka/config/zk_client_jaas.conf"</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>当然Kafka集群的配置文件中已经开启了ACL：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer</span><br></pre></td></tr></table></figure>
<p>至此完成配置。</p>
<h4 id="2-4-2-ACL配置"><a href="#2-4-2-ACL配置" class="headerlink" title="2.4.2 ACL配置"></a>2.4.2 ACL配置</h4><p>根据官网的介绍，ACL的格式如下：</p>
<p><em>“Principal P is [Allowed/Denied] Operation O From Host H On Resource R”</em></p>
<p>参数含义描述如下：</p>
<ul>
<li>principal：指定一个Kafka user；</li>
<li>operation：指定一个具体的操作类型，例如：Read, Write, Delete等；</li>
<li>Host：表示与集群交互的客户端IP地址，如果是通配符‘*’表示所有IP。目前不支持主机名（hostname）形式，只能是IP地址；</li>
<li><p>Resource：指定一种Kafka资源类型（共有4种类型）；</p>
<p>例如下面的ACL命令：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sh kafka-acls.sh --authorizer kafka.security.auth.SimpleAclAuthorizer --authorizer-properties zookeeper.connect=kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --add --allow-principal User:alice --allow-host <span class="string">'*'</span> --operation ALL --topic <span class="built_in">test</span></span></span><br></pre></td></tr></table></figure>
<p>赋权之后，用户alice对test具有全部权限，并且访问请求可以是来自任何IP的客户端。</p>
<p>常用参数的补充说明：</p>
<ul>
<li>对主机IP的限制参数，<code>allow-host</code>指定允许的IP，<code>deny-host</code>指定禁用IP；</li>
<li>新增和删除一个赋权策略，分别使用：<code>add</code>和<code>remove</code></li>
</ul>
<h4 id="2-4-3-ACL策略查看"><a href="#2-4-3-ACL策略查看" class="headerlink" title="2.4.3 ACL策略查看"></a>2.4.3 ACL策略查看</h4><p>使用参数<code>list</code>参看ACL策略。例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sh kafka-acls.sh --authorizer kafka.security.auth.SimpleAclAuthorizer --authorizer-properties zookeeper.connect=kafka.app.node1:2181,kafka.app.node2:2181,kafka.app.node3:2181 --list --topic <span class="built_in">test</span>-topic</span></span><br></pre></td></tr></table></figure>
<p>该查看命令显示<code>test-topic</code>资源相关的所有ACL策略。</p>
<h4 id="2-4-4-超级用户"><a href="#2-4-4-超级用户" class="headerlink" title="2.4.4 超级用户"></a>2.4.4 超级用户</h4><p>kafka集群的配置文件<code>server.properties</code>中定义了超级用户（Super Users），超级用户不在ACL控制范围内，默认可以访问集群中所有资源，并具备所有权限。</p>
<h3 id="2-5-权限认证数据访问"><a href="#2-5-权限认证数据访问" class="headerlink" title="2.5 权限认证数据访问"></a>2.5 权限认证数据访问</h3><p>集群的认证数据存储在Zookeeper，可以通过Zookeeper的console客户端访问认证数据。</p>
<p>使用zookeeper自带的命令行客户端：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/dmqs/zookeeper/bin&gt; ./zkCli.sh</span><br><span class="line">Connecting to localhost:2181</span><br><span class="line">Welcome to ZooKeeper!</span><br><span class="line">JLine support is enabled</span><br><span class="line">[zk: localhost:2181(CONNECTING) 0]</span><br></pre></td></tr></table></figure>
<p>查看zookeeper中的数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] ls /</span><br><span class="line">[cluster, controller_epoch, controller, brokers, zookeeper, kafka-acl, kafka-acl-changes, admin, isr_change_notification, consumers, config]</span><br></pre></td></tr></table></figure>
<p>其中<code>kafka-acl</code>中存储相关权限认证数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] ls /kafka-acl</span><br><span class="line">[Cluster, Topic]</span><br></pre></td></tr></table></figure>
<p>可以查看其中的权限信息。</p>
<h3 id="2-6-SSL和SASL的说明"><a href="#2-6-SSL和SASL的说明" class="headerlink" title="2.6 SSL和SASL的说明"></a>2.6 SSL和SASL的说明</h3><p>SSL是传输层安全协议，是位于传输层（TCP/IP）和应用层（HTTP）的协议，SSL是对整个传输过程的加密，SSL是对客户端和服务器之间传输的所有数据进行加密。假如在配置的时候使用了SASL，但是没有使用SSL，那么除了账号密码外，所有的传输内容都是裸奔的。</p>
<p>所以生产集群采用SSL和SASL结合方式，即SSL_SASL方式。</p>
<h2 id="第三部分-安全集群的客户端"><a href="#第三部分-安全集群的客户端" class="headerlink" title="第三部分 安全集群的客户端"></a>第三部分 安全集群的客户端</h2><h3 id="3-1-开发语言类"><a href="#3-1-开发语言类" class="headerlink" title="3.1 开发语言类"></a>3.1 开发语言类</h3><h4 id="3-1-1-Python客户端"><a href="#3-1-1-Python客户端" class="headerlink" title="3.1.1 Python客户端"></a>3.1.1 Python客户端</h4><p>目前市面上kafka的python API常用的有三种：</p>
<ul>
<li><strong>第一种 kafka</strong></li>
</ul>
<p>该项目是<code>kafka-python</code>的老项目，2017年后调整为<code>kafka-python</code>项目。</p>
<ul>
<li><strong>第二种 kafka-python</strong></li>
</ul>
<p>最新版本为2.0，首先从客户端的密钥库中导出CA证书。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -exportcert -<span class="built_in">alias</span> CARoot -keystore client.keystore.jks -rfc -file ca.cert.pem</span></span><br></pre></td></tr></table></figure>
<p>生产者和消费者的案例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kafka <span class="keyword">import</span> KafkaConsumer, KafkaProducer</span><br><span class="line"><span class="keyword">import</span> kafka</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#logging.basicConfig(level=logging.DEBUG)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    bootstrap_servers = <span class="string">'kafka.itdw.node1:9092,kafka.itdw.node2:9092,kafka.itdw.node3:9092'</span></span><br><span class="line">    topic = <span class="string">"test"</span></span><br><span class="line">    sasl_mechanism = <span class="string">"SCRAM-SHA-512"</span></span><br><span class="line">    username = <span class="string">"alice"</span></span><br><span class="line">    password = <span class="string">"alice-secret"</span></span><br><span class="line">    security_protocol = <span class="string">"SASL_SSL"</span></span><br><span class="line">    <span class="comment"># CA 证书路径</span></span><br><span class="line">    ssl_cafile = <span class="string">'ca.cert.pem'</span></span><br><span class="line">    <span class="comment"># SSL</span></span><br><span class="line">    context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)</span><br><span class="line">    context.verify_mode = ssl.CERT_NONE</span><br><span class="line">    context.check_hostname = <span class="keyword">False</span></span><br><span class="line">    context.load_verify_locations(ssl_cafile)</span><br><span class="line">    <span class="comment"># 消费者</span></span><br><span class="line">    consumer = KafkaConsumer(topic, bootstrap_servers=bootstrap_servers,</span><br><span class="line">                               api_version=(<span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">                               security_protocol=security_protocol,</span><br><span class="line">                               ssl_context=context,</span><br><span class="line">                               sasl_mechanism = sasl_mechanism,</span><br><span class="line">                               sasl_plain_username = username,</span><br><span class="line">                               sasl_plain_password = password</span><br><span class="line">                              )</span><br><span class="line">    <span class="comment"># 生产者</span></span><br><span class="line">    producer = KafkaProducer(bootstrap_servers=bootstrap_servers,</span><br><span class="line">                             api_version=(<span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">                             acks=<span class="string">'all'</span>,</span><br><span class="line">                             retries=<span class="number">1</span>,</span><br><span class="line">                             security_protocol=security_protocol,</span><br><span class="line">                             ssl_context=context,</span><br><span class="line">                             sasl_mechanism=sasl_mechanism,</span><br><span class="line">                             sasl_plain_username=username,</span><br><span class="line">                             sasl_plain_password=password</span><br><span class="line">                             )</span><br><span class="line">    <span class="comment"># 生产数据</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        producer.send(topic, bytes(<span class="string">"测试"</span>,encoding=<span class="string">'utf8'</span>))</span><br><span class="line">    producer.flush()</span><br><span class="line">    <span class="comment"># 消费数据</span></span><br><span class="line">    <span class="keyword">for</span> msg <span class="keyword">in</span> consumer:</span><br><span class="line">        print(msg)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(e)</span><br></pre></td></tr></table></figure>
<p>需要的注意的事项有：</p>
<ul>
<li><p>Kafka集群启用主机名模式，所以应用程序运行节点的hosts文件需要配置Kafka集群节点的域名映射。</p>
</li>
<li><p>ssl_context参数为包装套接字连接的预配置SSLContext。如果非None，将忽略所有其他ssl_ *配置。</p>
</li>
<li><p>主机名验证问题。如果证书中域名和主机名不匹配，客户端侧需要配置需要调整如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssl_ctx.check_hostname=<span class="keyword">False</span></span><br><span class="line">ssl_ctx.verify_mode = CERT_NONE</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果不提前预配置SSLContext，还需要客户端的证书。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> keytool -exportcert -<span class="built_in">alias</span> localhost -keystore client.keystore.jks -rfc -file client.cert.pem</span></span><br></pre></td></tr></table></figure>
<p>生产者的参数需要添加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ssl_certfile = <span class="string">"client.cert.pem"</span></span><br><span class="line">ssl_cafile = <span class="string">"ca.cert.pem"</span></span><br><span class="line">producer = KafkaProducer(bootstrap_servers=bootstrap_servers,</span><br><span class="line">                         api_version=(<span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">                         acks=<span class="string">'all'</span>,</span><br><span class="line">                         retries=<span class="number">1</span>,</span><br><span class="line">                         security_protocol=security_protocol,</span><br><span class="line">                         ssl_context=context,</span><br><span class="line">                         sasl_mechanism=sasl_mechanism,</span><br><span class="line">                         sasl_plain_username=username,</span><br><span class="line">                         sasl_plain_password=password,</span><br><span class="line">                         ssl_check_hostname=<span class="keyword">False</span>, </span><br><span class="line">                         ssl_certfile=ssl_certfile,</span><br><span class="line">                         ssl_cafile=ssl_cafile)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>第三种 confluent-kafka</strong></p>
</li>
</ul>
<p>confluent-kafka包由confluent公司开源，主要是对C/C++客户端包（<a href="https://github.com/edenhill/librdkafka" target="_blank" rel="noopener">librdkafka</a>）的封装。案例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> confluent_kafka <span class="keyword">import</span> Producer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回调函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delivery_report</span><span class="params">(err, msg)</span>:</span></span><br><span class="line">     <span class="string">""" Called once for each message produced to indicate delivery result.</span></span><br><span class="line"><span class="string">         Triggered by poll() or flush(). """</span></span><br><span class="line">     <span class="keyword">if</span> err <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        print(’Message delivery failed: &#123;&#125;‘.format(err))</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">        print(‘Message delivered to &#123;&#125; [&#123;&#125;]‘.format(msg.topic(),           msg.partition()))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == ‘__main__‘:</span><br><span class="line">     producerConfing = &#123;<span class="string">"bootstrap.servers"</span>: <span class="string">'kafka.itdw.node1:9092,kafka.itdw.node2:9092,kafka.itdw.node3:9092'</span>,</span><br><span class="line">         <span class="string">"security.protocol"</span>: <span class="string">'SASL_SSL'</span>,</span><br><span class="line">         <span class="string">"sasl.mechanisms"</span>: <span class="string">'SCRAM-SHA-256'</span>,</span><br><span class="line">         <span class="string">"sasl.username"</span>: <span class="string">'alice'</span>,</span><br><span class="line">         <span class="string">"sasl.password"</span>: <span class="string">'alice-secret'</span>,</span><br><span class="line">         <span class="string">"ssl.ca.location"</span>: <span class="string">'ca.cert.pem'</span></span><br><span class="line">     &#125;</span><br><span class="line">     ProducerTest = Producer(producerConfing)</span><br><span class="line"> </span><br><span class="line">     ProducerTest.poll(<span class="number">0</span>)</span><br><span class="line">     ProducerTest.produce(‘testTopic‘, ‘confluent kafka test‘.encode(‘utf<span class="number">-8</span>‘),callback=delivery_report)</span><br><span class="line">     ProducerTest.flush()</span><br></pre></td></tr></table></figure>
<h4 id="3-1-2-Go客户端"><a href="#3-1-2-Go客户端" class="headerlink" title="3.1.2 Go客户端"></a>3.1.2 Go客户端</h4><p>我们的Go语言中常用的Kafka的客户端包有：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"github.com/Shopify/sarama"</span><br><span class="line">"github.com/bsm/sarama-cluster"</span><br><span class="line">"github.com/confluentinc/confluent-kafka-go/kafka"</span><br><span class="line">"github.com/segmentio/ksuid"</span><br></pre></td></tr></table></figure>
<p>其中最常用的是<code>sarama</code>，案例参考<a href="https://github.com/Shopify/sarama/tree/master/examples/sasl_scram_client" target="_blank" rel="noopener">github项目</a>。</p>
<h4 id="3-1-3-Java客户端"><a href="#3-1-3-Java客户端" class="headerlink" title="3.1.3 Java客户端"></a>3.1.3 Java客户端</h4><p>生产者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.kafka.security;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.CommonClientConfigs;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.config.SaslConfigs;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.config.SslConfigs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerWithSASL_SSL</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_TOPIC = <span class="string">"topsec"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String BOOTSTRAP_SERVER = <span class="string">"docker31:9092"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String[] strs = <span class="keyword">new</span> String[]&#123;<span class="string">"zhao"</span>, <span class="string">"qian"</span>, <span class="string">"sun"</span>, <span class="string">"li"</span>, <span class="string">"zhou"</span>, <span class="string">"wu"</span>, <span class="string">"zheng"</span>, <span class="string">"wang"</span>, <span class="string">"feng"</span>, <span class="string">"chen"</span>&#125;;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Random r = <span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            producer();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);</span><br><span class="line">        <span class="comment">//SASL_SSL加密</span></span><br><span class="line">        props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, <span class="string">"SASL_SSL"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, <span class="string">"D:\\Download\\ca\\trust\\client.truststore.jks"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        <span class="comment">// SSL用户认证</span></span><br><span class="line">        props.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, <span class="string">"D:\\Download\\ca\\client\\client.keystore.jks"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_KEY_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        <span class="comment">//SASL用户认证</span></span><br><span class="line">                                props.put(SaslConfigs.SASL_JAAS_CONFIG,<span class="string">"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"admin\" password=\"admin-secret\";"</span>);</span><br><span class="line">        props.put(SaslConfigs.SASL_MECHANISM, <span class="string">"SCRAM-SHA-512"</span>);</span><br><span class="line"></span><br><span class="line">        props.put(ProducerConfig.ACKS_CONFIG, <span class="string">"all"</span>);</span><br><span class="line">        props.put(ProducerConfig.RETRIES_CONFIG, <span class="number">0</span>);</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(KAFKA_TOPIC, strs[r.nextInt(<span class="number">10</span>)],strs[r.nextInt(<span class="number">10</span>)]));</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消费者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.topsec.kafka.security;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.CommonClientConfigs;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.config.SaslConfigs;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.config.SslConfigs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaConsumerWithSASLAndSSL</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_TOPIC = <span class="string">"topsec"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String BOOTSTRAP_SERVER = <span class="string">"docker31:9092"</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        consumer();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//SASL_SSL加密配置</span></span><br><span class="line">        props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, <span class="string">"SASL_SSL"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, <span class="string">"D:\\Download\\ca\\trust\\client.truststore.jks"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        <span class="comment">//SSL身份验证配置</span></span><br><span class="line">        props.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, <span class="string">"D:\\Download\\ca\\client\\client.keystore.jks"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        props.put(SslConfigs.SSL_KEY_PASSWORD_CONFIG, <span class="string">"hadoop"</span>);</span><br><span class="line">        <span class="comment">//SASL身份验证</span></span><br><span class="line">        props.put(SaslConfigs.SASL_JAAS_CONFIG,<span class="string">"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"admin\" password=\"admin-secret\";"</span>);</span><br><span class="line">        props.put(SaslConfigs.SASL_MECHANISM, <span class="string">"SCRAM-SHA-512"</span>);</span><br><span class="line"></span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);</span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"true"</span>);</span><br><span class="line">        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string">"1000"</span>);</span><br><span class="line">        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="string">"6000"</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Collections.singletonList(KAFKA_TOPIC));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">2000</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(<span class="string">"offset = %d, key = %s, value = %s, partition = %d %n"</span>,</span><br><span class="line">                        record.offset(),</span><br><span class="line">                        record.key(),</span><br><span class="line">                        record.value(),</span><br><span class="line">                        record.partition());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-组件类"><a href="#3-2-组件类" class="headerlink" title="3.2 组件类"></a>3.2 组件类</h3><h4 id="3-2-1-Console客户端"><a href="#3-2-1-Console客户端" class="headerlink" title="3.2.1 Console客户端"></a>3.2.1 Console客户端</h4><p>客户端节点部署kafka项目，在bin目录下面我们已经更新了<code>kafka-console-consumer.sh</code>和<code>kafka-console-producer.sh</code>两个脚本。并分别新增了加密访问的配置文件<code>consumer.config</code>和<code>producer.config</code>。</p>
<p>命令案例参考：1.3.4 章节内容。</p>
<h4 id="3-2-2-Flume客户端"><a href="#3-2-2-Flume客户端" class="headerlink" title="3.2.2 Flume客户端"></a>3.2.2 Flume客户端</h4><p>目前Flume项目官网项目文档介绍支持下面三种方式：</p>
<ul>
<li>SASL_PLAINTEXT - 无数据加密的 Kerberos 或明文认证；</li>
<li>SASL_SSL - 有数据加密的 Kerberos 或明文认证；</li>
<li>SSL - 基于TLS的加密，可选的身份验证；</li>
</ul>
<p>事实上对于SASL/SCRAM方式Flume也是支持的。具体配置如下（以Flume1.9版本为例）：</p>
<h5 id="3-2-2-1-第一步-新增jaas配置文件"><a href="#3-2-2-1-第一步-新增jaas配置文件" class="headerlink" title="3.2.2.1 第一步 新增jaas配置文件"></a>3.2.2.1 第一步 新增jaas配置文件</h5><p>在Flume的conf配置目录下面新增flume_jaas.conf文件，文件内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Server &#123;</span><br><span class="line">    org.apache.kafka.common.security.plain.PlainLoginModule required</span><br><span class="line">    username="admin"</span><br><span class="line">    password="admin-secret"</span><br><span class="line">    user_admin="admin-secret";</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">KafkaClient &#123;</span><br><span class="line">    org.apache.kafka.common.security.scram.ScramLoginModule required</span><br><span class="line">    username="admin"</span><br><span class="line">    password="admin-secret";</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="3-2-2-2-第二步-更新flume-env-sh文件"><a href="#3-2-2-2-第二步-更新flume-env-sh文件" class="headerlink" title="3.2.2.2 第二步 更新flume-env.sh文件"></a>3.2.2.2 第二步 更新flume-env.sh文件</h5><p>Flume的conf配置目录下面<code>flume-env.sh</code>文件添加<code>JAVA_OPTS</code>配置更新：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS="$JAVA_OPTS -Djava.security.auth.login.config=/dmqs/apache-flume-1.9.0-bin/conf/flume_jaas.conf"</span><br></pre></td></tr></table></figure>
<p>其中路径为第一步中新增的<code>flume_jaas.conf</code>文件路径。</p>
<h5 id="3-2-2-3-测试案例（sinks）"><a href="#3-2-2-3-测试案例（sinks）" class="headerlink" title="3.2.2.3  测试案例（sinks）"></a>3.2.2.3  测试案例（sinks）</h5><p>我们使用一个简单的案例来测试，Flume的source为监控文件尾写入，Flume的sinks为加密kafka集群。具体配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">define</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">bind</span></span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -f /dmqs/apache-flume-1.9.0-bin/data/flume/flume.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 15000</span><br><span class="line">a1.channels.c1.transactionCapacity = 15000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> sink</span></span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.kafka.bootstrap.servers = kafka.itdw.node1:9093</span><br><span class="line">a1.sinks.k1.kafka.topic = flume</span><br><span class="line">a1.sinks.k1.kafka.flumeBatchSize = 15000</span><br><span class="line">a1.sinks.k1.kafka.producer.acks = 1</span><br><span class="line">a1.sinks.k1.kafka.producer.linger.ms = 1000</span><br><span class="line">a1.sinks.k1.kafka.producer.security.protocol=SASL_SSL</span><br><span class="line">a1.sinks.c1.kafka.producer.sasl.mechanism =SCRAM-SHA-512</span><br><span class="line">a1.sinks.c1.kafka.producer.sasl.jaas.config =org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret"</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###</span></span></span><br><span class="line">a1.sinks.k1.kafka.producer.ssl.truststore.location =/usr/ca/trust/client.truststore.jks</span><br><span class="line">a1.sinks.k1.kafka.producer.sasl.mechanism =SCRAM-SHA-512</span><br><span class="line">a1.sinks.k1.kafka.producer.ssl.truststore.password=app123</span><br><span class="line">a1.sinks.k1.kafka.producer.ssl.keystore.location=/usr/ca/client/client.keystore.jks</span><br><span class="line">a1.sinks.k1.kafka.producer.ssl.keystore.password=app123</span><br><span class="line">a1.sinks.k1.kafka.producer.ssl.key.password=app123</span><br><span class="line">a1.sinks.k1.kafka.producer.timeout.ms = 100</span><br><span class="line">a1.sinks.k1.batchSize=15000</span><br><span class="line">a1.sinks.k1.batchDurationMillis=2000</span><br></pre></td></tr></table></figure>
<p>配置保存为<code>flume-sink-auth-kafka.conf</code>,为了检查输出结果使用下面命令启动（在bin目录中）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./flume-ng agent --conf ../conf --conf-file ../conf/flume-sink-auth-kafka.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p>向文件尾部追加信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "test" &gt;&gt; /dmqs/apache-flume-1.9.0-bin/data/flume/flume.log</span><br></pre></td></tr></table></figure>
<p>然后使用消费者客户端查看数据是否写入kafka的flume主题中。</p>
<h5 id="3-2-2-3-测试案例（source）"><a href="#3-2-2-3-测试案例（source）" class="headerlink" title="3.2.2.3  测试案例（source）"></a>3.2.2.3  测试案例（source）</h5><p>同样可以也可以将加密Kafka作为Flume的source，配置案例如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">define</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">bind</span></span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers = kafka.app .node1:9093,kafka.app.node2:9093,kafka.app.node3:9093</span><br><span class="line">a1.sources.r1.kafka.topics = flume</span><br><span class="line">a1.sources.r1.kafka.consumer.group.id = flume</span><br><span class="line">a1.sources.r1.kafka.consumer.timeout.ms = 2000</span><br><span class="line">a1.sources.r1.batchSize=150</span><br><span class="line">a1.sources.r1.batchDurationMillis=1000</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">####</span></span></span><br><span class="line">a1.sources.r1.kafka.consumer.ssl.truststore.location =/usr/ca/trust/client.truststore.jks</span><br><span class="line">a1.sources.r1.kafka.consumer.sasl.mechanism =SCRAM-SHA-512</span><br><span class="line">a1.sources.r1.kafka.consumer.ssl.truststore.password=itdw123</span><br><span class="line">a1.sources.r1.kafka.consumer.ssl.keystore.location=/usr/ca/client/client.keystore.jks</span><br><span class="line">a1.sources.r1.kafka.consumer.ssl.keystore.password=itdw123</span><br><span class="line">a1.sources.r1.kafka.consumer.ssl.key.password=itdw123</span><br><span class="line">a1.sources.r1.kafka.consumer.security.protocol=SASL_SSL</span><br><span class="line">a1.sources.r1.kafka.consumer.sasl.mechanism =SCRAM-SHA-512</span><br><span class="line">a1.sources.r1.kafka.consumer.sasl.jaas.config =org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="admin-secret";</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 15000</span><br><span class="line">a1.channels.c1.transactionCapacity = 15000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> sink</span></span><br><span class="line">a1.sinks.k1.type = file_roll</span><br><span class="line">a1.sinks.k1.sink.directory = /dmqs/apache-flume-1.9.0-bin/data/flume</span><br><span class="line">a1.sinks.k1.sink.serializer = TEXT</span><br></pre></td></tr></table></figure>
<p>案例中将加密Kafka中flume主题中的数据汇入到指定目录的文件中。</p>
<h4 id="3-2-3-Logstash客户端"><a href="#3-2-3-Logstash客户端" class="headerlink" title="3.2.3 Logstash客户端"></a>3.2.3 Logstash客户端</h4><p>Logstash和Kafka交互使用<code>Kafka output plugin</code>插件实现。其中配置文件中output部分如下：</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    id =&gt; <span class="string">"kafkaSLL_SASL"</span></span><br><span class="line">    codec =&gt; <span class="string">"json"</span></span><br><span class="line">    ssl_endpoint_identification_algorithm =&gt; <span class="string">""</span></span><br><span class="line">    bootstrap_servers =&gt; <span class="string">"kafka.app.node1:9092,kafka.app.node2:9092,kafka.app.node3:9092"</span></span><br><span class="line">    jaas_path =&gt;<span class="string">"/etc/logstash/certificates/kafka_servcer_jaas.conf"</span></span><br><span class="line">    ssl_keystore_location =&gt; <span class="string">"/etc/logstash/certificates/client.keystore.jks"</span></span><br><span class="line">    ssl_keystore_password =&gt; <span class="string">"app123"</span></span><br><span class="line">    ssl_keystore_type =&gt; <span class="string">"JKS"</span></span><br><span class="line">    ssl_truststore_location =&gt; <span class="string">"/etc/logstash/certificates/client.truststore.jks"</span></span><br><span class="line">    ssl_truststore_password =&gt; <span class="string">"app123"</span></span><br><span class="line">    ssl_truststore_type =&gt; <span class="string">"JKS"</span></span><br><span class="line">    sasl_mechanism =&gt; <span class="string">"SCRAM-SHA-512"</span></span><br><span class="line">    security_protocol =&gt; <span class="string">"SASL_SSL"</span></span><br><span class="line">    topic_id =&gt; <span class="string">"test"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>参考：<a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-kafka.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-outputs-kafka.html</a></p>
</blockquote>
<h2 id="第四部分-加密认证集群的性能压测"><a href="#第四部分-加密认证集群的性能压测" class="headerlink" title="第四部分 加密认证集群的性能压测"></a>第四部分 加密认证集群的性能压测</h2><p>集群启用SSL后，数据交互中需要加密、解密。kafka集群的I/O性能会降低。我们使用Kafka自带的压侧工具对集群加密前和加密后性能进行评测。</p>
<h3 id="4-1生产者压力测试"><a href="#4-1生产者压力测试" class="headerlink" title="4.1生产者压力测试"></a>4.1生产者压力测试</h3><p>客户端写入参数配置为<code>acks=all</code>（即Topic中Leader和fellow副本均写入成功）。每条消息大小为1M（消息体小吞吐量会大一些）。另外测试客户端为集群内部节点，忽略了数据网络传输的性能消耗。</p>
<h4 id="4-1-1不加密集群"><a href="#4-1-1不加密集群" class="headerlink" title="4.1.1不加密集群"></a>4.1.1不加密集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-consumer-perf-test.sh --topic topsec --throughput 50000 --num-records 1500000 --record-size 10000 --producer-props bootstrap.servers=kafka.itdw.node1:9093,kafka.itdw.node2:9093,kafka.itdw.node3:9093 acks=all</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1500000 records sent, 38538.615693 records/sec (37.64 MB/sec), 748.44 ms avg latency, 5485.00 ms max latency, 227 ms 50th, 3194 ms 95th, 3789 ms 99th, 3992 ms 99.9th.</span><br></pre></td></tr></table></figure>
<h4 id="4-1-2加密集群"><a href="#4-1-2加密集群" class="headerlink" title="4.1.2加密集群"></a>4.1.2加密集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-producer-perf-test.sh --topic topsec --throughput 50000 --num-records 1500000 --record-size 10000 --producer-props bootstrap.servers=kafka.itdw.node1:9093,kafka.itdw.node2:9093,kafka.itdw.node3:9093 acks=all --producer.config producer.config</span><br></pre></td></tr></table></figure>
<p>测试结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1500000 records sent, 16901.027582 records/sec (16.50 MB/sec), 1713.43 ms avg latency, 9345.00 ms max latency, 72 ms 50th, 1283 ms 95th, 2067 ms 99th, 2217 ms 99.9th.</span><br></pre></td></tr></table></figure>
<h3 id="4-2-压侧结论"><a href="#4-2-压侧结论" class="headerlink" title="4.2 压侧结论"></a>4.2 压侧结论</h3><p>加密改造前，生产者的吞吐量为3.8w 条/秒，改造后1.7W 条/秒。整体吞吐性能降低50%左右，数据的加密、解密导致吞吐量性能降低。平均时延也增加了一倍多（改造前700ms，改造后1700ms）。在实际生产中可参考这个性能折扣基线配置集群资源。</p>
<h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Kafka官网对安全类功能介绍，链接：<a href="http://kafka.apache.org/documentation/#security" target="_blank" rel="noopener">http://kafka.apache.org/documentation/#security</a></p>
<p>2、Kafka ACLs in Practice – User Authentication and Authorization，链接：<a href="https://developer.ibm.com/opentech/2017/05/31/kafka-acls-in-practice/" target="_blank" rel="noopener">https://developer.ibm.com/opentech/2017/05/31/kafka-acls-in-practice/</a></p>
<p>3、维基百科（数字证书），链接：<a href="https://zh.wikipedia.org/wiki/公開金鑰認證" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/公開金鑰認證</a></p>
<p>4、SSL技术白皮书，链接：<a href="https://blog.51cto.com/xuding/1732723" target="_blank" rel="noopener">https://blog.51cto.com/xuding/1732723</a></p>
<p>5、Kafka权限管理，链接：<a href="https://www.jianshu.com/p/09129c9f4c80" target="_blank" rel="noopener">https://www.jianshu.com/p/09129c9f4c80</a></p>
<p>5、Flume文档，链接：<a href="https://flume.apache.org/FlumeUserGuide.html#kafka-sinkorg/FlumeUserGuide.html#kafka-sink" target="_blank" rel="noopener">https://flume.apache.org/FlumeUserGuide.html#kafka-sinkorg/FlumeUserGuide.html#kafka-sink</a></p>

      
    </div>

    

    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">
  <p><span>本文标题:</span><a href="/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/">Kafka系列文章（第五篇 Kafka安全集群）</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 rong xiang 的个人博客">rong xiang</a></p>
  <p><span>发布时间:</span>2020年03月02日 - 13:03</p>
  <p><span>最后更新:</span>2020年10月25日 - 13:10</p>
  <p><span>原始链接:</span><a href="/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/" title="Kafka系列文章（第五篇 Kafka安全集群）">https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({   
          title: "",   
          text: '复制成功',   
          html: false,
          timer: 500,   
          showConfirmButton: false
        });
      });
    }));  
</script>

      
    </div>
    
    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/01/31/2020-01-31-Go语言学习系列(一)Go语言Win开发环境部署 - 副本/" rel="next" title="Go语言学习系列(一)Go语言Win开发环境部署">
                <i class="fa fa-chevron-left"></i> Go语言学习系列(一)Go语言Win开发环境部署
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/03/02/2020-03-02-Pyspark系列文章-Pyspark和Kafka交互介绍/" rel="prev" title="PySpark和Kafka交互介绍">
                PySpark和Kafka交互介绍 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar/person.png" alt="rong xiang">
            
              <p class="site-author-name" itemprop="name">rong xiang</p>
              <p class="site-description motion-element" itemprop="description">Keep a Pure Curiosity</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">107</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">50</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/zjrongxiang" title="GitHub &rarr; https://github.com/zjrongxiang" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:rongxiang1986@163.com" title="E-Mail &rarr; mailto:rongxiang1986@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="http://weibo.com/u/1971060643" title="Weibo &rarr; http://weibo.com/u/1971060643" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Link
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://weibo.com/fly51fly?refer_flag=1005055010_" title="https://weibo.com/fly51fly?refer_flag=1005055010_" rel="noopener" target="_blank">爱生活爱可可</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">2.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第一部分-Kafka集群加密传输"><span class="nav-number">3.</span> <span class="nav-text">第一部分   Kafka集群加密传输</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-背景知识介绍"><span class="nav-number">3.1.</span> <span class="nav-text">1.1 背景知识介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-1-密码学基础"><span class="nav-number">3.1.1.</span> <span class="nav-text">1.1.1 密码学基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-2-CA数字证书"><span class="nav-number">3.1.2.</span> <span class="nav-text">1.1.2 CA数字证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-3-SSL-TLS加密协议"><span class="nav-number">3.1.3.</span> <span class="nav-text">1.1.3 SSL/TLS加密协议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-4-Openssl工具"><span class="nav-number">3.1.4.</span> <span class="nav-text">1.1.4 Openssl工具</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-5-Keytool工具介绍"><span class="nav-number">3.1.5.</span> <span class="nav-text">1.1.5 Keytool工具介绍</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Kafka集群配置SSL加密"><span class="nav-number">3.2.</span> <span class="nav-text">1.2 Kafka集群配置SSL加密</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-1-集群环境准备"><span class="nav-number">3.2.1.</span> <span class="nav-text">1.2.1 集群环境准备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-配置主机名验证"><span class="nav-number">3.2.2.</span> <span class="nav-text">1.2.2 配置主机名验证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-3-生成SSL密钥和证书（密钥库）"><span class="nav-number">3.2.3.</span> <span class="nav-text">1.2.3 生成SSL密钥和证书（密钥库）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-4-创建Kafka集群CA证书"><span class="nav-number">3.2.4.</span> <span class="nav-text">1.2.4 创建Kafka集群CA证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-5-集群服务节点签署证书"><span class="nav-number">3.2.5.</span> <span class="nav-text">1.2.5 集群服务节点签署证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-6-生成服务端信任库"><span class="nav-number">3.2.6.</span> <span class="nav-text">1.2.6 生成服务端信任库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-7-配置Kafka-Brokers"><span class="nav-number">3.2.7.</span> <span class="nav-text">1.2.7 配置Kafka Brokers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-8-初步验证"><span class="nav-number">3.2.8.</span> <span class="nav-text">1.2.8 初步验证</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-配置kafka客户端"><span class="nav-number">3.3.</span> <span class="nav-text">1.3 配置kafka客户端</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-1-签发客户端证书"><span class="nav-number">3.3.1.</span> <span class="nav-text">1.3.1 签发客户端证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-2-生成客户端信任库"><span class="nav-number">3.3.2.</span> <span class="nav-text">1.3.2 生成客户端信任库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-3-配置客户端"><span class="nav-number">3.3.3.</span> <span class="nav-text">1.3.3 配置客户端</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-4-消费者生产者"><span class="nav-number">3.3.4.</span> <span class="nav-text">1.3.4 消费者生产者</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二部分-Kafka集群权限认证"><span class="nav-number">4.</span> <span class="nav-text">第二部分 Kafka集群权限认证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-集群权限认证策略"><span class="nav-number">4.1.</span> <span class="nav-text">2.1 集群权限认证策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-SASL-SCRAM策略配置介绍"><span class="nav-number">4.2.</span> <span class="nav-text">2.2 SASL/SCRAM策略配置介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-Zookeeper集群侧配置"><span class="nav-number">4.2.1.</span> <span class="nav-text">2.2.1 Zookeeper集群侧配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-kafka集群侧配置"><span class="nav-number">4.2.2.</span> <span class="nav-text">2.2.2 kafka集群侧配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-SCRAM认证管理"><span class="nav-number">4.2.3.</span> <span class="nav-text">2.2.3 SCRAM认证管理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Kafka客户端配置"><span class="nav-number">4.3.</span> <span class="nav-text">2.3 Kafka客户端配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-ACL控制"><span class="nav-number">4.4.</span> <span class="nav-text">2.4 ACL控制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-1-更新脚本配置"><span class="nav-number">4.4.1.</span> <span class="nav-text">2.4.1 更新脚本配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-2-ACL配置"><span class="nav-number">4.4.2.</span> <span class="nav-text">2.4.2 ACL配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-3-ACL策略查看"><span class="nav-number">4.4.3.</span> <span class="nav-text">2.4.3 ACL策略查看</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-4-超级用户"><span class="nav-number">4.4.4.</span> <span class="nav-text">2.4.4 超级用户</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-权限认证数据访问"><span class="nav-number">4.5.</span> <span class="nav-text">2.5 权限认证数据访问</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-SSL和SASL的说明"><span class="nav-number">4.6.</span> <span class="nav-text">2.6 SSL和SASL的说明</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三部分-安全集群的客户端"><span class="nav-number">5.</span> <span class="nav-text">第三部分 安全集群的客户端</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-开发语言类"><span class="nav-number">5.1.</span> <span class="nav-text">3.1 开发语言类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-Python客户端"><span class="nav-number">5.1.1.</span> <span class="nav-text">3.1.1 Python客户端</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-Go客户端"><span class="nav-number">5.1.2.</span> <span class="nav-text">3.1.2 Go客户端</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-Java客户端"><span class="nav-number">5.1.3.</span> <span class="nav-text">3.1.3 Java客户端</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-组件类"><span class="nav-number">5.2.</span> <span class="nav-text">3.2 组件类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-Console客户端"><span class="nav-number">5.2.1.</span> <span class="nav-text">3.2.1 Console客户端</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-Flume客户端"><span class="nav-number">5.2.2.</span> <span class="nav-text">3.2.2 Flume客户端</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-1-第一步-新增jaas配置文件"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">3.2.2.1 第一步 新增jaas配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-2-第二步-更新flume-env-sh文件"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">3.2.2.2 第二步 更新flume-env.sh文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-3-测试案例（sinks）"><span class="nav-number">5.2.2.3.</span> <span class="nav-text">3.2.2.3  测试案例（sinks）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-3-测试案例（source）"><span class="nav-number">5.2.2.4.</span> <span class="nav-text">3.2.2.3  测试案例（source）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-3-Logstash客户端"><span class="nav-number">5.2.3.</span> <span class="nav-text">3.2.3 Logstash客户端</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第四部分-加密认证集群的性能压测"><span class="nav-number">6.</span> <span class="nav-text">第四部分 加密认证集群的性能压测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1生产者压力测试"><span class="nav-number">6.1.</span> <span class="nav-text">4.1生产者压力测试</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-1不加密集群"><span class="nav-number">6.1.1.</span> <span class="nav-text">4.1.1不加密集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-2加密集群"><span class="nav-number">6.1.2.</span> <span class="nav-text">4.1.2加密集群</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-压侧结论"><span class="nav-number">6.2.</span> <span class="nav-text">4.2 压侧结论</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献及资料"><span class="nav-number">7.</span> <span class="nav-text">参考文献及资料</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; 2014 – <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">rong xiang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">360k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">5:27</span>
  
</div>






        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=6.7.0"></script>




  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  
  
    
  <script id="dsq-count-scr" src="https://https-zjrongxiang-github-io.disqus.com/count.js" async></script>


<script>
  var disqus_config = function () {
    this.page.url = "https://zjrongxiang.github.io/2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/";
    this.page.identifier = "2020/03/02/2020-01-01-Kafka系列文章（第五篇Kafka安全）/";
    this.page.title = 'Kafka系列文章（第五篇 Kafka安全集群）';
    };
  function loadComments () {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-zjrongxiang-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', '' + +new Date());
    (d.head || d.body).appendChild(s);
  }
  
    loadComments();
  
</script>

  





  

  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap');
      $(e).after($wrap);
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text();
        }).toArray().join('\n');
        var ta = document.createElement('textarea');
        var range = document.createRange(); //For Chrome
        var sel = window.getSelection(); //For Chrome
        var yPosition = window.pageYOffset || document.documentElement.scrollTop;
        ta.style.top = yPosition + 'px'; //Prevent page scroll
        ta.style.position = 'absolute';
        ta.style.opacity = '0';
        ta.value = code;
        ta.textContent = code; //For FireFox
        ta.contentEditable = true;
        ta.readOnly = false;
        document.body.appendChild(ta);
        range.selectNode(ta);
        sel.removeAllRanges();
        sel.addRange(range);
        ta.setSelectionRange(0, code.length);
        var result = document.execCommand('copy');
        
          if (result) $(this).text('复制成功');
          else $(this).text('复制失败');
        
        ta.blur(); //For iOS
        $(this).blur();
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn');
        setTimeout(function () {
          $b.text('复制');
        }, 300);
      }).append(e);
    })
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  
  

  
  

  


</body>
</html>
