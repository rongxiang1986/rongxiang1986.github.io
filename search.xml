<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[sqlflow初体验]]></title>
    <url>%2F2019%2F05%2F06%2F2019-05-06-Sqlflow%E5%88%9D%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[目录 背景 第一部分 Sqlflow安装部署 第二部分 机器学习例子 第三部分 系统架构 参考文献及资料 背景2019年5 月 6 日，在QCon 全球软件开发大会（北京站）上，蚂蚁金服副 CTO 胡喜正式宣布开源机器学习工具 SQLFlow。实际上3个月前sqkflow项目已经在github上开源了。 本篇文件主要参考sqlflow官网的案例和说明对sqlflow进行了体验，并记录下来。 sqlflow按照官网的定义，将SQL引擎（例如MySQL，Hive，SparkSQL或SQL Server）和tensorflow和其他机器学习的桥梁。扩展了SQL语言，支持对机器学习模型训练、预测和推理。 目前开源版本仅支持MySQL和TensorFlow 介绍文档中也提到，在sqlflow之前也有SQL引擎提供了支持机器学习功能的扩展。 Microsoft SQL Server：Microsoft SQL Server具有机器学习服务，可以将R或Python中的机器学习程序作为外部脚本运行。 Teradata SQL for DL：Teradata还提供RESTful服务，可以从扩展的SQL SELECT语法中调用。 Google BigQuery：Google BigQuery通过引入CREATE MODEL语句在SQL中实现机器学习。 第一部分 Sqlflow安装部署1.1 部署mysql做为数据源（1）构建镜像官网提供了一个dockerfile，可以git clone整个项目。 https://github.com/sql-machine-learning/sqlflow/tree/7c873780bd8a3a9ea4d39ed7d0fcf154b2f8821f/example/datasets 1234# 进入Dockerfile文件所在目录cd example/datasets# 使用Dockerfile构建镜像docker build -t sqlflow:data . 可以查看创建了一个docker images： 12docker images# 创建了REPOSITORY：sqlflow镜像，TAG为：data （2）启动mysql容器用镜像启mysql容器： 12345docker run --rm -d --name sqlflowdata \ -p 3306:3306 \ -e MYSQL_ROOT_PASSWORD=root \ -e MYSQL_ROOT_HOST=% \ sqlflow:data 使用镜像：sqlflow:data，启动一个名为：sqlflowdata的容器，并且把3306端口映射到宿主机。mysql的root用户的密码为root。 （3）生成测试数据进入容器： 1docker exec -it sqlflowdata bash 执行SQL语句： 12345# 建库建表，注意宿主机目录：datasetscat /popularize_churn.sql | mysql -uroot -prootcat /popularize_iris.sql | mysql -uroot -proot# 建库echo "CREATE DATABASE IF NOT EXISTS sqlflow_models;" | mysql -uroot -proot 至此完成mysql容器的启动和测试数据的生成。按Ctrl+P+Q，正常退出不关闭容器。 1.2 使用docker部署slqflow（1）拉取镜像并启动容器首先从docker Hub上拉取镜像： 1# docker pull sqlflow/sqlflow:latest 启动容器： 123# docker run --rm -it --name sqlflowServer -p 8888:8888 sqlflow/sqlflow:latest \bash -c "sqlflowserver --datasource='mysql://root:root@tcp(192.168.31.3:3306)/?maxAllowedPacket=0' &amp;SQLFLOW_SERVER=localhost:50051 jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root" 命令使用镜像：sqlflow/sqlflow:lates，启动了名为：sqlflowServer的容器。将8888端口映射到宿主机上。这里需要配置datasource，指向mysql使用套接字：192.168.31.3:3306。这里使用之前构建的mysql容器的连接信息，可以根据实际情况配置。 如果mysql套接字配置错误，报错信息：connect: connection refused 如果没有报错： 12345672019/05/06 14:47:30 Server Started at :50051[I 14:47:30.261 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret[I 14:47:30.874 NotebookApp] Serving notebooks from local directory: /[I 14:47:30.874 NotebookApp] The Jupyter Notebook is running at:[I 14:47:30.874 NotebookApp] http://(fd2b9b3f994b or 127.0.0.1):8888/?token=265b3fc832b5b48689fa9f88483125dc9335188dd7c1d863[I 14:47:30.874 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).[W 14:47:30.877 NotebookApp] No web browser found: could not locate runnable browser. 这里启动了Jupyter Notebook服务，对外服务端口为8888，并且映射到宿主机。例如这里可以使用下面的url范围web界面：http://192.168.31.3:8888/?token=265b3fc832b5b48689fa9f88483125dc9335188dd7c1d863 （2）简单测试Jupyter Notebook 新建一个python3交互环境。测试一下： 12%%sqlflowselect * from iris.train limit 5; 第二部分 机器学习例子使用iris数据集体验机器学习的例子，使用Jupyter Notebook 完成： （1）训练模型：12%%sqlflowSELECT * FROM iris.train TRAIN DNNClassifier WITH n_classes = 3, hidden_units = [10, 20] COLUMN sepal_length, sepal_width, petal_length, petal_width LABEL class INTO sqlflow_models.my_dnn_model; 使用iris.train表中的数据训练神经网络。 模型训练结果输入到sqlflow_models.my_dnn_model，回显训练正确率为：0.97273 12Training set accuracy: 0.97273Done training （2）模型应用使用训练结果对数据进行预测应用： 12%%sqlflowSELECT * FROM iris.test PREDICT iris.predict.class USING sqlflow_models.my_dnn_model; 使用iris.test中的数据喂给训练好的模型，预测结果输出到表：iris.predict。 1Done predicting. Predict table : iris.predict 查看结果表中的数据案例： 12%%sqlflowselect * from iris.predict limit 2 123456+--------------+-------------+--------------+-------------+-------+| sepal_length | sepal_width | petal_length | petal_width | class |+--------------+-------------+--------------+-------------+-------+| 6.3 | 2.7 | 4.9 | 1.8 | 2 || 5.7 | 2.8 | 4.1 | 1.3 | 1 |+--------------+-------------+--------------+-------------+-------+ 第三部分 系统架构系统原型使用下面的架构： 12SQL statement -&gt; our SQL parser --standard SQL-&gt; MySQL \-extended SQL-&gt; code generator -&gt; execution engine 原型运行的数据流为： 它通过MySQL Connector Python API从MySQL检索数据 从MySQL检索模型 通过调用用户指定的TensorFlow估算器训练模型或使用训练模型进行预测 并将训练过的模型或预测结果写入表格 参考文献及资料1、sqlflow项目官网 链接：https://github.com/sql-machine-learning/sqlflow 2、会 SQL 就能搞定 AI！蚂蚁金服重磅开源机器学习工具 SQLFlow 链接：https://www.infoq.cn/article/vlVqC68h2MT-028lh68C]]></content>
      <categories>
        <category>sqlflow</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hive介绍及部署]]></title>
    <url>%2F2018%2F08%2F14%2F2018-08-13-Hive-install%2F</url>
    <content type="text"><![CDATA[背景Hive（蜂巢）是Hadoop的组件，官方介绍为： Hive™: A data warehouse infrastructure that provides data summarization and ad hoc querying. Hive有三种部署方式（本质是Hive Metastore的三种部署方式）： Embedded Metastore Database (Derby) 内嵌模式 内嵌模式使用的是内嵌的Derby数据库来存储元数据，也不需要额外起Metastore服务。这个是默认的，配置简单，但是一次只能一个客户端连接（Derby只提供单进程存储），适用于用来实验，不适用于生产环境。 Local Metastore Server 本地元存储 采用外部数据库来存储元数据 。本地元存储不需要单独起metastore服务，用的是跟hive在同一个进程里的metastore服务 。 目前支持：Derby，Mysql，微软SQLServer，Oracle和Postgres Remote Metastore Server 远程元存储 采用外部数据库来存储元数据 。远程元存储需要单独起metastore服务，然后每个客户端都在配置文件里配置连接到该metastore服务。远程元存储的metastore服务和hive运行在不同的进程里。 远程元存储是生产环境部署方式。 本地部署过程 由于设备资源限制，没有太多机器配置类似生产环境的集群环境。所以通过docker搭建大集群环境。 搭建目标： 集群中hadoop集群由3台构成（1台master，2台slaves） Hive的元数据库使用Mysql，并且单独包裹在一个docker环境中。 环境准备准备hadoop集群环境。启docker集群： 1234CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc27312e13270 kiwenlau/hadoop:1.0 "sh -c 'service ssh …" 2 hours ago Up 2 hours hadoop-slave2f8b69885f3ef kiwenlau/hadoop:1.0 "sh -c 'service ssh …" 2 hours ago Up 2 hours hadoop-slave1439b359d230e kiwenlau/hadoop:1.0 "sh -c 'service ssh …" 2 hours ago Up 2 hours 0.0.0.0:8088-&gt;8088/tcp, 0.0.0.0:50070-&gt;50070/tcp hadoop-master Hive部署下载安装包：1234# 进入hadoop-master主机，进入hadoop目录：/use/local/hadoopwget http://apache.claz.org/hive/hive-2.3.3/apache-hive-2.3.3-bin.tar.gztar -zxvf apache-hive-2.3.3-bin.tar.gzmv apache-hive-2.3.3-bin hive 配置Hive环境变量：123456vi /etc/profile#hiveexport HIVE_HOME=/usr/local/hadoop/hivePATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$PATH# 生效环境变量source /etc/profile 调整Hive的配置文件：12345# 进入hive 配置文件目录：cd confcp hive-default.xml.template hive-site.xml# 修改配置文件vim hive-site.xml 新建HDFS分布式文件目录：12345678# hadoop已经设置好环境变量，新建下面目录hadoop fs -mkdir -p /user/hive/warehouse hadoop fs -mkdir -p /user/hive/tmp hadoop fs -mkdir -p /user/hive/log # 设置目录权限hadoop fs -chmod -R 777 /user/hive/warehouse hadoop fs -chmod -R 777 /user/hive/tmp hadoop fs -chmod -R 777 /user/hive/log 可以用下面命令进行检查： 12345root@hadoop-master:/usr/local/hadoop/hive/conf# hadoop fs -ls /user/hiveFound 3 itemsdrwxrwxrwx - root supergroup 0 2018-08-14 07:34 /user/hive/logdrwxrwxrwx - root supergroup 0 2018-08-14 07:34 /user/hive/tmpdrwxrwxrwx - root supergroup 0 2018-08-14 07:34 /user/hive/warehouse 修改配置文件（hive-site.xml）：hive数据仓库数据路径：/user/hive/warehouse 需要使用hdfs新建文件目录。 12345&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;description&gt;location of default database for the warehouse&lt;/description&gt;&lt;/property&gt; 配置查询日志存放目录： 12345&lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/user/hive/log/hadoop&lt;/value&gt; &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt; 数据库JDBC连接配置（172.18.0.5为mysql的ip地址，暴露3306端口）： 12345&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://172.18.0.5:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;description&gt;&lt;/property&gt; 数据库驱动： 12345&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt; 数据库用户名： 12345&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;Username to use against metastore database&lt;/description&gt;&lt;/property&gt; 数据库密码： 12345&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt; 配置Hive临时目录： 1mkdir /usr/local/hadoop/hive/tmp 并在 hive-site.xml 中修改: 把${system:java.io.tmpdir} 改成真实物理绝对路径 /usr/local/hadoop/hive/tmp 把 ${system:user.name} 改成 ${user.name} 可以在外面编辑好配置文件，拷贝进docke： 12&gt; docker cp hive-site.xml 439b359d230e:/usr/local/hadoop/hive/conf/hive-site.xml&gt; 配置hive-env.sh文件：尾部加上下面的配置（或者修改注释部分的配置亦可）： 123HADOOP_HOME=/usr/local/hadoopexport HIVE_CONF_DIR=/usr/local/hadoop/hive/confexport HIVE_AUX_JARS_PATH=/usr/local/hadoop/hive/lib 配置Mysql启mysql容器，容器名：first-mysql，使用和hadoop一个桥接网络hadoop，密码为123456 1docker run --name first-mysql --net=hadoop -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=123456 -d mysql:5.7 回显： 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES84ae224cee53 mysql:5.7 "docker-entrypoint.s…" 32 minutes ago Up 32 minutes 0.0.0.0:3306-&gt;3306/tcp first-mysql 在Hadoop-master中配置mysql客户端（用来访问mysql服务器）： 1apt-get install mysql-client-core-5.6 测试远程连接： 1mysql -h172.18.0.5 -P3306 -uroot -p123456 新建数据库，数据库名为hive： 12mysql&gt; CREATE DATABASE hive;Query OK, 1 row affected (0.00 sec) 初始化（Hive主机上）： 12cd /usr/local/hadoop/hive/bin./schematool -initSchema -dbType mysql 回显： 12345root@hadoop-master:/usr/local/hadoop/hive/bin# ./schematool -initSchema -dbType mysqlSLF4J: Class path contains multiple SLF4J bindings.。。。（略）schemaTool completed# 初始化成功 下载配置mysql驱动包，放在Hive的lib路径下面： 12cd /usr/local/hadoop/hive/libwget http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.38/mysql-connector-java-5.1.38.jar 启动Hive做完上面准备工作后，开始启动hive： 12345678910root@hadoop-master:/usr/local/hadoop/hive/bin# ./hiveSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/hadoop/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]Logging initialized using configuration in jar:file:/usr/local/hadoop/hive/lib/hive-common-2.3.3.jar!/hive-log4j2.properties Async: trueHive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.hive&gt; 最后进入hive的命令界面。 踩坑备注1、Hive提示SSL连接警告 1Tue Aug 14 10:53:12 UTC 2018 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification. 虽然Hive SQL执行成功，但是报上面的错误。产生的原因是使用JDBC连接MySQL服务器时为设置useSSL参数 。 解决办法：javax.jdo.option.ConnectionURL 配置的value值进行调整，设置useSSL=false ，注意xml中的语法。 12345678&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://172.18.0.5:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;description&gt; JDBC connect string for a JDBC metastore. To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL. For example, jdbc:postgresql://myhost/db?ssl=true for postgres database. &lt;/description&gt; 重启Hive，不再有警告。 远程部署对于远程部署需要单独启metastore服务，具体需要调整下面的配置文件（hive-site.xml）： 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://hadoop-master:9083&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动metastore服务： 1nohup hive --service metastore &amp; 当然这属于简单方式将Hive都扎堆部署在一个容器中。可以在集群其他几点启metastore服务，提升架构的高可用性，避免单点问题。 参考文献1、Apache Hive-2.3.0 快速搭建与使用，https://segmentfault.com/a/1190000011303459 2、Hive提示警告SSL，https://blog.csdn.net/u012922838/article/details/73291524]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用Cloudera Quickstart Docker镜像快速部署hadoop集群]]></title>
    <url>%2F2018%2F06%2F25%2F2019-04-30-%E4%BD%BF%E7%94%A8Cloudera%20Quickstart%20Docker%E9%95%9C%E5%83%8F%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2hadoop%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[背景参考文献及材料1、Minitube项目地址：https://github.com/kubernetes/minikube]]></content>
      <categories>
        <category>Docker hadoop</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[在Ubuntu上部署Minikube]]></title>
    <url>%2F2018%2F06%2F25%2F2018-06-25-%E5%9C%A8Ubuntu%E4%B8%8A%E9%83%A8%E7%BD%B2Minikube%2F</url>
    <content type="text"><![CDATA[[TOC] 背景Kubernetes是Google推出的容器编排工具，这是Google保密十几年的强大武器Borg的开源版本。Kubernetes这个名字源于古希腊，意思是舵手。既然docker被比喻成大海上驮着集装箱的鲸鱼，那么Kubernetes就是舵手，掌握鲸鱼的游弋方向，寓意深刻。 Kubernetes第一个正式版本于2015年7月发布。从Kubernetes 1.3开始提供了一个叫Minikube的强大测试工具，可以在主流操作系统平台（win、os、linux）上运行单节点的小型集群，这个工具默认安装和配置了一个Linux VM，Docker和Kubernetes的相关组件，并且提供Dashboard。 本篇主要介绍Ubuntu平台上部署Minikube。Minikube利用本地虚拟机环境部署Kubernetes，其基本架构如下图所示。 Minitube项目地址：https://github.com/kubernetes/minikube 第一部分 准备Minikube在OS X和Windows上部署需要安装虚拟机实现（用虚拟机来初始化Kubernetes环境），但是Linux例外可以使用自己的环境。参见：https://github.com/kubernetes/minikube#quickstart 1.1 准备工作检查CPU是否支持虚拟化，即BIOS中参数（VT-x/AMD-v ）设置为enable。 1.2 安装虚拟机Minikube在不同操作系统上支持不同的虚拟驱动： macOS xhyve driver, VirtualBox 或 VMware Fusion Linux VirtualBox 或 KVM 注意: Minikube 也支持 --vm-driver=none 选项来在本机运行 Kubernetes 组件，这时候需要本机安装了 Docker。 Windows VirtualBox 或 Hyper-V 本篇在Ubuntu部署VirtualBox虚拟驱动。 123# wget https://download.virtualbox.org/virtualbox/5.1.38/virtualbox-5.1_5.1.38-122592~Ubuntu~xenial_i386.deb#dpkg -i virtualbox-5.1_5.1.38-122592~Ubuntu~xenial_i386.deb 第二部分 安装minikube1234# curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v0.28.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/ % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 40.8M 100 40.8M 0 0 4671k 0 0:00:08 0:00:08 --:--:-- 7574k 第三部分 安装Kubectlkubectl即kubernetes的客户端，通过他可以进行类似docker run等容器管理操作 。 下载： 1234567# curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 52.5M 100 52.5M 0 0 6654k 0 0:00:08 0:00:08 --:--:-- 10.3M# chmod +x kubectl# mv kubectl /usr/local/bin/ 第四部分 启集群1234567891011121314151617root@deeplearning:~# minikube start --registry-mirror=https://registry.docker-cn.comStarting local Kubernetes v1.10.0 cluster...Starting VM...Downloading Minikube ISO 153.08 MB / 153.08 MB [============================================] 100.00% 0sGetting VM IP address...Moving files into cluster...Downloading kubeadm v1.10.0Downloading kubelet v1.10.0Finished Downloading kubelet v1.10.0Finished Downloading kubeadm v1.10.0Setting up certs...Connecting to cluster...Setting up kubeconfig...Starting cluster components...Kubectl is now configured to use the cluster.Loading cached images from config file. 进入minikube虚拟机： 123456789101112root@deeplearning:~# minikube ssh _ _ _ _ ( ) ( ) ___ ___ (_) ___ (_)| |/') _ _ | |_ __ /' _ ` _ `\| |/' _ `\| || , &lt; ( ) ( )| '_`\ /'__`\| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )( ___/(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)$ # 通过exit退出集群$ exitlogout 虚拟机地址： 12# minikube ip192.168.99.100 启停集群： 1# minikube start/stop 获取集群信息： 123root@deeplearning:/home/rongxiang# kubectl get node NAME STATUS ROLES AGE VERSIONminikube Ready master 7h v1.10.0 删除集群： 123# minikube delete # rm -rf ~/.minikube # kubeadm reset 第五部分 心酸踩坑如果在启集群时遇到下面类似的错误，不要慌。国内环境99%的原因是GFW的原因，集群在抓取Google站点docker镜像时候被墙咔嚓了，然后time out。 WTF！我开始不知道呀。网上的部署指引都那么轻松！！然后重复删除集群，重新装，配参数，给docker配代理。尼玛，最后代理都被咔嚓了。终于撞了南墙，去阿里云拉取镜像，几秒钟搞定。 1234567891011121314151617# minikube startStarting local Kubernetes v1.10.0 cluster...Starting VM...Getting VM IP address...Moving files into cluster...Setting up certs...Connecting to cluster...Setting up kubeconfig...Starting cluster components...E0626 12:57:46.868961 26526 start.go:299] Error restarting cluster: restarting kube-proxy: waiting for kube-proxy to be up for configmap update: timed out waiting for the condition================================================================================An error has occurred. Would you like to opt in to sending anonymized crashinformation to minikube to help prevent future errors?To opt out of these messages, run the command: minikube config set WantReportErrorPrompt false================================================================================Please enter your response [Y/n]: 第六部分 远程访问 minikube dashboard在虚拟机启动前，设置端口转发。注意这里使用tcp而不是http。 1# VBoxManage modifyvm "minikube" --natpf1 "kubedashboard,tcp,,30000,,30000" 然后启动虚拟机，这时候局域网上的其他服务器就可以通过宿主机的IP:30000访问web UI。 或者： 1# kubectl proxy --address='0.0.0.0' --disable-filter=true 附录 补充VBoxManage管理查询虚拟机： 123# VBoxManage list vms"&lt;inaccessible&gt;" &#123;4a3cefe1-11d1-45d2-91c5-1e39fccb6a8d&#125;"minikube" &#123;dfcd1bdf-afc1-49e6-a270-9d8ff14bf167&#125; 删除虚拟机： 1# VBoxManage unregistervm --delete 4a3cefe1-11d1-45d2-91c5-1e39fccb6a8d 参考文献及材料1、Minitube项目地址：https://github.com/kubernetes/minikube]]></content>
      <categories>
        <category>Minikube Ubuntu</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[在Minikube上运行Spark集群]]></title>
    <url>%2F2018%2F06%2F25%2F2018-08-06-%E5%9C%A8Minikube%E4%B8%8A%E8%BF%90%E8%A1%8CSpark%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[[TOC] 背景​ Spark2.3版本开始支持使用spark-submit直接提交任务给Kubernetes集群。执行机制原理： Spark创建一个在Kubernetes pod中运行的Spark驱动程序。 驱动程序创建执行程序，这些执行程序也在Kubernetes pod中运行并连接到它们，并执行应用程序代码。 当应用程序完成时，执行程序窗格会终止并清理，但驱动程序窗格会保留日志并在Kubernetes API中保持“已完成”状态，直到它最终被垃圾收集或手动清理。 第一部分 环境准备1.1 minikube虚拟机准备由于spark集群对内存和cpu资源要求较高，在minikube启动前，提前配置较多的资源给虚拟机。 当minikube启动时，它以单节点配置开始，默认情况下占用1Gb内存和2CPU内核，但是，为了运行spark集群，这个资源配置是不够的，而且作业会失败。 12345# minikube config set memory 8192These changes will take effect upon a minikube delete and then a minikube start# minikube config set cpus 2These changes will take effect upon a minikube delete and then a minikube start 或者用下面的命令启集群 1# minikube start --cpus 2 --memory 8192 1.2 Spark环境准备第一步 下载saprk2.3 1# wget http://apache.mirrors.hoobly.com/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz 解压缩： 1# tar xvf spark-2.3.0-bin-hadoop2.7.tgz 制作docker镜像 12# cd spark-2.3.0-bin-hadoop2.7# docker build -t rongxiang/spark:2.3.0 -f kubernetes/dockerfiles/spark/Dockerfile . 查看镜像情况： 123# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZErongxiang1986/spark 2.3.0 c5c806314f25 5 days ago 346MB 登录docker 账户： 12345# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: Password: Login Succeeded 将之前build好的镜像pull到docker hub上： 1# docker push rongxiang1986/spark:2.3.0 注意这里的格式要求（我踩坑了）：docker push 注册用户名/镜像名 在https://hub.docker.com/上查看，镜像确实push上去了。 第二部分 提交Spark作业2.1 作业提交提前配置serviceaccount信息。 1234# kubectl create serviceaccount sparkserviceaccount/spark created# kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=default:spark --namespace=defaultclusterrolebinding.rbac.authorization.k8s.io/spark-role created 提交作业： 12345678910# ./spark-submit \--master k8s://https://192.168.99.100:8443 \--deploy-mode cluster \--name spark-pi \--class org.apache.spark.examples.SparkPi \--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \--conf spark.kubernetes.authenticate.executor.serviceAccountName=spark \--conf spark.executor.instances=2 \--conf spark.kubernetes.container.image=rongxiang1986/spark:2.3.0 \local:///opt/spark/examples/jars/spark-examples_2.11-2.3.0.jar 提交命令的参数含义分别是： --class：应用程序的入口点（命令中使用：org.apache.spark.examples.SparkPi）； --master：Kubernetes集群的URL（k8s://https://192.168.99.100:8443）； --deploy-mode：驱动程序部署位置（默认值：客户端），这里部署在集群中； --conf spark.executor.instances=2：运行作业启动的executor个数； --conf spark.kubernetes.container.image=rongxiang1986/spark:2.3.0：使用的docker镜像名称； local:///opt/spark/examples/jars/spark-examples_2.11-2.3.0.jar：应用程序依赖jar包路径； 注意：目前deploy-mode只支持cluster模式，不支持client模式。 Error: Client mode is currently not supported for Kubernetes. 作业运行回显如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677782018-08-12 15:51:17 WARN Utils:66 - Your hostname, deeplearning resolves to a loopback address: 127.0.1.1; using 192.168.31.3 instead (on interface enp0s31f6)2018-08-12 15:51:17 WARN Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address2018-08-12 15:51:18 INFO LoggingPodStatusWatcherImpl:54 - State changed, new state: pod name: spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver namespace: default labels: spark-app-selector -&gt; spark-8be4d909d85148bc9f1f91d511c275c6, spark-role -&gt; driver pod uid: 7f6dd84d-9e04-11e8-b58f-080027b3a6c0 creation time: 2018-08-12T07:51:18Z service account name: spark volumes: spark-token-rzrgk node name: N/A start time: N/A container images: N/A phase: Pending status: []2018-08-12 15:51:18 INFO LoggingPodStatusWatcherImpl:54 - State changed, new state: pod name: spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver namespace: default labels: spark-app-selector -&gt; spark-8be4d909d85148bc9f1f91d511c275c6, spark-role -&gt; driver pod uid: 7f6dd84d-9e04-11e8-b58f-080027b3a6c0 creation time: 2018-08-12T07:51:18Z service account name: spark volumes: spark-token-rzrgk node name: minikube start time: N/A container images: N/A phase: Pending status: []2018-08-12 15:51:18 INFO LoggingPodStatusWatcherImpl:54 - State changed, new state: pod name: spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver namespace: default labels: spark-app-selector -&gt; spark-8be4d909d85148bc9f1f91d511c275c6, spark-role -&gt; driver pod uid: 7f6dd84d-9e04-11e8-b58f-080027b3a6c0 creation time: 2018-08-12T07:51:18Z service account name: spark volumes: spark-token-rzrgk node name: minikube start time: 2018-08-12T07:51:18Z container images: rongxiang1986/spark:2.3.0 phase: Pending status: [ContainerStatus(containerID=null, image=rongxiang1986/spark:2.3.0, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties=&#123;&#125;), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=ContainerCreating, additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;)]2018-08-12 15:51:18 INFO Client:54 - Waiting for application spark-pi to finish...2018-08-12 15:51:51 INFO LoggingPodStatusWatcherImpl:54 - State changed, new state: pod name: spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver namespace: default labels: spark-app-selector -&gt; spark-8be4d909d85148bc9f1f91d511c275c6, spark-role -&gt; driver pod uid: 7f6dd84d-9e04-11e8-b58f-080027b3a6c0 creation time: 2018-08-12T07:51:18Z service account name: spark volumes: spark-token-rzrgk node name: minikube start time: 2018-08-12T07:51:18Z container images: rongxiang1986/spark:2.3.0 phase: Running status: [ContainerStatus(containerID=docker://d43089c8340affc4534f796b94a90ae080670c36c095176575fbeebacaab648e, image=rongxiang1986/spark:2.3.0, imageID=docker-pullable://rongxiang1986/spark@sha256:3e93a2d462679015a9fb7d723f53ab1d62c5e3619e3f1564d182c3d297ddf75d, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties=&#123;&#125;), name=spark-kubernetes-driver, ready=true, restartCount=0, state=ContainerState(running=ContainerStateRunning(startedAt=Time(time=2018-08-12T07:51:51Z, additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;), terminated=null, waiting=null, additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;)]2018-08-12 15:51:57 INFO LoggingPodStatusWatcherImpl:54 - State changed, new state: pod name: spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver namespace: default labels: spark-app-selector -&gt; spark-8be4d909d85148bc9f1f91d511c275c6, spark-role -&gt; driver pod uid: 7f6dd84d-9e04-11e8-b58f-080027b3a6c0 creation time: 2018-08-12T07:51:18Z service account name: spark volumes: spark-token-rzrgk node name: minikube start time: 2018-08-12T07:51:18Z container images: rongxiang1986/spark:2.3.0 phase: Succeeded status: [ContainerStatus(containerID=docker://d43089c8340affc4534f796b94a90ae080670c36c095176575fbeebacaab648e, image=rongxiang1986/spark:2.3.0, imageID=docker-pullable://rongxiang1986/spark@sha256:3e93a2d462679015a9fb7d723f53ab1d62c5e3619e3f1564d182c3d297ddf75d, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties=&#123;&#125;), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=ContainerStateTerminated(containerID=docker://d43089c8340affc4534f796b94a90ae080670c36c095176575fbeebacaab648e, exitCode=0, finishedAt=Time(time=2018-08-12T07:51:57Z, additionalProperties=&#123;&#125;), message=null, reason=Completed, signal=null, startedAt=Time(time=2018-08-12T07:51:51Z, additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;), waiting=null, additionalProperties=&#123;&#125;), additionalProperties=&#123;&#125;)]2018-08-12 15:51:57 INFO LoggingPodStatusWatcherImpl:54 - Container final statuses: Container name: spark-kubernetes-driver Container image: rongxiang1986/spark:2.3.0 Container state: Terminated Exit code: 02018-08-12 15:51:57 INFO Client:54 - Application spark-pi finished.2018-08-12 15:51:57 INFO ShutdownHookManager:54 - Shutdown hook called2018-08-12 15:51:57 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-6dd1c204-4ad7-40c4-b47f-a34f18e1995d 2.2 日志查询可以通过命令查看容器执行日志，或者通过kubernetes-dashboard提供web界面查看。 1# kubectl logs spark-pi-709e1c1b19813e7cbc1aeff45200c64e-driver 1234567891011121314152018-08-12 07:51:57 INFO DAGScheduler:54 - Job 0 finished: reduce at SparkPi.scala:38, took 0.576528 sPi is roughly 3.13367566837834182018-08-12 07:51:57 INFO AbstractConnector:318 - Stopped Spark@9635fa&#123;HTTP/1.1,[http/1.1]&#125;&#123;0.0.0.0:4040&#125;2018-08-12 07:51:57 INFO SparkUI:54 - Stopped Spark web UI at http://spark-pi-7314d819cd3730b4bf7d02bfedd21373-driver-svc.default.svc:40402018-08-12 07:51:57 INFO KubernetesClusterSchedulerBackend:54 - Shutting down all executors2018-08-12 07:51:57 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Asking each executor to shut down2018-08-12 07:51:57 INFO KubernetesClusterSchedulerBackend:54 - Closing kubernetes client2018-08-12 07:51:57 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!2018-08-12 07:51:57 INFO MemoryStore:54 - MemoryStore cleared2018-08-12 07:51:57 INFO BlockManager:54 - BlockManager stopped2018-08-12 07:51:57 INFO BlockManagerMaster:54 - BlockManagerMaster stopped2018-08-12 07:51:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!2018-08-12 07:51:57 INFO SparkContext:54 - Successfully stopped SparkContext2018-08-12 07:51:57 INFO ShutdownHookManager:54 - Shutdown hook called2018-08-12 07:51:57 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-435d5ab2-f7b4-45d0-a00f-0bd9f162f9db 执行结束后executor pod被自动清除。计算得到pi的值为： 1Pi is roughly 3.1336756683783418 如果作业通过cluster提交，driver容器会被保留，可以查看： 123456789# minikube service list|-------------|------------------------------------------------------|-----------------------------|| NAMESPACE | NAME | URL ||-------------|------------------------------------------------------|-----------------------------|| default | kubernetes | No node port || default | spark-pi-27fcc168740e372292b27185d124ad7b-driver-svc | No node port || kube-system | kube-dns | No node port || kube-system | kubernetes-dashboard | http://192.168.99.100:30000 ||-------------|------------------------------------------------------|-----------------------------| 参考文献1、Running Spark on Kubernetes ：https://spark.apache.org/docs/latest/running-on-kubernetes.html 2、在Minikube Kubernetes集群上运行Spark工作：https://iamninad.com/running-spark-job-on-kubernetes-minikube/]]></content>
      <categories>
        <category>Minikube spark Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[5分钟介绍深度学习（科普）]]></title>
    <url>%2F2018%2F04%2F16%2F2018-04-15-network_intro%2F</url>
    <content type="text"><![CDATA[历史背景最近几年Deep Learning、AI人工智能、机器学习等名词称为新闻热点，特别是Google Deep mind的Alpha Go战胜韩国棋手李世石，让深度学习妇孺皆知。 首先从概念范畴上讲，deep learning属于机器学习的一个分支，追根溯源其实是人工神经网络。顾名思义，人工神经网络是借鉴人类神经网路的结构原型，算生物仿生学（虽然人类到现在也没弄明白大脑原理）。 例如下面就是一个3层结构的人工神经网络（1个输入层、1个隐藏层、1个输出层）。 1989年Yann LeCun使用反向传播算法（Back Propagation）应用于多层神经网络训练。但一旦层数较大，网络的参数和训练计算量成倍增加，通常需要几周时间才能完成参数训练，另外反向传播算法容易梯度爆炸。研究人员获得好的结果，时间成本太大。 所以当时机器学习研究方向中，支持向量机（SVM）算法比多层神经网络更为热门，神经网络研究则相当冷门。 直到2012 年的ImageNet 图像分类竞赛中，Alex Krizhevsky使用CNN（卷积）多层网络（共8层、6千万个参数）赢得当年的比赛，领先第二名10.8个百分点。并且模型使用GPU芯片训练、引入正则技术（Dropout）。 从此多层神经网络成为机器学习中的研究热点。而为了“洗白”以前暗淡历史，被赋予了新的名称：Deep Learning。 深度学习背后的数学目前的人工智能均属于弱人工智能（不具备心智和意识）。事实上，深度学习目前主要在图像识别和声音识别场景中获得较好的效果。深度学习的成为热点，依赖于两方面条件的成熟: 算力的提升，训练中大量使用GPU。 大量数据的获得和沉淀。 弱人工智能背后的理论基础依赖于数学和统计理论，其实更应该算数据科学的范畴。 比如输入数据具有$m$维特征，而输出特征为$k$维（例如如果是个二分类问题，$k=2$）。我们使用3层神经网络（输入层为$m$维，即含有$m$个神经元；隐藏层为$n$维，输出层为$k$维）用来训练。 通常我们将输入数据看成$R^m$（$m$维欧几里得空间），输出数据看成$R^k$（$k$维欧式空间）,如下图： 从数学上看，神经网络的结构定义了一个函数空间：${R^{n}} \xrightarrow{\text{f}} {R^{h}} \xrightarrow{\text{g}} {R^{m}}$ 。这个函数空间中元素是非线性的（隐藏层和输出层有非线性的激活函数）。空间中每个函数由网络中的参数（w，b）唯一决定。 神经网络训练的过程可以形象的理解为寻找最佳函数的过程：输入层“吃进”大量训练数据，通过非线性函数的作用，观察输出层输出结果和实际值的差异。这是一个监督学习的过程。 如果差异（误差）在容忍范围内，停止训练，认为该函数是目标函数。 如果差异较大，反向传播算法根据梯度下降的反向更新网络中的参数（w，b），即挑选新的函数。 重新喂进数据，计算新挑选函数的误差。如此循环，直到找到目标函数（也可设置提前结束训练）。 为什么神经网络的发展最后偏向的是“深度”呢？即增加层数来提高网络的认知能力。为什么没有“宽度学习”？即增加网络隐藏层的维度（宽度）。 其实从数学上可以证明深度网络和“宽度网络”的等价性。证明提示：考虑网络定义的函数空间出发。 写在最后（畅想未来）深度学习的局限性思考目前深度学习被各行各业应用于各种场景，而且有些特定场景取得了良好结果。但是传统的深度学习仍属于监督学习，更像一个被动的执行者，按照人类既定的规则，吃进海量数据，然后训练。 那么深度网络是否真的理解和学到了模式？还是只学会对有限数据的模式识别？甚至就是一个庞大的记忆网络？这都是值得我们深度思考的。 GAN对抗网络那么怎么能说明模型真的学习并理解了。我们提出了一个原则：如果你理解了一个事物，那么你就可以创造它。这样就发明了GAN对抗网络。让网络自己去创造事物，然后用现实数据去监督，当网络的创造能力和现实接近时，我们认为网络学会了。 其实思想类似传统的遗传算法。 强化学习另外传统的深度学习，输入的环境（数据）是固定的。然而现实中我们学习过程其实是：环境（数据）与学习个体互相作用的交互过程。这个学习过程人类由于时间有限，是个漫长的过程。但是计算机有个天然优势，可以同时启用成千上万的学习个体完成与环境数据的交互学习过程。例如Alpha Go启用上万个体，两两互搏，配上强大算力，短时间完成学习，这是人类不可企及的。 迁移学习人类学习中还有个方法叫：触类旁通。其实就是不同场景训练模型的借鉴。例如A场景得到训练好的模型（网络参数），对于新的场景B，可以尝试直接用A场景的网络（或部分使用，拼接），以此来减少训练成本。 那么新的问题来了：是否具有统一的迁移标准，即什么模型是适合迁移的？如果这些问题没有理论基础支持，迁移学习也摆脱不了“炼丹术”的非议。 深度学习从过去的暗淡无色到现在的光耀夺目。 然而任何方法都是有边际效应的。 人工智能的终点还很遥远，谁是下一颗耀眼的明星，需要学界和工业界共同探索。 ​ ​ 2018年4月15日 夜]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>BP， network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机语言中编译和解释的总结]]></title>
    <url>%2F2018%2F04%2F14%2F2018-04-14-interprete_and_compile%2F</url>
    <content type="text"><![CDATA[非计算机科班，主要是总结给自己看的，如果有表达错误，请大家指正。 几个概念高级语言与低级语言高级语言（High Level Programming Language）和低级语言（Low Level Programming Language）是一对相对的共生概念（没有一个严格的量化区分标准）。 低级语言更接近计算机底层资源（直接与硬件资源进行交互）。例如汇编语言。 高级语言进行了封装和抽象，语言设计更容易被人类思维逻辑所理解（和低级语言比较，学习曲线较缓）。例如C、C++、java、python等。 随着计算机语言的蓬勃发展（计算机语言的文艺复兴），过去一些高级语言，也有人重新定位成低级语言，例如C语言。 字节码与机器码字节码（Byte Code）不是一种计算机语言。属于高级语言预编译生成的中间码。高级语言源码在预编译的过程中，就完成这部分工作，生成字节码。 机器码（Machine Code）是一组可以直接被CPU执行的指令集。所有语言（低级和高级）最后都需要编译或解释成机器码（CPU指令集），才能执行。 编译器和解释器编译器（Interpreter） A compiler is a computer program (or a set of programs) that transforms source code written in a programming language (the source language) into another computer language (the target language), with the latter often having a binary form known as object code. The most common reason for converting source code is to create an executable program. 编译器是一种计算机程序。 编译器是一个计算机语言的翻译工具，直接将源代码文件预编译（形象的说：翻译）成更低级的代码语言（字节码码、机器码）。 编译器不会去执行编译的结果，只生成编译的结果文件。 解释器（Compiler） In computer science, an interpreter is a computer program that directly executes, i.e. performs, instructions written in a programming or scripting language, without previously compiling them into a machine language program. An interpreter generally uses one of the following strategies for program execution: 1、parse the source code and perform its behavior directly. 2、translate source code into some efficient intermediate representation and immediately execute this. 3、explicitly execute stored precompiled code made by a compiler which is part of the interpreter system. 解释器是一种计算机程序。 解释器读取源代码或者中间码文件，转换成机器码并与计算机硬件交互。即逐行执行源码。 解释器会将源代码转换成一种中间代码不会输出更低级的编译结果文件。输出执行结果。 解释型语言和编译型语言两者的区别主要是源码编译时间的差异。相同点都要翻译成机器码后由计算机执行。 编译型语言 编译语言的源码文件需要提前通过编译器编译成机器码文件（比如win中的exe可执行文件）。 执行时，只需执行编译结果文件。不需要重复翻译。 这类语言有：C、C++、Fortran、Pascal等。 解释型语言 解释型语言在运行时进行翻译。比如VB语言，在执行的时候，解释器将语言翻译成机器码，然后执行。 这类语言有：Ruby、Perl、JavaScript、PHP等。 混合型语言但是随着计算机语言的发展，有些语言兼具两者的特点。 JAVA语言 JAVA编译过程只是将.java文件翻译成字节码（Byte Code）（.class文件）。字节码文件交由java虚拟机（JVM）解释运行。也就是说Java源码文件既要编译也要JVM虚拟机进行解释后运行。所以有种说法认为Java是半解释型语言（semi-interpreted” language）。 Python语言 python其实类似Java。例如一个python文件test.py ，解释器首先尝试读取该文件历史编译结果（pyc文件）即test.pyc文件或者test.pyo 。如果没有历史文件或者编译文件的日期较旧（即py文件可能有更新），解释器会重新编译生成字节码文件（pyc文件），然后Python虚拟机对字节码解释执行。 参考【1】 你知道「编译」与「解释」的区别吗？]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>interpreter， compiler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Python语言中import机制]]></title>
    <url>%2F2018%2F04%2F14%2F2018-04-14-python_import%2F</url>
    <content type="text"><![CDATA[包和模块首先要介绍Python中两个概念：包和模块。简单的理解（从文件系统角度），包（package）是一个文件夹，而模块（module）是一个python源码文件（扩展名为.py）。 包（package）：文件夹（文件夹中含有文件__init__.py），包里面含有很多模块组成。 __init__.py文件，在里面自定义初始化操作，或为空。 模块（module）：即python文件，文件中定义了函数、变量、常量、类等。 Import 方法Import 模块方法先看一个例子。我们经常使用的模块math ，背后对应其实是一个python文件：math.py 。该文件在C:\Anaconda3\Lib\site-packages\pymc3目录里面（具体环境会有差异）。 123import mathmath.sqrt(2)#1.4142135623730951 如果只要import math.py中具体的函数： 123from math import sqrt，sinsqrt(2)sin（1） 另外可以将模块中所有内容导入： 12from math import *sqrt(2) Import 包方法包（package）可以简单理解为文件夹。该文件夹下须存在 __init__.py 文件, 内容可以为空。另外该主文件夹下面可以有子文件夹，如果也有 __init__.py 文件，这是子包。类似依次嵌套。 例如Tensorflow的包（文件树）： 123456789101112root@vultr:~/anaconda3/lib/python3.6/site-packages/tensorflow# tree -L 1.├── aux-bin├── contrib├── core├── examples├── include├── __init__.py├── libtensorflow_framework.so├── __pycache__├── python└── tools __init__.py 文件在import包时，优先导入，作为import包的初始化。 我们以Tensorflow为例： 12345678#导入包import tensorflow as tf#导入子包：contribimport tensorflow.contrib as contribfrom tensorflow import contrib#导入具体的模块：mnistfrom tensorflow.examples.tutorials import mnistimport tensorflow.examples.tutorials.mnist 命名空间（namespace）Namespace是字典数据，供编译器、解释器对源代码中函数名、变量名、模块名等信息进行关联检索。 定义Python语言使用namespace（命名空间）来存储变量，namespace是一个mapping（映射）。namespace可以理解是一个字典（dict）数据类型，其中键名（key）为变量名，而键值（value）为变量的值。 A namespace is a mapping from names to objects. Most namespaces are currently implemented as Python dictionaries。 每一个函数拥有自己的namespace。称为local namespace（局部命名空间），记录函数的变量。 每一个模块（module）拥有自己的namespace。称为global namespace（全局命名空间），记录模块的变量，包括包括模块中的函数、类，其他import（导入）的模块，还有模块级别的变量和常量。 每一个包（package）拥有自己的namespace。 也是global namespace ，记录包中所有子包、模块的变量信息。 Python的built-in names（内置函数、内置常量、内置类型）。 即内置命名空间。在Python解释器启动时创建，任何模块都可以访问。当退出解释器后删除。 命名空间的检索顺序当代码中需要访问或获取变量时（还有模块名、函数名），Python解释器会对命名空间进行顺序检索，直到根据键名（变量名）找到键值（变量值）。查找的顺序为（LEGB）： local namespace，即当前函数或者当前类。如找到，停止检索。 enclosing function namespace，嵌套函数中外部函数的namespace。 global namespace，即当前模块。如找到，停止检索。 build-in namespace，即内置命名空间。如果前面两次检索均为找到，解释器才会最后检索内置命名空间。如果仍然未找到就会报NameRrror（类似：NameError: name &#39;a&#39; is not defined）。 举栗子讲完了理论介绍，我们来举栗子，直观感受一下。 12345678910111213#进入python环境Python 3.5.3 |Anaconda custom (64-bit)| (default, May 11 2017, 13:52:01) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print(globals())&#123;'__name__': '__main__', '__doc__': None, '__spec__': None, '__package__': None, '__loader__': &lt;class '_frozen_importlib.BuiltinImporter'&gt;, '__builtins__': &lt;module 'builtins' (built-in)&gt;&#125;&gt;&gt;&gt; x=1&gt;&gt;&gt; print(globals())&#123;'__name__': '__main__', '__doc__': None, '__spec__': None, '__package__': None, '__loader__': &lt;class '_frozen_importlib.BuiltinImporter'&gt;, '__builtins__': &lt;module 'builtins' (built-in)&gt;, 'x': 1&#125; 上面的例子我们查看了global namespace的字典（dict），其中&#39;__builtins__&#39;就是内置命名空间。新建变量x=1后，全局命名空间会新增这个K-V对。 还可以通过下面的方法查看import模块、包的namespace。 当我们import一个module（模块）或者package（包）时，伴随着新建一个global namespace（全局命名空间）。 1234567891011import mathmath.__dict__&#123;'__name__': 'math', 'tanh': &lt;built-in function tanh&gt;, 'nan': nan, 'atanh': &lt;built-in function atanh&gt;,'acosh': &lt;built-in function acosh&gt;, #中间略'trunc': &lt;built-in function trunc&gt;, 'acos': &lt;built-in function acos&gt;, 'sqrt': &lt;built-in function sqrt&gt;, 'floor': &lt;built-in function floor&gt;, 'gamma': &lt;built-in function gamma&gt;, 'cosh': &lt;built-in function cosh&gt;&#125;import tensorflowtensorflow.__dict__#包的所有模块、函数等命名空间信息。大家可以试一下。 大家可以动手试试其他的场景，比如函数内部查看locals() 。函数内部的变量global声明后，查看globals()字典会有怎样变化。这里就不再一一验证举栗了。 对于包，我们以tensorflow为例： 123456import tensorflowtensorflow.__dict__##中间略，只摘取部分信息。命名空间中包含module和function的信息。'angle': &lt;function tensorflow.python.ops.math_ops.angle&gt;, 'app': &lt;module 'tensorflow.python.platform.app' from '/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py'&gt;, 'arg_max': &lt;function tensorflow.python.ops.gen_math_ops.arg_max&gt;, Import的过程当我们执行import 模块、包时，主要有三个过程：检索、加载、名字绑定。 第一步：检索（Finder）Python解释器会对模块所属位置进行搜索： （1）检索：内置模块（已经加载到缓存中的模块）内置模块（已经加载到缓存中的模块），即在 sys.modules 中检索。Python已经加载到内存中的模块均会在这个字典中进行登记。如果已经登记，不再重复加载。直接将模块的名字加入正在import的模块的namespace。可以通过下面方法查看： 123456789&gt;&gt;&gt; import sys&gt;&gt;&gt; print(sys.modules)&#123;'_signal': &lt;module '_signal' (built-in)&gt;, 'os.path': &lt;module 'ntpath' from 'C:\Anaconda3\\lib\\ntpath.py'&gt;,pickle': &lt;module 'pickle' from 'C:\\Anaconda3\\lib\\pickle.py'&gt;, #中间略'subprocess':module 'subprocess' from 'C:\\Anaconda3\\lib\\subprocess.py'&gt;, 'sys': &lt;module 'ys' (built-in)&gt;, 'ctypes.util': &lt;module 'ctypes.util' from 'C:\\Anaconda3\\lib\ctypes\\util.py'&gt;, '_weakref': &lt;module '_weakref' (built-in)&gt;, '_imp': &lt;module_imp' (built-in)&gt;&#125; 如果不是built-in，value中会有模块的绝对路径信息。 通过key查找模块位置，如果value为None，就会抛出错误信息：ModuleNotFoundError。 如果key不存在，就会进入下一步检索。 如果我们导入过包，例如tensorflow。 注意如果要使用其中模块，需要该模块的全名（即全路径信息），例如：tensorflow.examples.tutorials.mnist.input_data 。因为sys.modules中只有全路径的key。 1234import tensorflowprint(sys.modules)##这个字典中会有tensorflow所有子包、模块的信息和具体的路径。#'tensorflow.examples.tutorials.mnist.input_data': &lt;module 'tensorflow.examples.tutorials.mnist.input_data' from '/root/anaconda3/lib/python3.6/site-packages/tensorflow/examples/tutorials/mnist/input_data.py'&gt; （2）检索 sys.meta_path逐个遍历其中的 finder 来查找模块。否则进入下一步检索。 （3）检索模块所属包目录如果模块Module在包（Package）中（如import Package.Module），则以Package.__path__为搜索路径进行查找。 （4）检索环境变量 如果模块不在一个包中（如import Module），则以 sys.path 为搜索路径进行查找。 如果上面检索均为找到，抛出错误信息：ModuleNotFoundError。 第二步：加载（Loader）加载完成对模块的初始化处理： 设置属性。包括__name__、__file__、__package__和__loader__ 。 编译源码。编译生成字节码文件（.pyc文件），如果是包，则是其对应的__init__.py文件编译为字节码（*.pyc）。如果字节码文件已存在且仍然是最新的（时间戳和py文件一致），则不会重新编译。 加载到内存。模块在第一次被加载时被编译，载入内存，并将信息加入到sys.modules中。 也可以强制用reload()函数重新加载模块（包）。 第三步：名字绑定将模块和包的命名空间信息导入到当前执行Python文件的namespace（命名空间）。 将模块、包的路径加入检索路径讲完了枯燥的理论背景，下面我们来介绍实际应用。当你写好一个模块文件，如何正确完成import模块？主要有下面两类方法： 动态方法（sys.path中添加）我们知道检索路径中sys.path，所以可以在import模块之前将模块的绝对路径添加到sys.path中。同样导入包需要加入包的文件夹绝对路径。具体方法如下： 12345import sys##sys.path.append(dir)sys.path.append('your\module（package）\file\path')##sys.path.insert(pos,dir)sys.path.insert(0,'your\module（package）\file\path') 注意： 1、这里pos参数是插入sys.path这个list数据的位置，pos=0，即list第一位，优先级高。 2、python程序向sys.path添加的目录只在此程序的生命周期之内有效。程序结束，失效。所以这是一种动态方法。 123456789#win7import sysprint(sys.path)#输出['', 'C:\\Python27\\lib\\site-packages\\pip-8.1.1-py2.7.egg', 'C:\\windows\\system32\\python27.zip', 'C:\\Python27\\DLLs', 'C:\\Python27\\lib', 'C:\\Python27\\lib\\plat-win', 'C:\\Python27\\lib\\lib-tk', 'C:\\Python27', 'C:\\Users\\rongxiang\\AppData\\Roaming\\Python\\Python27\\site-packages', 'C:\\Python27\\lib\\site-packages'] 静态方法（1）另外检索路径还有系统环境变量，所以可以将模块（包）路径添加在系统环境变量中。 （2）粗暴一点直接将模块（包）拷贝到sys.path的其中一个路径下面。但是这种管理比较乱。 （3）Python在遍历sys.path的目录过程中，会解析 .pth 文件，将文件中所记录的路径加入到 sys.path ，这样 .pth 文件中的路径也可以找到了。例如我们在C:\Python27\lib\site-packages 中新建一个.pth文件。例如： 12# .pth file for the your module or package'your\module（package）\file\path' 这样在模块（包）上线时，我们只需要将模块（包）的目录或者文件绝对路径放在新建的.path文件中即可。 参考文章【1】http://www.cnblogs.com/russellluo/p/3328683.html#_3]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>import</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据科学实践中常用开放数据集介绍]]></title>
    <url>%2F2018%2F04%2F05%2F2018-04-01-datasets_example%2F</url>
    <content type="text"><![CDATA[介绍数据科学研究的对象是数据，学习过程中需要相关数据集辅助大家练习、做实验。从而体会数据科学中算法方法论。中国古语云：巧妇难有无米之炊，说的就是数据对于数据科学学习的重要性。 这篇文章收集介绍了各种常用的开放数据集，供大家学习参考。会持续更新。 开放数据集这里主要将开放数据分为三类：图像类、自然语言（NLP）类、音频类。 图像类MNIST手写数据集 介绍： MNIST（全称：Modified National Institute of Standards and Technology database）数据集是常见的深度学习开放数据集（基本属于深度学习的hello world数据集）。这是一个手写阿拉伯数据集（0-9数字），数据主要采集于美国高中学生。数据集总量为7W个手写数字图像（训练集6w个、测试机1w个）。 文件 内容 train-images-idx3-ubyte.gz 训练集图片 - 60000张训练图片 train-labels-idx1-ubyte.gz 训练集图片对应的数字标签（0-9） t10k-images-idx3-ubyte.gz 测试集图片 - 10000 张 图片 t10k-labels-idx1-ubyte.gz 测试集图片对应的数字标签 数据存储大小：二进制文件，50M，压缩形式约10M。每张图像被归一化成28*28的像素矩阵。 图像数据格式：像素值为0到255. 0表示背景（白色），255表示前景（黑色）。例如下面手写数字1的数据矩阵表示： 官方网页连接：http://yann.lecun.com/exdb/mnist/ 读取数据案例（Python）： Tensorflow中已经有对MNIST数据集解析的脚本，我们可以直接调用： 文件 目的 input_data.py、mnist.py 用于读取MNIST数据集 12345678910111213141516import tensorflow as tf#tf为1.7版本import numpy as npfrom tensorflow.examples.tutorials.mnist import input_datadata_dir = '/root/tftest/mnistdata/'#data_dir为数据集文件存放目录mnist = input_data.read_data_sets(data_dir, one_hot=True，validation_size=5000)#mnist = input_data.read_data_sets(data_dir, one_hot=False)#one_hot参数True，表示标签进行one-hot编码处理。#validation_size参数可以从训练集中划出一部分数据作为验证集。默认是5w个，可以自己调节。x_train,y_train,x_test,y_test,x_vali,y_vali = \mnist.train.images,mnist.train.labels,mnist.test.images,mnist.test.labels,\mnist.validation.images,mnist.validation.labels#x_train的数据类型为：&lt;class 'numpy.ndarray'&gt; ​ 上面的例子划分好数据就可以喂给各种算法模型进行训练。 扩展：EMNIST数据集：https://arxiv.org/abs/1702.05373。 按照MNIST规范，数据集更大：包含240,000个训练图像和40,000个手写数字测试图像。 MS-COCO图像分割数据集 介绍： MS-COCO（全称是Common Objects in Context）是微软团队提供的一个可以用来进行图像识别的数据集。数据集中的图像分为训练、验证和测试集。COCO数据集现在有3种标注类型：object instances（目标实例）, object keypoints（目标上的关键点）, 和image captions（看图说话），使用JSON文件存储。 一共有33w张图像，80个对象类别，每幅图5个字母、25w个关键点。 数据存储大小：约25G（压缩形式） 数据格式：中文介绍可以参考知乎这篇文章：COCO数据集的标注格式 。 官方网站：http://mscoco.org/ ImageNet图像数据集 介绍： Imagenet是深度学习中大名鼎鼎的数据集。数据集有1400多万幅图片，涵盖2万多个类别；其中有超过百万的图片有明确的类别标注和图像中物体位置的标注。深度学习中关于图像分类、定位、检测等研究工作大多基于此数据集展开。Imagenet数据集文档详细，有专门的团队维护，使用非常方便，在计算机视觉领域研究论文中应用非常广，几乎成为了目前深度学习图像领域算法性能检验的“标准”数据集。 数据存储大小：约150G 官方网站：http://www.image-net.org/ Open Image图像数据集 介绍： Open Image为Google提供。数据集包含近900万个图像URL。这些图像已经用数千个类的图像级标签边框进行了注释。该数据集包含9,011,219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。 数据大小：500G 官方网站：https://github.com/openimages/dataset VisualQA图像数据库 介绍： VQA是一个包含有关图像的开放式问题的数据集。这些问题需要理解视野和语言。数据集有265,016张图片。 数据大小：25G 官方网站：http://www.visualqa.org/ The Street View House Numbers (SVHN) Dataset街边号码牌数据集 介绍： SVHN图像数据集用于开发机器学习和对象识别算法，对数据预处理和格式化的要求最低。它可以被看作与MNIST相似，但是将更多标记数据（超过600,000个数字图像）并入一个数量级并且来自显着更难以解决的真实世界问题（识别自然场景图像中的数字和数字）。SVHN数据从谷歌街景图片中的房屋号码中获得的。书记含有用于训练的73257个数字，用于测试的26032个数字以及用作额外训练数据的531131个附加数字。 数据集大小： [train.tar.gz]， [test.tar.gz]， [extra.tar.gz ] 共三个文件。 官方网站：http://ufldl.stanford.edu/housenumbers/ CIFAR-10图像数据集 介绍： CIFAR-10数据集由10个类的60,000个图像组成（每个类在上图中表示为一行）。总共有50,000个训练图像和10,000个测试图像。数据集分为6个部分 - 5个培训批次和1个测试批次。每批有10,000个图像。 数据大小：170M 官方网站：http://www.cs.toronto.edu/~kriz/cifar.html Fashion-MNIST 介绍 Fashion-MNIST包含60,000个训练图像和10,000个测试图像。它是一个类似MNIST的时尚产品数据库。开发人员认为MNIST已被过度使用，因此他们将其作为该数据集的直接替代品。每张图片都以灰度显示，并与10个类别的标签相关联。 数据集大小：30M 官方网站：https://github.com/zalandoresearch/fashion-mnist 自然语言类数据库IMDB电影评论数据集 介绍： 这是电影爱好者的梦幻数据集。它具有比此领域以前的任何数据集更多的数据。除了训练和测试评估示例之外，还有更多未标记的数据供您使用。原始文本和预处理的单词格式包也包括在内。 数据集大小：80 M 官方网站：http://ai.stanford.edu/~amaas/data/sentiment/ 模型案例：https://arxiv.org/abs/1705.09207 Twenty Newsgroups Data Set 介绍： 该数据集包含有关新闻组的信息。为了管理这个数据集，从20个不同的新闻组中获取了1000篇Usenet文章。这些文章具有典型特征，如主题行，签名和引号。 数据集大小：20 M 官方网站：https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups 模型案例：https://arxiv.org/abs/1606.01781 Sentiment140情感分析数据集 介绍： Sentiment140是一个可用于情感分析的数据集。 数据集大小：80 M 官方网站：http://help.sentiment140.com/for-students/ 模型案例：http://www.aclweb.org/anthology/W17-5202 WordNet 介绍： WordNet是英语synsets的大型数据库。Synsets是同义词组，每个描述不同的概念。WordNet的结构使其成为NLP非常有用的工具。 数据集大小：10 M 官方网站：https://wordnet.princeton.edu/ 模型案例：https://aclanthology.info/pdf/R/R11/R11-1097.pdf Yelp评论 介绍： 这是Yelp为了学习目的而发布的一个开放数据集。它由数百万用户评论，商业属性和来自多个大都市地区的超过20万张照片组成。这是一个非常常用的全球NLP挑战数据集。 数据集大小：2.66 GB JSON，2.9 GB SQL和7.5 GB照片（全部压缩） 官方网站：https://www.yelp.com/dataset 模型案例：https://arxiv.org/pdf/1710.00519.pdf 维基百科语料库 介绍： 该数据集是维基百科全文的集合。它包含来自400多万篇文章的将近19亿字。什么使得这个强大的NLP数据集是你可以通过单词，短语或段落本身的一部分进行搜索。 数据集大小： 20 MB 官方网站：https://corpus.byu.edu/wiki/ 模型案例：https://arxiv.org/pdf/1711.03953.pdf 博客作者身份语料库 介绍： 此数据集包含从数千名博主收集的博客帖子，从blogger.com收集。每个博客都作为一个单独的文件提供。每个博客至少包含200次常用英语单词。 数据集大小： 300 MB 官方网站：http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm 模型案例：https://arxiv.org/pdf/1609.06686.pdf 欧洲语言的机器翻译 介绍： 数据集包含四种欧洲语言。 数据集大小： 约15 G 官方网站：http://statmt.org/wmt11/translation-task.html 模型案例：https://arxiv.org/abs/1706.03762 音频/语音数据集口语数字数据集 介绍： 为了解决识别音频样本中的口头数字的任务而创建。这是一个开放的数据集，所以希望随着人们继续贡献更多样本，它会不断增长。 数据集大小： 约10 G=M 记录数量：1500个音频样本 官方网站：https://github.com/Jakobovski/free-spoken-digit-dataset 模型案例：https://arxiv.org/pdf/1712.00866 免费音乐档案（FMA） 介绍： FMA是音乐分析的数据集。数据集由全长和HQ音频，预先计算的特征以及音轨和用户级元数据组成。它是一个开放数据集，用于评估MIR中的几个任务。以下是数据集连同其包含的csv文件列表： tracks.csv：所有106,574首曲目的每首曲目元数据，如ID，标题，艺术家，流派，标签和播放次数。 genres.csv：所有163种风格的ID与他们的名字和父母（用于推断流派层次和顶级流派）。 features.csv：用librosa提取的共同特征 。 echonest.csv：由Echonest （现在的 Spotify）为13,129首音轨的子集提供的音频功能 。 数据集大小： 约1T 记录数量：1500个音频样本 官方网站：https://github.com/mdeff/fma 模型案例：https://arxiv.org/pdf/1803.05337.pdf 舞厅 介绍： 该数据集包含舞厅跳舞音频文件。以真实音频格式提供了许多舞蹈风格的一些特征摘录。 以下是数据集的一些特征： 数据集大小： 约14 G 记录数量：约700个音频样本 官方网站：http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html 模型案例：https://pdfs.semanticscholar.org/0cc2/952bf70c84e0199fcf8e58a8680a7903521e.pdf 百万歌曲数据集 介绍： 百万歌曲数据集是音频功能和元数据的一百万当代流行音乐曲目可自由可用的集合。 其目的是： 鼓励对扩大到商业规模的算法进行研究 为评估研究提供参考数据集 作为使用API创建大型数据集的捷径（例如Echo Nest的） 帮助新研究人员在MIR领域开始工作 数据集的核心是一百万首歌曲的特征分析和元数据。该数据集不包含任何音频，只包含派生的功能。示例音频可以通过使用哥伦比亚大学提供的代码从7digital等服务中获取。 数据集大小： 约280 G 记录数量：它的一百万首歌曲！ 官方网站：https://labrosa.ee.columbia.edu/millionsong/ 模型案例：http://www.ke.tu-darmstadt.de/events/PL-12/papers/08-aiolli.pdf LibriSpeech 介绍： 该数据集是大约1000小时的英语语音的大型语料库。这些数据来自LibriVox项目的有声读物。它已被分割并正确对齐。如果您正在寻找一个起点，请查看已准备好的声学模型，这些模型在kaldi-asr.org和语言模型上进行了训练，适合评估，网址为http://www.openslr.org/11/。 数据集大小： 约60 G 记录数量：1000小时的演讲 官方网站：http://www.openslr.org/12/ 模型案例：https://arxiv.org/abs/1712.09444 VoxCeleb 介绍： VoxCeleb是一个大型的说话人识别数据集。它包含约1,200名来自YouTube视频的约10万个话语。数据大部分是性别平衡的（男性占55％）。名人跨越不同的口音，职业和年龄。开发和测试集之间没有重叠。对于隔离和识别哪个超级巨星来说，这是一个有趣的用例。 数据集大小： 约150 M 记录数量： 1,251位名人的100,000条话语 官方网站：http://www.robots.ox.ac.uk/~vgg/data/voxceleb/ 模型案例：https://www.robots.ox.ac.uk/~vgg/publications/2017/Nagrani17/nagrani17.pdf 比赛数据Twitter情绪分析数据 介绍： 仇恨以种族主义和性别歧视为形式的言论已成为叽叽喳喳的麻烦，重要的是将这类推文与其他人分开。在这个实践问题中，我们提供既有正常又有仇恨推文的Twitter数据。您作为数据科学家的任务是确定推文是仇恨推文，哪些不是。 数据集大小： 约3 M 记录数量： 31,962条推文 官方网站：https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/ 印度演员的年龄检测 介绍： 对于任何深度学习爱好者来说，这是一个令人着迷的挑战。该数据集包含数千个印度演员的图像，你的任务是确定他们的年龄。所有图像都是手动选择的，并从视频帧中剪切，导致尺度，姿势，表情，照度，年龄，分辨率，遮挡和化妆的高度可变性。 数据集大小： 约48 M 记录数量： 训练集中的19,906幅图像和测试集中的6636幅图像 官方网站：https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/ 城市声音分类 介绍： 这个数据集包含超过8000个来自10个班级的城市声音摘录。这个实践问题旨在向您介绍常见分类方案中的音频处理。 数据集大小： 训练集 - 3 GB（压缩），测试集 - 2 GB（压缩） 记录数量： 来自10个班级的8732个城市声音标注的声音片段（&lt;= 4s） 官方网站：https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/ 参考文章【1】 https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners 【2】 https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/ 【3】 https://deeplearning4j.org/cn/opendata]]></content>
      <categories>
        <category>datasets</category>
      </categories>
      <tags>
        <tag>datasets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu挂载新的硬盘（2T以上）]]></title>
    <url>%2F2018%2F04%2F01%2F2018-04-01-ubuntu_add_disk%2F</url>
    <content type="text"><![CDATA[系统环境：Linux version 4.13.0-37-generic (Ubuntu 5.4.0-6ubuntu1~16.04.9) root用户登入操作 查看硬盘信息机器断电时，接入硬盘。开机后用下面的命令查看硬盘状况（非root用户需sudo）。 123456789101112131415161718root@deeplearning:~# fdisk -lDisk /dev/sda: 465.8 GiB, 500107862016 bytes, 976773168 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: CC8004FC-D422-48FA-8ACF-54C3F48E860BDevice Start End Sectors Size Type/dev/sda1 2048 1050623 1048576 512M EFI System/dev/sda2 1050624 909946879 908896256 433.4G Linux filesystem/dev/sda3 909946880 976771071 66824192 31.9G Linux swapDisk /dev/sdb: 3.7 TiB, 4000787030016 bytes, 7814037168 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytes 查看到系统由两块硬盘：/dev/sda和/dev/sdb，如果还有其他硬盘会继续sdc、sdd编号。 正在使用的系统盘sda已经有三个分区（sda1、sda2、sda3），新挂载的硬盘sdb位分区。 新挂载硬盘分区新硬盘存储空间一共4T，我们对硬盘进行分区。划分为两个分区： 1234567891011121314root@deeplearning:~# fdisk /dev/sdbWelcome to fdisk (util-linux 2.27.1).Changes will remain in memory only, until you decide to write them.Be careful before using the write command./dev/sdb: device contains a valid 'ext4' signature; it is strongly recommended to wipe the device with wipefs(8) if this is sible collisionsDevice does not contain a recognized partition table.The size of this disk is 3.7 TiB (4000787030016 bytes). DOS partition table format can not be used on drives for volumes lar512-byte sectors. Use GUID partition table format (GPT).Created a new DOS disklabel with disk identifier 0x6b028a17.Command (m for help): 注意这里已经有警告：The size of this disk is 3.7 TiB (4000787030016 bytes). DOS partition table format can not be used on drives for volumes lar512-byte sectors. Use GUID partition table format (GPT) 这里情况特殊，新加入的磁盘为4T。fdisk命令对于大于2T的分区无法划分。如果继续使用fdisk工具，最多只能分出2T的分区，剩下的空间无法利用。这不坑爹嘛。提示我们使用parted命令。 使用parted分区parted命令可以划分单个分区大于2T的GPT格式的分区。 更改分区表类型： 1root@deeplearning:~# parted -s /dev/sdb mklabel gpt 使用parted进行分区： 123456789101112131415161718192021222324252627282930313233root@deeplearning:~# parted /dev/sdbGNU Parted 3.2Using /dev/sdbWelcome to GNU Parted! Type 'help' to view a list of commands.(parted) print Model: ATA WDC WD40EFRX-68N (scsi)Disk /dev/sdb: 4001GBSector size (logical/physical): 512B/4096BPartition Table: gptDisk Flags: Number Start End Size File system Name Flags(parted) mklabel gpt Warning: The existing disk label on /dev/sdb will be destroyed and all data on this disk will be lost. Do you want to continue?Yes/No? yes (parted) mkpart Partition name? []? File system type? [ext2]? ext4 Start? 0% End? 100% (parted) print Model: ATA WDC WD40EFRX-68N (scsi)Disk /dev/sdb: 4001GBSector size (logical/physical): 512B/4096BPartition Table: gptDisk Flags: Number Start End Size File system Name Flags 1 1049kB 4001GB 4001GB ext4(parted) quit Information: You may need to update /etc/fstab. 最后我们验证一下，sdb1分区成功，提示我们要更新系统文件：/etc/fstab。 12345678910111213141516171819202122232425root@deeplearning:~# ls /dev/sd* /dev/sda /dev/sda1 /dev/sda2 /dev/sda3 /dev/sdb /dev/sdb1root@deeplearning:~# fdisk -lDisk /dev/sda: 465.8 GiB, 500107862016 bytes, 976773168 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: CC8004FC-D422-48FA-8ACF-54C3F48E860BDevice Start End Sectors Size Type/dev/sda1 2048 1050623 1048576 512M EFI System/dev/sda2 1050624 909946879 908896256 433.4G Linux filesystem/dev/sda3 909946880 976771071 66824192 31.9G Linux swapDisk /dev/sdb: 3.7 TiB, 4000787030016 bytes, 7814037168 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: gptDisk identifier: 0D8B0FBC-83F6-4D77-ABDB-98875EC511E4Device Start End Sectors Size Type/dev/sdb1 2048 7814035455 7814033408 3.7T Linux filesystem 格式化新建分区将分区格式化为ext4格式的文件系统。 1234567891011121314root@deeplearning:~# mkfs.ext4 /dev/sdb1mke2fs 1.42.13 (17-May-2015)Creating filesystem with 976754176 4k blocks and 244195328 inodesFilesystem UUID: dfcd419f-38a5-4a5c-9b93-9f236d2c2444Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, 102400000, 214990848, 512000000, 550731776, 644972544Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done 如果有多个分区需要依次执行格式化。 挂载分区新建硬盘即将挂载的目录，然后将硬盘挂载到该目录下。并验证挂载成功，检查硬盘空间。 12345678910111213root@deeplearning:/# mkdir /dataroot@deeplearning:/# mount /dev/sdb1 /dataroot@deeplearning:/# df -hFilesystem Size Used Avail Use% Mounted onudev 16G 0 16G 0% /devtmpfs 3.2G 9.3M 3.2G 1% /run/dev/sda2 427G 21G 385G 5% /tmpfs 16G 0 16G 0% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 16G 0 16G 0% /sys/fs/cgroup/dev/sda1 511M 3.5M 508M 1% /boot/efitmpfs 3.2G 12K 3.2G 1% /run/user/1000/dev/sdb1 3.6T 68M 3.4T 1% /data 上面我们把新的硬盘挂载到了/data目录，硬盘空间大小正常。 配置开机自动挂载分区查看分区的UUID123root@deeplearning:/# blkid#（略）.../dev/sdb1: UUID="dfcd419f-38a5-4a5c-9b93-9f236d2c2444" TYPE="ext4" PARTUUID="fe373bd5-5b19-4ed0-8713-716455a8ebb4" 配置/etc/fstab将分区信息写到/etc/fstab文件中让它永久挂载: 将下面的配置信息加入配置文件尾部： 1UUID=dfcd419f-38a5-4a5c-9b93-9f236d2c2444 /data ext4 defaults 0 1 附录/etc/fstab配置说明12345678910111213# Use &apos;blkid&apos; to print the universally unique identifier for a# device; this may be used with UUID= as a more robust way to name devices# that works even if disks are added and removed. See fstab(5).&lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; 1 2 3 4 5 6对应参数说明：1、指代文件系统的设备名。最初，该字段只包含待挂载分区的设备名（如/dev/sda1）。现在，除设备名外，还可以包含LABEL或UUID2、文件系统挂载点。文件系统包含挂载点下整个目录树结构里的所有数据，除非其中某个目录又挂载了另一个文件系统3、文件系统类型。下面是多数常见文件系统类型（ext3,tmpfs,devpts,sysfs,proc,swap,vfat）4、mount命令选项。mount选项包括noauto（启动时不挂载该文件系统）和ro（只读方式挂载文件系统）等。在该字段里添加用户或属主选项，即可允许该用户挂载文件系统。多个选项之间必须用逗号隔开。其他选项的相关信息可参看mount命令手册页（-o选项处）5、转储文件系统？该字段只在用dump备份时才有意义。数字1表示该文件系统需要转储，0表示不需要转储6、文件系统检查？该字段里的数字表示文件系统是否需要用fsck检查。0表示不必检查该文件系统，数字1示意该文件系统需要先行检查（用于根文件系统）。数字2则表示完成根文件系统检查后，再检查该文件系统。 Parted命令说明（本文使用交互模式完成配置）Parted 命令分为两种模式：命令行模式和交互模式。 命令行模式： parted [option] device [command] ,该模式可以直接在命令行下对磁盘进行分区操作，比较适合编程应用。 交互模式：parted [option] device 类似于使用fdisk /dev/xxx MBR：MBR分区表(即主引导记录)大家都很熟悉。所支持的最大卷：2T，而且对分区有限制：最多4个主分区或3个主分区加一个扩展分区 GPT： GPT（即GUID分区表）。是源自EFI标准的一种较新的磁盘分区表结构的标准，是未来磁盘分区的主要形式。与MBR分区方式相比，具有如下优点。突破MBR 4个主分区限制，每个磁盘最多支持128个分区。支持大于2T的分区，最大卷可达18EB。 parted是一个可以分区并进行分区调整的工具，他可以创建，破坏，移动，复制，调整ext2 linux-swap fat fat32 reiserfs类型的分区，可以创建，调整，移动Macintosh的HFS分区，检测jfs，ntfs，ufs，xfs分区。 使用方法：parted [options] [device [command [options...]...]] 12345678910111213141516171819202122232425262728options-h 显示帮助信息-l 显示所有块设备上的分区device 对哪个块设备进行操作，如果没有指定则使用第一个块设备command [options...]check partition 对分区做一个简单的检测cp [source-device] source dest 复制source-device设备上的source分区到当前设备的dest分区mklabel label-type 创建新分区表类型，label-type可以是："bsd", "dvh", "gpt", "loop","mac", "msdos", "pc98", or "sun" 一般的pc机都是msdos格式，如果分区大于2T则需要选用gpt格式的分区表。mkfs partition fs-type 在partition分区上创建一个fs-type文件系统，fs-type可以是："fat16", "fat32", "ext2", "linux-swap","reiserfs" 注意不支持ext3格式的文件系统，只能先分区然后用专有命令进行格式化。mkpart part-type [fs-type] start end 创建一个part-type类型的分区，part-type可以是："primary", "logical", or "extended" 如果指定fs-type则在创建分区的同时进行格式化。start和end指的是分区的起始位置，单位默认是M。eg：mkpart primary 0 -1 0表示分区的开始 -1表示分区的结尾 意思是划分整个硬盘空间为主分区mkpartfs part-type fs-type start end 创建一个fs-type类型的part-type分区，不推荐使用，最好是使用mkpart分区完成后使用mke2fs进行格式化。name partition name 给分区设置一个名字，这种设置只能用在Mac, PC98, and GPT类型的分区表，设置时名字用引号括起来select device 在机器上有多个硬盘时，选择操作那个硬盘resize partition start end 调整分区大小rm partition 删除一个分区rescue start end 拯救一个位于stat和end之间的分区unit unit 在前面分区时，默认分区时数值的单位是M，这个参数卡伊改变默认单位，"kB", "MB", "GB", "TB"move partition start end 移动partition分区print 显示分区表信息 quit 退出parted 参考文献【1】 Setting up a large (2TB+) hard disk drive on Linux]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>disk</tag>
        <tag>parted</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo:解决Typora编辑table无法被解析问题]]></title>
    <url>%2F2018%2F04%2F01%2F2018-04-05-Hexo_table%2F</url>
    <content type="text"><![CDATA[掉坑背景使用Typora编辑Makedown文件，添加表格，但是提交给Hexo渲染网页，无法正常解析显示，而是显示源码。例如：| Table Header 1 | Table Header 2 || ————– | ————– || Division 1 | Division 2 || Division 1 | Division 2 | 爬坑过程和解决办法一开始认为是Hexo的bug，Google也没人遇到类似情况，都准备在github上建问题单了。最后本着严谨的态度，以文本的格式打开文档，发现表格源码和正文之间没有空行！！！！！ 这尼玛坑爹呀，所以Hexo无法解析，但是Typora能正常解析。空出一行后正常解析： 123456&lt;正文&gt;(空一行)| Table Header 1 | Table Header 2 || - | - | | Division 1 | Division 2 | | Division 1 | Division 2 | Table Header 1 Table Header 2 Division 1 Division 2 Division 1 Division 2 这一点Typora做的不够兼容（只怪他太过于强大的解析能力。。。。）。Tyopra不服了，我强大也有错？？哈哈哈 记录该坑供掉坑小伙伴参考。 提示如果掉坑小伙伴，上面办法没解决。用文本方式打开文件，逐个排查原因。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Typora</tag>
        <tag>table</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter notebook:主题和字体的美化]]></title>
    <url>%2F2018%2F03%2F19%2F2018-03-26-jupyter-notebook%2F</url>
    <content type="text"><![CDATA[背景Jupyter notebook是数据科学常用的代码交互式工具。通常在server端启jupyter进程（web服务），client端打开浏览器，jupyter提供代码编写和调试交互环境。非常方便。 但是jupyter提供的默认界面不够美观，特别是windows操作系统默认字体为浏览器默认字体–宋体（下图），另外默认主题太难看了，没有通常IDE提供的主题美观。 发现一个Jupyter的美化工具：jupyterthemes ，和大家分享一下。简单介绍一下安装和配置。细节介绍参考项目的介绍文档。 安装使用pip安装： 1root@vultr:~# pip install jupyterthemes 或者使用Anaconda的conda安装： 1root@vultr:~# conda install -c conda-forge jupyterthemes 命令格式使用jt -h显示命令帮助说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354root@vultr:~# jt -husage: jt [-h] [-l] [-t THEME] [-f MONOFONT] [-fs MONOSIZE] [-nf NBFONT] [-nfs NBFONTSIZE] [-tf TCFONT] [-tfs TCFONTSIZE] [-dfs DFFONTSIZE] [-ofs OUTFONTSIZE] [-mathfs MATHFONTSIZE] [-m MARGINS] [-cursw CURSORWIDTH] [-cursc CURSORCOLOR] [-cellw CELLWIDTH] [-lineh LINEHEIGHT] [-altp] [-altmd] [-altout] [-P] [-T] [-N] [-vim] [-r] [-dfonts]optional arguments: -h, --help show this help message and exit #-h，--help显示此帮助信息并退出 -l, --list list available themes #-l， 列出可用主题 -t THEME, --theme THEME theme name to install（配置需要安装的主题） -f MONOFONT, --monofont MONOFONT monospace code font（代码的字体） -fs MONOSIZE, --monosize MONOSIZE code font-size（代码字体大小） -nf NBFONT, --nbfont NBFONT notebook font（notebook 字体） -nfs NBFONTSIZE, --nbfontsize NBFONTSIZE notebook fontsize（notebook 字体大小） -tf TCFONT, --tcfont TCFONT txtcell font（文本的字体） -tfs TCFONTSIZE, --tcfontsize TCFONTSIZE txtcell fontsize（文本的字体大小） -dfs DFFONTSIZE, --dffontsize DFFONTSIZE pandas dataframe fontsize（pandas类型的字体大小） -ofs OUTFONTSIZE, --outfontsize OUTFONTSIZE output area fontsize（输出区域字体大小） -mathfs MATHFONTSIZE, --mathfontsize MATHFONTSIZE mathjax fontsize (in %)（数学公式字体大小） -m MARGINS, --margins MARGINS fix margins of main intro page -cursw CURSORWIDTH, --cursorwidth CURSORWIDTH set cursorwidth (px)（设置光标宽度） -cursc CURSORCOLOR, --cursorcolor CURSORCOLOR cursor color (r, b, g, p)（设置光标颜色） -cellw CELLWIDTH, --cellwidth CELLWIDTH set cell width (px or %)（单元的宽度） -lineh LINEHEIGHT, --lineheight LINEHEIGHT code/text line-height (%)（行高） -altp, --altprompt alt input prompt style -altmd, --altmarkdown alt markdown cell style -altout, --altoutput set output bg color to notebook bg -P, --hideprompt hide cell input prompt -T, --toolbar make toolbar visible（工具栏可见） -N, --nbname nb name/logo visible -vim, --vimext toggle styles for vim -r, --reset reset to default theme（设置成默认主题） -dfonts, --defaultfonts force fonts to browser default（设置成浏览器默认字体） 案例例如下面的命令完成效果： 使用的主题是：monokai，工具栏可见，命名笔记本的选项，代码的字体为13，代码的字体为consolamono。 1root@vultr:~# jt -t monokai -T -N -fs 13 -f consolamono 如果jupyter进程已启，需要重新启进程后生效。 实现的效果截图： 其他主题效果大家可以自己尝试。]]></content>
      <categories>
        <category>jupyter_notebook</category>
      </categories>
      <tags>
        <tag>jupyter notebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派：使用USB摄像头自制家庭监控]]></title>
    <url>%2F2018%2F03%2F18%2F2018-03-18-raspberry_usb_camera%2F</url>
    <content type="text"><![CDATA[树莓派摄像头和USB摄像头 树莓派有配套的摄像头模块（Raspberry Pi camera board），如下图。 另外树莓派也支持USB摄像头。关于树莓派支持的USB摄像头有个清单参考（需要梯子）。大家购买前最好确认一下是否在兼容清单中。 部署步骤第一步：检查USB摄像头和树莓派的兼容性将USB摄像头和树莓派连接，查看USB接口连接情况。 12345root@raspberrypi:/# lsusbBus 001 Device 004: ID 046d:0825 Logitech, Inc. Webcam C270Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet AdapterBus 001 Device 002: ID 0424:9514 Standard Microsystems Corp.Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub 发现004口上面连接并识别了摄像头（我的是Logitech 270摄像头）。 如果没有识别出来，需要查看USB兼容清单是否有该型号。另外由于树莓派供电功率较小，也有可能是USB供电功率不足，需要有外置电源的USB摄像头。 另外还可以查看设备驱动情况： 12root@raspberrypi:/# ls /dev/vid*/dev/video0 发现video0设备，说明识别了USB摄像头（罗技的c270i） 第二步：MOTION软件实现对于USB摄像头，有多种软件包可以实现拍照和摄像等功能，这里使用motion。 安装motion 1root@raspberrypi:/# sudo apt-get install motion 编辑配置配置文件 1root@raspberrypi:~# vi /etc/motion/motion.conf 调整相关参数 123456789101112# The mini-http server listens to this port for requests (default: 0 = disabled)stream_port 8082# web界面访问端口# TCP/IP port for the http server to listen on (default: 0 = disabled)webcontrol_port 8080#控制端口# Restrict control connections to localhost only (default: on)webcontrol_localhost off# Target base directory for pictures and films# Recommended to use absolute path. (Default: current working directory)target_dir /var/lib/motion#照片及视频存放路径 其他参数调整如下： ​ ffmpeg_output_movies=off ​ stream_localhost=off ​ webcontrol_localhost=off ​ locate_motion_mode=peview ​ locate_motion_style=redbox ​ text_changes=on 开启motion进程修改motion文件，设置为守护进程运行（即参数配置为：yes）： 123# vi /etc/default/motion# set to 'yes' to enable the motion daemonstart_motion_daemon=yes 启进程： 1234567root@raspberrypi:/etc/init.d# motion start[0] [NTC] [ALL] conf_load: Processing thread 0 - config file /etc/motion/motion.conf[0] [ALR] [ALL] conf_cmdparse: Unknown config option "sdl_threadnr"[0] [NTC] [ALL] motion_startup: Motion 3.2.12+git20140228 Started[0] [NTC] [ALL] motion_startup: Logging to syslog[0] [NTC] [ALL] motion_startup: Using log type (ALL) log level (NTC)[0] [NTC] [ALL] become_daemon: Motion going to daemon mode 查看监控画面地址栏中输入地址和端口号（IP：8082），上面配置的web界面访问端口为8082： 查看监控数据存放目录另外目录/var/lib/motion中存放历史数据。 第三步：内网穿透（外网访问web监控界面）实现上面的步骤，你只能在家里本地局域网访问监控界面，意义不大。 由于目前中国宽带服务公司都不会给家庭网络外网地址。所以需要内网穿透，实现外网访问家庭内网。 具体可以使用frp软件实现内网穿透。具体做法参考的博客中另一篇介绍frp的分享文章。 参考文章【1】 https://www.bouvet.no/bouvet-deler/utbrudd/building-a-motion-activated-security-camera-with-the-raspberry-pi-zero 【2】 https://medium.com/@Cvrsor/how-to-make-a-diy-home-alarm-system-with-a-raspberry-pi-and-a-webcam-2d5a2d61da3d]]></content>
      <categories>
        <category>raspberry</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动手实现深度学习相机]]></title>
    <url>%2F2018%2F03%2F14%2F2018-03-14-deeplearning_camera%2F</url>
    <content type="text"><![CDATA[2017年年底，亚马逊（AWS）宣布将推出深度学习相机——DeepLens ，亚马逊官网已经开始预售，预计6月14日发货。但是售价为249刀（约1600人民币）。偏贵了。 具体介绍可以参考这篇文章：AWS深度学习摄像头，将对机器学习产业有何影响？ 看到有人利用树莓派和简易摄像头实现了一个深度学习相机，用来检测院子里面小鸟吃食。正好自己有一个树莓派，可以参考玩一下。进一步优化甚至可以放在家门口，对访客人脸识别。]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[动手实现Ubuntu系统WOL远程唤醒]]></title>
    <url>%2F2018%2F03%2F14%2F2018-03-14-%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0Ubuntu%E7%B3%BB%E7%BB%9FWOL%E8%BF%9C%E7%A8%8B%E5%94%A4%E9%86%92%2F</url>
    <content type="text"><![CDATA[背景本篇博客主要介绍通过局域网唤醒服务器（远程启动计算机）。具体在Ubuntu操作系统上实现。具体数据流为：通过互联网远程登录长期开机的树莓派，然后通过树莓派唤醒同一个局域网的高性能服务器。 目前中国家庭宽带网络都是没有外网IP的，如果外网访问家庭网络，需要做端口映射，实现远程访问。 什么是WoL（Wake on LAN）电脑处在关机（或休眠）状态时，只要主机保持连接电源、网线连接网卡，其实网卡和主板仍然有微弱供电。这部分供电能让网卡监听和解读来自外部网络的广播信息。其中会对一种特殊的广播信息Magic Packet（魔法数据包）进行侦测。Magic Packet网络包以广播的形式发送，发送的范围可以是整个局域网或者指定的子网。另外Magic Packet中唤醒服务器IP可以是多个，侦测主机一旦发现包中的唤醒IP集中包含自己的IP，会通知主板、电源供电器，开始执行唤醒，打开机器。 第一部分 检查主机板块和网卡是否支持Wol 主板是否支持：进入BIOS，将“Power Management Setup”中的“Wake Up On LAN”或“Resume by LAN”项设置为“Enable”或“On” 网卡是否支持： 1# ethtool enp0s31f6 其中有下面的字段信息： 12Supports Wake-on: pumbgWake-on: g 第二部分 部署步骤2.1 方法1需要安装wakeonlan包： 1root@raspberrypi:~# sudo apt-get install wakeonlan 下面的命令通过树莓派发送魔术包： 12root@raspberrypi:~# wakeonlan -i 192.168.1.3 b0:6f:bf:b0:9f:2fSending magic packet to 192.168.1.3:9 with b0:6f:b0:bf:9f:2f 2.2 方法2在网关配置ARP信息（IP与物理地址进行绑定），发送网段的广播： 12root@raspberrypi:~# wakeonlan -i 192.168.1.0 b0:6f:bf:b0:9f:2fSending magic packet to 192.168.1.0:9 with b0:6f:b0:bf:9f:2f 参考文献及链接1、WakeOnLan 链接：https://help.ubuntu.com/community/WakeOnLan 2、wiki 链接：https://en.wikipedia.org/wiki/Wake-on-LAN 3、Ubuntu 與 Wake on LAN 链接：http://softsmith.blogspot.com/2014/05/ubuntu-wake-on-lan.html]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统版本信息查询]]></title>
    <url>%2F2018%2F03%2F14%2F2018-03-15-ubuntu_ssh_ip_OK%2F</url>
    <content type="text"><![CDATA[本篇博客主要汇总查询Ubuntu系统的信息的相关命令及展示案例。 会持续更新。 系统信息查看：CPU信息12root@deeplearning:/# cat /proc/versionLinux version 4.13.0-37-generic (buildd@lcy01-amd64-012) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)) #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 查看：内核、操作系统、CPU信息12root@deeplearning:/# uname -aLinux deeplearning 4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux 查看：操作系统版本信息123456root@deeplearning:/# lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 16.04.4 LTSRelease: 16.04Codename: xenial 查看：计算机名12root@vultr:~# hostnamevultr.guest 资源信息查看：存储分区的使用信息123456789root@vultr:~# df -hFilesystem Size Used Avail Use% Mounted onudev 469M 0 469M 0% /devtmpfs 99M 11M 89M 11% /run/dev/vda1 25G 12G 12G 49% /tmpfs 495M 0 495M 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 495M 0 495M 0% /sys/fs/cgrouptmpfs 99M 0 99M 0% /run/user/0 查看：系统运行时间、用户数量12root@vultr:~# uptime 23:04:54 up 10 days, 17:21, 1 user, load average: 0.21, 0.06, 0.02 磁盘信息查看:所有分区信息12345678910root@vultr:~# fdisk -lDisk /dev/vda: 25 GiB, 26843545600 bytes, 52428800 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: dosDisk identifier: 0xcb855d49Device Boot Start End Sectors Size Id Type/dev/vda1 * 2048 52428257 52426210 25G 83 Linux 网络信息查看：网络接口信息12345678910root@vultr:~# ifconfig#（略）lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 198660 bytes 27478459 (27.4 MB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 198660 bytes 27478459 (27.4 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 查看：防火墙信息1234root@vultr:~# iptables -LChain DOCKER-USER (1 references)target prot opt source destination RETURN all -- anywhere anywhere 查看：路由表12345root@vultr:~# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface#（略）172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 查看：监听端口、已经建立的连接1234root@vultr:~# netstat -lntpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 749/sshd 1234root@vultr:~# netstat -antpActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 749/sshd 查看：网络统计信息123456root@vultr:~# netstat -sIp: Forwarding: 1 5729182 total packets received 9 with invalid addresses#略信息 进程信息查看：所有进程信息123root@vultr:~# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 Mar25 ? 00:00:44 /sbin/init 查看：实时显示进程状态12345678910root@vultr:~# toptop - 23:24:19 up 10 days, 17:41, 1 user, load average: 0.02, 0.02, 0.00Tasks: 87 total, 1 running, 86 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.7 us, 0.3 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1012392 total, 74384 free, 270236 used, 667772 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 556896 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 25691 root 20 0 554760 13348 3448 S 0.3 1.3 35:21.42 docker-containe #（略信息） 用户信息查看：活动用户1234root@vultr:~# w 23:25:22 up 10 days, 17:42, 1 user, load average: 0.33, 0.08, 0.02USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 140.31.74.0 22:59 2.00s 0.06s 0.00s w 查看：用户登录日志信息12345root@vultr:~# lastroot pts/0 113.41.56.0 Wed Apr 4 22:59 still logged inroot pts/0 113.41.56.0 Wed Apr 4 08:37 - 13:38 (05:00)wtmp begins Sun Apr 1 19:59:32 2018]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu添加国内apt更新源]]></title>
    <url>%2F2018%2F03%2F14%2F2018-03-15-ubuntu_apt_change%2F</url>
    <content type="text"><![CDATA[本篇博客主要介绍如何更改Ubuntu系统的apt源。 关于源我们使用apt安装软件时，会到国外源下载软件包。但是由于各种原因（你懂的）国外站点到国内的下载速度非常缓慢，甚至1k/s。对于大的包，这是无法忍受的等待，经常会超时中断。所以我们换成国内的源站点。其中口碑比较好的源站点有：阿里源、清华源、中科大源等。 Ubuntu系统的源地址文件位置：/etc/apt/sources.list 更换步骤第一步：备份 对于系统文件的修改建议实施备份。养成良好的变更习惯。关键时候能救命。 关于备份文件命名有两个建议：（1）含有backup字段提示为备份文件；（2）含有备份日期，便于区分多个备份。当然如果是多用户话应该含有用户名，便于区分。 1root@deeplearning:/# cp /etc/apt/sources.list /etc/apt/sources.list.backup.20180315 第二步：添加源地址 我们添加阿里源， 进入阿里云开源镜像站，找到ubuntu的帮助信息： 我们版本号Ubuntu 16.04.4 LTS，并且Codename: xenial。需要根据自己的版本对应相应的源。 123456789101112131415161718# deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricteddeb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 直接将source.list中内容用上面的源地址内容替换，保存后退出。更新源： 1root@deeplearning:/# apt-get update 附录：apt的常用操作命令清单12345678910111213141516sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索软件包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖那些包sudo apt-cache rdepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>apt</tag>
        <tag>mirrors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派：更改APT为国内源]]></title>
    <url>%2F2018%2F03%2F01%2F2018-03-12-raspberry_apt-get%2F</url>
    <content type="text"><![CDATA[背景发现树莓派wget国外源异常慢。其实可以更改为国内的apt源，不用走海下光缆啦。 更改步骤编辑sources.list文件还没安装我喜爱的vim，只能先用nano编辑文件： 1root@raspberrypi:~# nano /etc/apt/sources.list 修改源将原始的源注释掉，添加阿里云的源地址（在这里感谢阿里爸爸）。 12deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib rpideb-src http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib rpi 更软件索引清单最后更新一下，以后就可以快速apt-get啦。 1sudo apt-get update]]></content>
      <categories>
        <category>raspberry</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
        <tag>apt-get</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派：搭建家庭内网穿透服务器（frp实现）]]></title>
    <url>%2F2018%2F03%2F01%2F2018-03-12-raspberry_frp%2F</url>
    <content type="text"><![CDATA[背景对于目前家庭网络，有下面两个迫切需求： 需要远程（比如在单位、路途等）SSH访问家里PC服务器、后续实现远程唤醒服务器。 后续部署自制家庭监控，需要远程访问监控web界面。 鉴于上面的需求，技术上需要实现外网访问内网（即内网穿透）。下面详细介绍具体实现步骤。 环境准备 一台树莓派主机。由于耗电较少，适合长期开机，作为中转服务器。 一个公网IP。由于电信宽带不提供公网IP，只能自己想办法。正好有一台外网VPS服务器（独有公网IP） 另外顺便打个不收钱的广告：VPS可以使用vultr的虚机，支持支付宝，非常方便。 FRP介绍实现内网穿透有很多方法：frp软件、ngrok软件、还有花生壳。关于frp有详细的官方介绍文档 ，不再赘述。 实现步骤第一步：配置VPS服务器VPS操作系统为Ubuntu，下载linux_amd64版本： 1root@vultr:~# wget https://github.com/fatedier/frp/releases/download/v0.16.1/frp_0.16.1_linux_amd64.tar.gz 解压缩： 123456789101112root@vultr:~# tar -zxvf frp_0.16.1_linux_amd64.tar.gzfrp_0.16.1_linux_amd64/frp_0.16.1_linux_amd64/frpc_full.inifrp_0.16.1_linux_amd64/LICENSEfrp_0.16.1_linux_amd64/frpc.inifrp_0.16.1_linux_amd64/frps.inifrp_0.16.1_linux_amd64/frpcfrp_0.16.1_linux_amd64/frps_full.inifrp_0.16.1_linux_amd64/frpsroot@vultr:~# cd frp_0.16.1_linux_amd64/root@vultr:~/frp_0.16.1_linux_amd64# lsfrpc frpc_full.ini frpc.ini frps frps_full.ini frps.ini LICENSE 对于VPS服务端只有两个文件是需要的：frps （服务）和frps.ini （配置文件）是需要的，我们拷贝到/bin目录下面（这一步主要是集中放在bin目录便于管理）。 frpc 和frpc.ini是客户端服务和配置文件，后面介绍。 12root@vultr:~/frp_0.16.1_linux_amd64# cp frps /bin/frpsroot@vultr:~/frp_0.16.1_linux_amd64# cp frps.ini /bin/frps.ini 然后对配置文件进行修改： 123456789101112131415161718192021222324252627282930313233root@vultr:/bin# vi frps.ini#修改配置文件[common]bind_addr = 10.66.2.137#VPS公网IP地址（为了保护隐私，上面地址是虚构的）bind_port = 7000#frp服务端口，用户自己定于一个空闲端口（不要和其他应用服务端口冲突）。需要注意的是必须与frpc.ini相同vhost_http_port = 80#http服务端口vhost_https_port = 443#https服务端口dashboard_port = 7500#web控制台端口，10.66.2.137：7500可以访问控制界面#下面两个参数是控制界面的用户名和密码dashboard_user = admindashboard_pwd = Password123！privilege_token = Password123！#特权模式密钥，需与frpc.ini相同log_file = /bin/frps_log/frps.log#日志文件存储路径log_level = info#日志记录级别log_max_days = 7#日志最大存储天数max_pool_count = 5#后端连接池最大连接数量#口令超时时间authentication_timeout = 900#subdomain_host = frp.com #服务端绑定域名tcp_mux = true 保存修改后的配置文件，后台启服务端进程，下面是命令格式： 12345root@vultr:/bin# nohup ./frps -c ./frps.ini &amp;#查看服务进程：root@vultr:/bin# ps -ef|grep frproot 1339 1 0 Mar25 ? 00:03:54 ./frps -c ./frps.iniroot 5320 4958 0 11:42 pts/1 00:00:00 grep --color=auto frp 以上完成服务端配置。 第二步：配置树莓派客户端 注意：树莓派的CPU处理器是ARM的，所以注意下载的版本包。 1root@raspberrypi:~# wget https://github.com/fatedier/frp/releases/download/v0.16.1/frp_0.16.1_linux_arm.tar.gz 解压缩下载的包： 123456789101112root@raspberrypi:~# tar -zxvf frp_0.16.1_linux_arm.tar.gz frp_0.16.1_linux_arm/frp_0.16.1_linux_arm/frpc_full.inifrp_0.16.1_linux_arm/LICENSEfrp_0.16.1_linux_arm/frpc.inifrp_0.16.1_linux_arm/frps.inifrp_0.16.1_linux_arm/frpcfrp_0.16.1_linux_arm/frps_full.inifrp_0.16.1_linux_arm/frpsroot@raspberrypi:~# cd frp_0.16.1_linux_armroot@raspberrypi:~/frp_0.16.1_linux_arm# lsfrpc frpc_full.ini frpc.ini frps frps_full.ini frps.ini LICENSE 类似服务端操作将frpc和frpc.ini拷贝到/bin目录下面。 12root@raspberrypi:~/frp_0.16.1_linux_arm# cp frpc /bin/frpcroot@raspberrypi:~/frp_0.16.1_linux_arm# cp frpc.ini /bin/frpc.ini 修改配置文件： 123456789101112131415161718192021222324252627282930313233343536373839root@raspberrypi:/bin# vi frpc.ini#修改客户端配置文件[common]server_addr = 10.66.2.137#VPS公网IP地址（为了保护隐私，上面地址是虚构的）server_port = 7000privilege_token = Password123！log_file = /bin/frpc.log#日志目录log_level = infolog_max_days = 7pool_count = 5tcp_mux = true#配置SSH端口映射[ssh]type = tcplocal_ip = 127.0.0.1#本地端口local_port = 22#映射端口remote_port = 6000[web]type = httplocal_ip = 127.0.0.1local_port = 80use_encryption = falseuse_compression = truesubdomain = web#所绑定的公网服务器域名，一级、二级域名都可以。这里没有就不用配置了custom_domains = web.frp.com#远程监控端口映射[motion]type = tcplocal_ip = 127.0.0.1local_port = 8082remote_port = 8000 保存修改，后台启客户端进程： 1234root@raspberrypi:/bin# nohup ./frpc -c ./frpc.ini &amp;root@raspberrypi:/bin# ps -ef|grep frproot 4627 1 0 4月02 ? 00:05:19 ./frpc -c ./frpc.iniroot 13731 13669 0 19:56 pts/0 00:00:00 grep frp 第三步：验证FRP管理界面（http://公网IP:7500）显示两个端口映射都是online可用的： 下面是整体视图： SSH服务我们已经将本地访问ssh的服务端口（192.168.1.2：22）映射到外网端口（10.66.2.137：6000）。 例如使用putty工具，IP地址填写：10.66.2.137，端口：6000。 连接后使用树莓派本地ssh用户和密码即可登录。 参考[1] FRP官方网站 https://github.com/fatedier/frp]]></content>
      <categories>
        <category>raspberry</category>
      </categories>
      <tags>
        <tag>raspberry</tag>
        <tag>frp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu操作系统静态IP地址]]></title>
    <url>%2F2018%2F02%2F06%2F2018-02-25-Linux_ip%2F</url>
    <content type="text"><![CDATA[有一台Linux台式机（Ubuntu 16.04.3 LTS (GNU/Linux 4.13.0-32-generic x86_64)）。之前IP是DHCP服务分配的。准备给服务器分配静态IP，方便使用。 ubuntu的网络参数保存在文件/etc/network/interfaces中。 1、编辑interfaces文件12345vi /etc/network/interfaces# interfaces(5) file used by ifup(8) and ifdown(8)auto loiface lo inet loopback 2、添加静态IP信息及DNS信息12345678910# interfaces(5) file used by ifup(8) and ifdown(8)auto loiface lo inet loopbackauto enp0s31f6iface enp0s31f6 inet staticaddress 192.168.31.62gateway 192.168.31.254netmask 255.255.255.0dns-nameservers 192.168.31.1 8.8.8.8]]></content>
      <categories>
        <category>Linux IP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SAS 9.4 部署及SID文件调整]]></title>
    <url>%2F2018%2F02%2F06%2F2018-02-09-SAS_install%2F</url>
    <content type="text"><![CDATA[本篇博客主要介绍个人部署SAS 9.4软件过程及安装过程中调整SID文件技巧。由于工作中经常使用SAS软件连接数据库查数，所以个人电脑准备也装备一下，部署过程分享给大家。 第一部 下载SAS 9.4介质及安装相信大家的资源检索能力，肯定能找到可用的安装介质。 介质可以参考一个网盘地址：http://pan.baidu.com/s/1qYz7ZNA 密码：ulig 解压缩后windows 直接执行setup.exe文件，linux 执行setup.sh文件执行命令：sh setup.sh。 然后选择安装语言、需要安装的组件、选择（32bit或64bit）等，不再赘述。 第二部分 SID文件的导入 如果你有未过期的SID文件，直接导入后安装即可。下面主要介绍没有时咋办（本文介绍方法主要是个人学习使用哈，商业使用建议购买SID哈，毕竟不差钱） 1、闹心的方法首先找到旧的SID文件（授权时间已经过期），导入SID文件前，将操作系统修改为历史时间，然后顺利安装。但是每次使用SAS都要将系统时间后调，否则没法启动SAS正常使用。确实很闹心，而且修改系统时间后很多软件会提示异常，比如浏览器等。 2、奇技淫巧 其实认真查找SID文件，还是可以找到不过期的。 比如下面的链接：http://downloads.npust.edu.tw/otherFile/20170703022854.txt 过期时间为：30APR2018 [ ] 如果用这个SID提示无效或报错，这时候我们需要调整一下这个SID文件。 - 在安装源文件目录中找到order.xml文件，我的目录为：~\SAS 9.4\order_data\99YYS5\order.xm。在文件中找到两个参数：setnumid=&quot;51200421&quot;、number=&quot;99YYS5&quot; - 将SID文件中下面两个参数调整和order文件中相同： 123#调整后Order=99YYS5Setnumid=51200421 [ ] 最后重新加载SID文件，顺利安装。 &gt; 另外如果还是报错可能是遇到别的坑了。。。。。 第三部分 分享一个坑作者部署平台是win7。所以涉及“C:\ Program Files”（存放64bit软件）和“C:\ Program Files(x86)”（存放32bit软件）。 而下载的SAS 9.4是32bit的，路径选择了“C:\ Program Files”，所以导入SID一直报错。 最后缓过神，调整了安装路径为“C:\ Program Files（x86）”（存放32bit软件的地方），最后顺利安装。 第四部分 一点提示SID文件中会有各个组件的授权，如果使用SAS软件部分组件无效，可能是SID文件中未有该组件的授权信息。下面是截取一个SID的授权组件的信息。例如有基础SAS 、SAS EG、还有SAS和oracle、Teradata连接的组件等。 123456Base SAS 31DEC2017SAS Enterprise Guide 31DEC2017SAS Enterprise Miner Personal Client 31DEC2017SAS/ACCESS Interface to Oracle 31DEC2017SAS/ACCESS Interface to PC Files 31DEC2017SAS/ACCESS Interface to Teradata 31DEC2017 例如：Interface to Oracle组件用来和oracle数据链接。连接后SAS EG客户端可以读取数据库中表，新建映射逻辑库就可以用SAS EG来做表操作。]]></content>
      <categories>
        <category>SAS install</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（数据类型及常用命令）]]></title>
    <url>%2F2018%2F01%2F25%2F2018-01-25-Redis-study%2F</url>
    <content type="text"><![CDATA[Redis作为内存数据库，具有高效的读取性能。首次安装完Redis和Python连接redis的包。尝试做一些hello world的练习。 Redis的数据类型 Redis是一个键值数据库（Key-Value） 其中Value值支持5中数据类型。分别是string（字符串）、list（列表）、set（集合）、hash（散列）、zset（有序集合） redis-cli控制台的使用及各种数据类型的操作 进入控制台 12&gt;&gt;&gt;redis-cli127.0.0.1:6379&gt; 表示进入控制台，可以和redis进行互动。首先尝试字符串类型的三个命令（set、get、del）。 1、string类型的3个常用命令set命令 12127.0.0.1:6379&gt; set hello worldOK set命令用于给redis中指定键赋值。这里key为hello，而键值value为world。如果key不存在会自动新建该键。 get命令 12127.0.0.1:6379&gt; get hello"world" get命令用于从redis中获取指定键的值。例子获取了hello键的值，返回键值字符串“world”。 del命令 1234127.0.0.1:6379&gt; del hello(integer) 1127.0.0.1:6379&gt; get hello(nil) del命令用于从redis中删除指定键的键值。且我们用get命令检验，确实被删除了。 2、list类型的4个命令rpush、lpush命令 12345678127.0.0.1:6379&gt; rpush list-test item1(integer) 1127.0.0.1:6379&gt; rpush list-test item2(integer) 2127.0.0.1:6379&gt; rpush list-test item1(integer) 3127.0.0.1:6379&gt; lpush list-test item3(integer) 4 上面的命令我们从右边先后推入了item1，item2，item1；然后从左边推入了item3。所以最后的形式应该是[“item3”,”item1”,”item2”,”item1”] lrange命令 12345127.0.0.1:6379&gt; lrange list-test 0 -11) "item3"2) "item1"3) "item2"4) "item1" lrange用于获取list中指定范围的值。这里0是起始索引，-1是最后一个索引（类似python中的list索引）。 lindex 命令 12127.0.0.1:6379&gt; lindex list-test 2"item2" lindex命令从list中获得指定索引位置的值。这里2实际是第三个值，所以返回“item2”。 lpop、rpop命令 123456127.0.0.1:6379&gt; lpop list-test"item3"127.0.0.1:6379&gt; lrange list-test 0 -11) "item1"2) "item2"3) "item1" lpop命令将list-test中最左边的值删除（弹掉），我们用lrange命令查看，确实已经删除。rpop类似使用。 3、set集合类型的四个命令sadd命令 12345678910127.0.0.1:6379&gt; sadd set-test item(integer) 1127.0.0.1:6379&gt; sadd set-test item1(integer) 1127.0.0.1:6379&gt; sadd set-test item2(integer) 1127.0.0.1:6379&gt; sadd set-test item3(integer) 1127.0.0.1:6379&gt; sadd set-test item4(integer) 1 使用sadd命令向集合set-test加入了5个字符串值。注意set类型类似python中的set类型。无序值不重复。 sismember命令 12127.0.0.1:6379&gt; sismember set-test item3(integer) 1 sismember用来查看值是否在集合中。上面检查item3是否在set-test，返回1，表示在集合中。 srem命令 1234127.0.0.1:6379&gt; srem set-test item2(integer) 1127.0.0.1:6379&gt; srem set-test item6(integer) 0 srem命令查看值是否在集合中，如果在返回1且删除该值。否则返回0。 smembers命令 12345127.0.0.1:6379&gt; smembers set-test1) "item"2) "item4"3) "item1"4) "item3" smembers命令查看集合中所有值。上面的结果也验证了srem确实将item2删除了。 set类型还有集合之间的运算（数学），例如sinter、sunion、sdiff分别是集合的交集、并集、差集运算。 4、hash散列类型的命令散列的数据类型是存储多个键值对之间的映射。 hset命令 12345678127.0.0.1:6379&gt; hset hash-test sub-key1 value1(integer) 1127.0.0.1:6379&gt; hset hash-test sub-key2 value2(integer) 1127.0.0.1:6379&gt; hset hash-test sub-key3 value3(integer) 1127.0.0.1:6379&gt; hset hash-test sub-key2 value2(integer) 0 hset 向hash-test中插入键及键值。返回1表示原hash中无该值，0表示重复插入。 hgetall命令 1234567127.0.0.1:6379&gt; hgetall hash-test1) "sub-key1"2) "value1"3) "sub-key2"4) "value2"5) "sub-key3"6) "value3" hgetall命令从hash-test中获取所有的键值。 hget命令 12127.0.0.1:6379&gt; hget hash-test sub-key2"value2" hget命令从hash-test中获得指定键的键值。 hdel命令 1234567127.0.0.1:6379&gt; hdel hash-test sub-key2(integer) 1127.0.0.1:6379&gt; hgetall hash-test1) "sub-key1"2) "value1"3) "sub-key3"4) "value3" hdel命令删除指定键及键值。 5、有序集合的命令zadd命令 123456127.0.0.1:6379&gt; zadd zset-test 123 number1(integer) 1127.0.0.1:6379&gt; zadd zset-test 456 number2(integer) 1127.0.0.1:6379&gt; zadd zset-test 123 number1(integer) 0 zadd命令zset-test中插入分值（score）及成员名（member）。 zrange命令 12345678127.0.0.1:6379&gt; zrange zset-test 0 -1 withscores1) "number1"2) "123"3) "number2"4) "456"127.0.0.1:6379&gt; zrange zset-test 0 -11) "number1"2) "number2" zrange命令获取指定范围的分值和成员名。其中withscores参数用来控制是否同时获得score值。 zrangebyscores命令 123127.0.0.1:6379&gt; zrangebyscore zset-test 0 200 withscores1) "number1"2) "123" zrangebyscores命令获取scores指定范围的分值和成员名。 zrem命令 12345127.0.0.1:6379&gt; zrem zset-test number1(integer) 1127.0.0.1:6379&gt; zrange zset-test 0 -1 withscores1) "number2"2) "456" zrem命令检查zset-test中知否有该分值和成员名。如果有返回1，并且删除。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python标准库timeit的使用简介]]></title>
    <url>%2F2018%2F01%2F25%2F2018-01-25-Python-timeit%2F</url>
    <content type="text"><![CDATA[Python调试代码时，经常需要测算一些代码模块或函数的执行效率（即耗时）。常用手段会在代码前后分别用time.time()记下开始和结束的时间，然后相减获得执行耗时。 本篇博客是一篇学习笔记，介绍Python一个内置模块实现代码执行计时。 模块介绍 timeit属于Python的标准库。文件路径在~Lib/timeit.py。 timeit同时具有命令行接口和可调用的函数接口。 一、命令行接口1、案例 12&gt;&gt;&gt;python -m timeit '"-".join(str(n) for n in range(100))&gt;&gt;&gt;100000 loops, best of 3: 14.1 usec per loop 回显内容：语句&quot;-&quot;.join(str(n) for n in range(100)执行了10w次，平均耗时14.1 usec。 2、接口参数说明 123456789python -m timeit [-n N] [-r N] [-s S] [-t] [-c] [-h] [statement ...]#[-n N] 表示测试语句（statement）执行的次数。如果不指定，会连续执行10，100，1000，...即10的倍数次，直到总时间至少0.2秒，结束。#[-r N] 计数器重复次数。默认是3。返回一个list，记录每次耗时。#[-s S] statement之前前的初始化语句。默认为pass。#[-t] 使用time.time()。#[-c] 使用time.clock()。#[-v] 会输出更多的执行过程信息。10次的耗时，1000次耗时，等等#[-h] 单独使用，反馈接口的使用信息。 注意：statement和[-s S]的参数按照字符串的形式传入。 二、函数接口1、类timeit.Timer 案例 123456789import timeit#定义一个类t=timeit.Timer('char in text',setup='text="sample string";char="g"')#timeit()函数t.timeit()#回显：0.019882534000089436#repeat()函数t.repeat()#回显：[0.01990252700011297, 0.01574616299990339, 0.015739961000008407] 参数说明 123456#1、初始化一个Timer类的参数：timeit.Timer(stmt='pass', setup='pass', timer=&lt;timer function&gt;)#2、timeit(number=1000000)# 默认number执行100w次。#3、repeat(repeat=3，number=1000000)# 默认执行100w次，重复3次（返回list） 2、两个函数 类似Timer的类，timeit也有两个函数。 1234567#1、timeit函数timeit.timeit(stmt="pass", setup="pass", timer=default_timer,number=default_number)#参数说明：stmt即statement，重复执行的语句。setup即执行前的初始化语句（执行一次）。#2、repeat函数timeit.repeat(stmt='pass', setup='pass', timer=&lt;default timer&gt;, repeat=3, number=1000000)#类似Timer类中函数。 案例 1234567import timeitdef test_example(): for i in range(100): "-".join(str(i))if __name__ == '__main__': print(timeit.timeit("test_example()", setup="from __main__ import test_example"))#25.844697911000367 例子中statement是个函数，重复执行前需要在setup中提前import。]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
</search>
