<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">



  
  
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="目录 术语说明 背景 第一部分   Apache Spark运行模式介绍 第二部分   Spark on Yarn 第三部分   Pyspark Application原理 第四部分   Python on Yarn配置及运行 第五部分   总结 参考文献及资料  背景Apache Spark属于重要的大数据计算框架，另外spark还提供了Python的原生API和机器学习组件Spark Ml，使">
<meta property="og:type" content="article">
<meta property="og:title" content="从Spark on Yarn到Python on Yarn">
<meta property="og:url" content="https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/index.html">
<meta property="og:site_name" content="RongXiang">
<meta property="og:description" content="目录 术语说明 背景 第一部分   Apache Spark运行模式介绍 第二部分   Spark on Yarn 第三部分   Pyspark Application原理 第四部分   Python on Yarn配置及运行 第五部分   总结 参考文献及资料  背景Apache Spark属于重要的大数据计算框架，另外spark还提供了Python的原生API和机器学习组件Spark Ml，使">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://zjrongxiang.github.io/images/picture/python-on-yarn/spark.bmp">
<meta property="og:image" content="https://zjrongxiang.github.io/images/picture/python-on-yarn/zk-spark.bmp">
<meta property="og:image" content="https://zjrongxiang.github.io/images/picture/python-on-yarn/yarn-client-mode.png">
<meta property="og:image" content="https://zjrongxiang.github.io/images/picture/python-on-yarn/yarn-cluster-mode.png">
<meta property="og:image" content="http://www.uml.org.cn/bigdata/images/2017111321.png">
<meta property="og:updated_time" content="2020-03-22T03:40:17.610Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="从Spark on Yarn到Python on Yarn">
<meta name="twitter:description" content="目录 术语说明 背景 第一部分   Apache Spark运行模式介绍 第二部分   Spark on Yarn 第三部分   Pyspark Application原理 第四部分   Python on Yarn配置及运行 第五部分   总结 参考文献及资料  背景Apache Spark属于重要的大数据计算框架，另外spark还提供了Python的原生API和机器学习组件Spark Ml，使">
<meta name="twitter:image" content="https://zjrongxiang.github.io/images/picture/python-on-yarn/spark.bmp">



  <link rel="alternate" href="/atom.xml" title="RongXiang" type="application/atom+xml">




  <link rel="canonical" href="https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>从Spark on Yarn到Python on Yarn | RongXiang</title>
  




  <script async src="//www.googletagmanager.com/gtag/js?id=UA-113063423-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-113063423-1');
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <!-- <a href="https://github.com/zjrongxiang"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png" alt="Fork me on GitHub"></a> -->
    <a href="https://github.com/zjrongxiang"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_green_007200.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">RongXiang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">我的烂笔头</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>Schedule</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="rong xiang">
      <meta itemprop="description" content="Keep a Pure Curiosity">
      <meta itemprop="image" content="/images/avatar/person.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RongXiang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">从Spark on Yarn到Python on Yarn

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-08-01 19:30:00" itemprop="dateCreated datePublished" datetime="2019-08-01T19:30:00+08:00">2019-08-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-03-22 11:40:17" itemprop="dateModified" datetime="2020-03-22T11:40:17+08:00">2020-03-22</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/pyspark/" itemprop="url" rel="index"><span itemprop="name">pyspark</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/#comments" itemprop="discussionUrl">
                
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>术语说明</li>
<li>背景</li>
<li>第一部分   Apache Spark运行模式介绍</li>
<li>第二部分   Spark on Yarn</li>
<li>第三部分   Pyspark Application原理</li>
<li>第四部分   Python on Yarn配置及运行</li>
<li>第五部分   总结</li>
<li>参考文献及资料</li>
</ul>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Apache Spark属于重要的大数据计算框架，另外spark还提供了Python的原生API和机器学习组件Spark Ml，使的可以通过Python编写机器学习任务由Spark运行。本篇文件从Spark运行模式开始讲起，重点介绍Spark on Yarn运行模式，最后重点介绍Python on Yarn（即Pyspark on Yarn）上运行原理和案例。</p>
<h2 id="第一部分-Apache-Spark运行模式"><a href="#第一部分-Apache-Spark运行模式" class="headerlink" title="第一部分 Apache Spark运行模式"></a>第一部分 Apache Spark运行模式</h2><p>目前 Apache Spark已知支持5种运行模式。按照节点资源数量可以分为单节点模式（2种）和集群模式（3种）。</p>
<ul>
<li>单节点模式：本地模式、本地伪集群模式</li>
<li>集群模式：Standalone模式、Spark on Yarn模式、Spark on Mesos模式</li>
<li>原生云模式：在Kubernetes上运行。随着Docker容器和原生云技术的兴起，Spark开始支持在Kubernetes上运行。</li>
</ul>
<blockquote>
<p>对于Spark on Kubernetes可以参考官方文档：<a href="https://spark.apache.org/docs/latest/running-on-kubernetes.html。另外可以参考我的另外一篇技术总结：《在Minikube上运行Spark集群》。" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-kubernetes.html。另外可以参考我的另外一篇技术总结：《在Minikube上运行Spark集群》。</a></p>
</blockquote>
<h3 id="1-1-本地模式（单节点模式）"><a href="#1-1-本地模式（单节点模式）" class="headerlink" title="1.1 本地模式（单节点模式）"></a>1.1 本地模式（单节点模式）</h3><p>本地模式又称为Loacl[N]模式。该模式只需要在单节点上解压spark包即可运行，使用多个线程模拟Spark分布式计算，Master和Worker运行在同一个JVM虚拟机中。这里参数N代表可以使用（预申请）N个线程资源，每个线程拥有一个Core（默认值N=1）。</p>
<blockquote>
<p>如果参数为：Loacl[*]，表明：Run Spark locally with as many worker threads as logical cores on your machine。即线程数和物理核数相同。</p>
</blockquote>
<p>例如下面的启动命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ./spark-submit –class org.apache.spark.examples.JavaWordCount –master <span class="built_in">local</span>[*] spark-examples_2.11-2.3.1.jar file:///opt/README.md</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>该模式不依懒于HDFS分布式文件系统。例如上面的命令使用的本地文件系统。</p>
</blockquote>
<h3 id="1-2-本地伪集群模式（单节点模式）"><a href="#1-2-本地伪集群模式（单节点模式）" class="headerlink" title="1.2 本地伪集群模式（单节点模式）"></a>1.2 本地伪集群模式（单节点模式）</h3><p>该模式和Local[N]类似，不同的是，它会在单机启动多个进程来模拟集群下的分布式场景，而不像Local[N]这种多个线程在一个进程下共享资源。通常用来测试和验证应用程序逻辑上有没有问题，或者想使用Spark的计算框架而而受限于没有太多资源。</p>
<p>作业提交命令中使用local-cluster[x,y,z]参数模式：x代表要生成的executor数，y和z分别代表每个executor所拥有的core和memory数值。例如下面的命令作业申请了2个executor 进程，每个进程分配3个core和1G的内存，来运行应用程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ./spark-submit –master <span class="built_in">local</span>-cluster[2, 3, 1024]</span></span><br></pre></td></tr></table></figure>
<h3 id="1-3-Standalone模式（集群模式）"><a href="#1-3-Standalone模式（集群模式）" class="headerlink" title="1.3 Standalone模式（集群模式）"></a>1.3 Standalone模式（集群模式）</h3><h4 id="1-3-1-构架部署"><a href="#1-3-1-构架部署" class="headerlink" title="1.3.1 构架部署"></a>1.3.1 构架部署</h4><p>Standalone为spark自带资源管理系统（即经典的Master/Slaves架构模式）。该模式下集群由Master和Worker节点组成，程序通过与Master节点交互申请资源，Worker节点启动Executor运行。具体数据流图如下：</p>
<p><img src="\images\picture\python-on-yarn\spark.bmp" alt=""></p>
<p>另外考虑到Master节点存在单点故障。Spark支持使用Zookeeper实现HA高可用（high avalible）。Zookeeper提供一种领导选举的机制，通过该机制可以保证集群中只有一个Master节点处于RecoveryState.Active状态，其他Master节点处于RecoveryState.Standby状态。</p>
<p><img src="\images\picture\python-on-yarn\zk-spark.bmp" alt=""></p>
<h4 id="1-3-2-作业运行模式"><a href="#1-3-2-作业运行模式" class="headerlink" title="1.3.2 作业运行模式"></a>1.3.2 作业运行模式</h4><p>在该模式下，用户提交任务有两种方式：Standalone-client和Standalone-cluster。</p>
<h4 id="1-5-1-Client模式"><a href="#1-5-1-Client模式" class="headerlink" title="1.5.1 Client模式"></a>1.5.1 Client模式</h4><p>执行流程：</p>
<p>(1)客户端启动Driver进程。</p>
<p>(2)Driver向Master申请启动Application启动需要的资源。</p>
<p>(3)资源申请成功后，Driver将task发送到相应的Worker节点执行，并负责监控task运行情况。</p>
<p>(4)Worker将task执行结果返回到客户端的Driver进程。</p>
<blockquote>
<p>Client模式适用于调试程序。Driver进程在客户端侧启动，如果生产采用这种模式，当业务量较大时，客户端需要启动大量Driver进程，会消耗大量系统资源，导致资源枯竭。</p>
</blockquote>
<h4 id="1-5-2-Cluster模式"><a href="#1-5-2-Cluster模式" class="headerlink" title="1.5.2 Cluster模式"></a>1.5.2 Cluster模式</h4><p>执行流程：</p>
<p>(1)客户端会想Master节点申请启动Driver。</p>
<p>(2)Master受理客户端的请求，分配一个Work节点，启动Driver进程。</p>
<p>(3)Driver启动后，重新想Master节点申请运行资源，Master分配资源，并在相应的Worker节点上启动Executor进程。</p>
<p>(4)Driver发送task到相应的Worker节点运行，并负责监控task。</p>
<p>(5)Worker将task执行结果返回到Driver进程。</p>
<blockquote>
<p>Driver运行有Master在集群Worker节点上随机分配，相当于在集群上负载资源。</p>
</blockquote>
<p>两种方式最大的区别就是Driver进程运行的位置。Cluster模式相对于Client模式更适合于生成环境的部署。</p>
<h3 id="1-4-Spark-on-Yarn（集群模式）"><a href="#1-4-Spark-on-Yarn（集群模式）" class="headerlink" title="1.4 Spark on Yarn（集群模式）"></a>1.4 Spark on Yarn（集群模式）</h3><p>目前大部分企业级Spark都是跑在已有的Hadoop集群（hadoop 2.0系统）中，均使用Yarn来作为Spark的Cluster Manager，为Spark提供资源管理服务，Spark自身完成任务调度和计算。这部分内容会在后文中细致介绍。</p>
<h3 id="1-5-Spark-on-Mesos（集群模式）"><a href="#1-5-Spark-on-Mesos（集群模式）" class="headerlink" title="1.5 Spark on Mesos（集群模式）"></a>1.5 Spark on Mesos（集群模式）</h3><p>参考官方文档介绍：<a href="https://spark.apache.org/docs/latest/running-on-mesos.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-mesos.html</a></p>
<h2 id="第二部分-Spark-on-Yarn"><a href="#第二部分-Spark-on-Yarn" class="headerlink" title="第二部分 Spark on Yarn"></a>第二部分 Spark on Yarn</h2><p>我们知道MapReduce任务是运行在Yarn上的，同样Spark Application也可以运行在Yarn上。这种模式下，资源的管理、协调、执行和监控交给Yarn集群完成。</p>
<blockquote>
<p>Yarn集群上可以运行：MapReduce任务、Spark Application、Hbase集群、Storm集群、Flink集群等等，还有我们后续重点介绍的Python on Yarn。</p>
</blockquote>
<p>从节点功能上看，Yarn也采用类似Standalone模式的Master/Slave结构。资源框架中RM（ResourceManager）对应Master，NM（NodeManager）对应Slave。RM负责各个NM资源的统一管理和调度，NM节点负责启动和执行任务以及各任务间的资源隔离。</p>
<p>当集群中存在多种计算框架时，架构上选用Yarn统一管理资源要比Standalone更合适。类似Standalone模式，Spark on Yarn也有两种运行方式：Yarn-Client模式和Yarn-Cluster模式。从适用场景上看，Yarn-Cluster模式适用于生产环境，而Yarn-Client模式更适用于开发（交互式调试）。</p>
<h3 id="2-1-Client模式"><a href="#2-1-Client模式" class="headerlink" title="2.1 Client模式"></a>2.1 Client模式</h3><p>在Yarn-client模式下，Driver运行在本地Client上，通过AM（ApplicationMaster）向RM申请资源。本地Driver负责与所有的executor container进行交互，并将最后的结果汇总。结束掉Client，相当于kill掉这个spark应用。</p>
<p><img src="\images\picture\python-on-yarn\yarn-client-mode.png" alt=""></p>
<ul>
<li>Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend。</li>
<li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派。</li>
<li>Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）。</li>
<li>一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task。</li>
<li>client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。</li>
<li>应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。</li>
</ul>
<h3 id="2-2-Cluster模式"><a href="#2-2-Cluster模式" class="headerlink" title="2.2 Cluster模式"></a>2.2 Cluster模式</h3><p>在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：</p>
<ol>
<li>第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动。</li>
<li>第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。</li>
</ol>
<p>应用的运行结果不能在客户端显示（可以在history server中查看），所以最好将结果保存在HDFS而非stdout输出，客户端的终端显示的是作为YARN的job的简单运行状况，下图是yarn-cluster模式：</p>
<p><img src="\images\picture\python-on-yarn\yarn-cluster-mode.png" alt=""></p>
<p>执行过程： </p>
<ul>
<li>Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等。</li>
<li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster进行SparkContext等的初始化。</li>
<li>ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束。</li>
<li>一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，而Executor对象的创建及维护是由。CoarseGrainedExecutorBackend负责的，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等。</li>
<li>ApplicationMaster中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。</li>
<li>应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己。</li>
</ul>
<h3 id="2-3-两种模式的比较"><a href="#2-3-两种模式的比较" class="headerlink" title="2.3 两种模式的比较"></a>2.3 两种模式的比较</h3><p>在client模式下，Spark Application运行的Driver会在提交程序的节点上，而该节点可以是YARN集群内部节点，也可以不是。一般来说提交Spark Application的客户端节点不是YARN集群内部的节点，那么在客户端节点上可以根据自己的需要安装各种需要的软件和环境，以支撑Spark Application正常运行。在cluster模式下，Spark Application运行时的所有进程都在YARN集群的NodeManager节点上，而且具体在哪些NodeManager上运行是由YARN的调度策略所决定的。</p>
<p>对比这两种模式，最关键的是Spark Application运行时Driver所在的节点不同，而且，如果想要对Driver所在节点的运行环境进行配置，区别很大，但这对于PySpark Application运行来说是非常关键的。</p>
<h2 id="第三部分-Pyspark-Application原理"><a href="#第三部分-Pyspark-Application原理" class="headerlink" title="第三部分 Pyspark Application原理"></a>第三部分 Pyspark Application原理</h2><p>PySpark是Spark为使用Python程序编写Spark Application而实现的客户端库，通过PySpark也可以编写Spark Application并在Spark集群上运行。Python具有非常丰富的科学计算、机器学习处理库，如numpy、pandas、scipy等等。为了能够充分利用这些高效的Python模块，很多机器学习程序都会使用Python实现，同时也希望能够在Spark集群上运行。</p>
<p>理解PySpark Application的运行原理，有助于我们使用Python编写Spark Application，并能够对PySpark Application进行各种调优。PySpark构建于Spark的Java API之上，数据在Python脚本里面进行处理，而在JVM中缓存和Shuffle数据，数据处理流程如下图所示:</p>
<p><img src="http://www.uml.org.cn/bigdata/images/2017111321.png" alt="img"></p>
<p>Spark Application会在Driver中创建pyspark.SparkContext对象，后续通过pyspark.SparkContext对象来构建Job DAG并提交DAG运行。使用Python编写PySpark Application，在Python编写的Driver中也有一个pyspark.SparkContext对象，该pyspark.SparkContext对象会通过Py4J模块启动一个JVM实例，创建一个JavaSparkContext对象。PY4J只用在Driver上，后续在Python程序与JavaSparkContext对象之间的通信，都会通过PY4J模块来实现，而且都是本地通信。</p>
<p>PySpark Application中也有RDD，对Python RDD的Transformation操作，都会被映射到Java中的PythonRDD对象上。对于远程节点上的Python RDD操作，Java PythonRDD对象会创建一个Python子进程，并基于Pipe的方式与该Python子进程通信，将用户编写Python处理代码和数据发送到Python子进程中进行处理。</p>
<h2 id="第四部分-Python-on-Yarn配置及运行"><a href="#第四部分-Python-on-Yarn配置及运行" class="headerlink" title="第四部分 Python on Yarn配置及运行"></a>第四部分 Python on Yarn配置及运行</h2><h3 id="4-1-Yarn节点配置Python环境"><a href="#4-1-Yarn节点配置Python环境" class="headerlink" title="4.1 Yarn节点配置Python环境"></a>4.1 Yarn节点配置Python环境</h3><p>该模式需要在Yarn集群上每个NM节点（Node Manager）上部署Python编译环境，即安装Python安装包、依赖模块。用户编写的Pyspark Application由集群中Yarn调度执行。</p>
<blockquote>
<p>通常使用Anaconda安装包进行统一部署，简化环境的部署。</p>
</blockquote>
<p>该模式存在下面缺点：</p>
<ul>
<li>新增依赖包部署安装代价大。如果后续用户编写的Spark Application需要依赖新的Python模块或包，那么就需要依次在集群Node Manager上部署更新依赖包。</li>
<li>用户对于Python环境的依赖差异化无法满足。通常不同用户编写Spark Application会依赖不同的Python环境，比如Python2、Python3环境等等。该模式下只能支持一种环境，无法满足Python多环境的需求。</li>
<li>各节点的Python环境需要统一。由于用户提交的Spark Application具体在哪些Node Manager上执行，由YARN调度决定，所以必须保证每个节点的Python环境（基础环境+依赖环境）都是相同的，环境维护成本高。</li>
</ul>
<h3 id="4-2-Yarn节点不配置Python环境"><a href="#4-2-Yarn节点不配置Python环境" class="headerlink" title="4.2 Yarn节点不配置Python环境"></a>4.2 Yarn节点不配置Python环境</h3><p>该模式不需要提前在集群Node Manager上预安装Python环境。</p>
<blockquote>
<p>参考文章：<a href="http://quasiben.github.io/blog/2016/4/15/conda-spark/" target="_blank" rel="noopener">http://quasiben.github.io/blog/2016/4/15/conda-spark/</a></p>
</blockquote>
<p>我们基于华为C60集群（开源集群相同）以及Anaconda环境对该模式进行了测试验证。具体实现思路如下所示：</p>
<ol>
<li>在一台SUSE节点上部署Anaconda，并创建虚拟Python环境（如果需要可以部署安装部分依赖包）。</li>
<li>创建conda虚拟环境，并整体打包为zip文件。</li>
<li>用户提交PySpark Application时，使用<code>--archives</code>参数指定该zip文件路径。</li>
</ol>
<p>详细操作步骤如下：</p>
<ul>
<li><strong>第一步</strong></li>
</ul>
<p>下载Anaconda3-4.2.0-Linux-x86_64.sh安装软件（基于python3.5），在SUSE服务器上部署安装。Anaconda的安装路径为/usr/anaconda3。查看客户端服务器的python环境清单：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/usr/anaconda3 # conda env list</span><br><span class="line"><span class="meta">#</span><span class="bash"> conda environments:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line">root                  *  /usr/anaconda3</span><br></pre></td></tr></table></figure>
<p>其中root环境为目前的主环境。为了便于环境版本管理我们新建一个专用环境（mlpy_env）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/usr/anaconda3/envs # conda create -n mlpy --clone root</span><br></pre></td></tr></table></figure>
<p>上述命令创建了一个名称为mlpy_env的Python环境，clone选项将对应的软件包都安装到该环境中，包括一些C的动态链接库文件。</p>
<p>接着，将该Python环境打包，执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/usr/anaconda3/envs # cd /root/anaconda2/envs</span><br><span class="line">dkfzxwma07app08:/usr/anaconda3/envs # zip -r mlpy_env.zip mlpy_env</span><br></pre></td></tr></table></figure>
<p>将该zip压缩包拷贝到指定目录中（或者后续引用使用绝对路径），方便后续提交PySpark Application：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/usr/anaconda3/envs # cp mlpy_env.zip /tmp/</span><br></pre></td></tr></table></figure>
<p>最后，我们可以提交我们的PySpark Application，执行如下命令（或打包成shell脚本）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PYSPARK_PYTHON=./ANACONDA/mlpy_env/bin/python </span><br><span class="line">spark-submit \</span><br><span class="line">--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./ANACONDA/mlpy_env/bin/python \</span><br><span class="line">--master yarn-cluster \</span><br><span class="line">--archives /tmp/mlpy_env.zip#ANACONDA \</span><br><span class="line">/var/lib/hadoop-hdfs/pyspark/test_pyspark_dependencies.py</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：下面命令指的是zip包将在ANACONDA的目录中展开，需要注意路径。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> --archives /tmp/mlpy_env.zip<span class="comment">#ANACONDA</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>环境打包需要注意压缩路径。</p>
</blockquote>
<p>上面的依赖zip压缩包将整个Python的运行环境都包含在里面，在提交PySpark Application时会将该环境zip包上传到运行Application的所在的每个节点上。解压缩后为Python代码提供运行时环境。如果不想每次都从客户端将该环境文件上传到集群中运行节点上，也可以提前将zip包上传到HDFS文件系统中，并修改–archives参数的值为hdfs:///tmp/mlpy_env.zip #ANACONDA（注意环境差异），也是可以的。</p>
<p>另外，需要说明的是，如果我们开发的/var/lib/hadoop-hdfs/pyspark /test_pyspark_dependencies.py文件中，依赖多个其他Python文件，想要通过上面的方式运行，必须将这些依赖的Python文件拷贝到我们创建的环境中，对应的目录为mlpy_env/lib/python2.7/site-packages/下面。</p>
<blockquote>
<p>注意：pyspark不支持python3.6版本，所以python环境使用python3.5</p>
<p>否则程序执行回显会有这样的报错信息：</p>
<p>TypeError: namedtuple() missing 3 required keyword-only arguments: ‘verbose’, ‘rename’, and ‘module’</p>
<p><a href="https://issues.apache.org/jira/browse/SPARK-19019?page=com.atlassian.jira.plugin.system.issuetabpanels%3Aall-tabpanel" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/SPARK-19019?page=com.atlassian.jira.plugin.system.issuetabpanels%3Aall-tabpanel</a></p>
</blockquote>
<h3 id="4-3-一个机器学习任务栗子"><a href="#4-3-一个机器学习任务栗子" class="headerlink" title="4.3 一个机器学习任务栗子"></a>4.3 一个机器学习任务栗子</h3><p>举一个Kmeans无监督算法的Python案例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.clustering <span class="keyword">import</span> KMeans, KMeansModel</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建spark context</span></span><br><span class="line">sc = SparkContext(appName=<span class="string">"kmeans"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载和解析数据文件</span></span><br><span class="line">stg_path = <span class="string">"hdfs://hacluster"</span> + <span class="string">"/user/"</span> + str(os.environ[<span class="string">'USER'</span>]) + <span class="string">"/.sparkStaging/"</span> + str(sc.applicationId) + <span class="string">"/"</span> </span><br><span class="line">data = sc.textFile(os.path.join(stg_path,<span class="string">'kmeans_data.txt'</span>)) </span><br><span class="line">parsedData = data.map(<span class="keyword">lambda</span> line: array([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line.split(<span class="string">' '</span>)]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">clusters = KMeans.train(parsedData, <span class="number">2</span>, maxIterations=<span class="number">10</span>,runs=<span class="number">10</span>,initializationMode=<span class="string">"random"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">error</span><span class="params">(point)</span>:</span></span><br><span class="line">    i = clusters.predict(point)</span><br><span class="line">    center = clusters.centers[i]</span><br><span class="line">    print(<span class="string">"("</span> + str(point[<span class="number">0</span>]) + <span class="string">","</span> + str(point[<span class="number">1</span>]) + <span class="string">","</span> + str(point[<span class="number">2</span>]) + <span class="string">")"</span> + <span class="string">"blongs to cluster "</span> + str(i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># print("Cluster Number:" + str(len(clusters.centers)))</span></span><br><span class="line">    <span class="keyword">return</span> sqrt(sum([x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> (point - center)]))</span><br><span class="line"></span><br><span class="line">WSSSE = parsedData.map(<span class="keyword">lambda</span> point: error(point)).reduce(<span class="keyword">lambda</span> x, y: x + y)</span><br><span class="line">print(<span class="string">"Within Set Sum of Squared Error = "</span> + str(WSSSE))</span><br><span class="line"><span class="comment"># 打印类心</span></span><br><span class="line"><span class="keyword">for</span> mCenter <span class="keyword">in</span> clusters.centers:</span><br><span class="line">    print(mCenter)</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">myModelPath = <span class="string">"hdfs://hacluster"</span>+<span class="string">"/user/model/"</span>+<span class="string">"KMeansModel.ml"</span></span><br><span class="line">clusters.save(sc, myModelPath)</span><br><span class="line"><span class="comment"># 加载模型并测试</span></span><br><span class="line">loadModel = KMeansModel.load(sc, myModelPath)</span><br><span class="line">print(loadModel.predict(array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])))</span><br></pre></td></tr></table></figure>
<p>整理成下面的提交命令，将作业提交到Yarn集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/tmp/pyspark # cat run.sh</span><br><span class="line">PYSPARK_PYTHON=./ANACONDA/mlpy_env/bin/python \</span><br><span class="line">/approot1/utility/hadoopclient/Spark/spark/bin/spark-submit \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--archives /tmp/pyspark/mlpy_env.zip#ANACONDA \</span><br><span class="line">--files /tmp/pyspark/kmeans_data.txt \</span><br><span class="line">--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./ANACONDA/mlpy_env/bin/python \</span><br><span class="line">/tmp/pyspark/kmeanTest.py</span><br></pre></td></tr></table></figure>
<p>模型训练结果会写到路径下面：/user/model：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/tmp/pyspark/pythonpkg # hdfs dfs -ls /user/model</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x+  - itdw hadoop          0 2019-07-30 11:30 /user/model/KMeansModel.ml</span><br></pre></td></tr></table></figure>
<p>模型加载的预测结果可以在Yarn日志中查询：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dkfzxwma07app08:/tmp/pyspark # yarn logs -applicationId application_1562162322775_150207</span><br><span class="line"><span class="meta">#</span><span class="bash"> 提取部分回显</span></span><br><span class="line">LogType:stdout</span><br><span class="line">Log Upload Time:星期二 七月 30 13:47:23 +0800 2019</span><br><span class="line">LogLength:120414</span><br><span class="line">Log Contents:</span><br><span class="line">Within Set Sum of Squared Error = 0.6928203230275529</span><br><span class="line">[ 9.1  9.1  9.1]</span><br><span class="line">[ 0.1  0.1  0.1]</span><br><span class="line">1</span><br></pre></td></tr></table></figure>
<p>当然对于输出可以选择其他输出源(表或者文件)。</p>
<h2 id="第五部分-总结"><a href="#第五部分-总结" class="headerlink" title="第五部分 总结"></a>第五部分 总结</h2><h3 id="5-1-混合多语言数据流"><a href="#5-1-混合多语言数据流" class="headerlink" title="5.1 混合多语言数据流"></a>5.1 混合多语言数据流</h3><p>通常一个完整的机器学习应用的数据流设计中，可以将数据ETL准备阶段和算法计算分离出来。使用Java/scala/sql进行数据的预处理，输出算法计算要求的数据格式。这会极大降低算法计算的数据输入规模，降低算法计算的节点的IO。</p>
<p>机器学习的算法计算部分具有高迭代计算特性，对于非分布式的机器学习算法，我们通常部署在高性能的节点上，基于丰富、高性能的Python科学计算模块，使用Python语言实现。而对于数据准备阶段，更适合使用原生的Scala/java编程语言实现Spark Application来处理数据，包括转换、统计、压缩等等，将满足算法输入格式的数据输出到HDFS文件系统中。特别对于数据规模较大的情况，在Spark集群上处理数据，Scala/Java实现的Spark Application运行（多机并行分布式处理）性能要好一些。然后输出数据交给Python进行迭代计算训练。</p>
<p>当然对于分布式机器学习框架，将数据迭代部分分解到多个节点并行处理，由参数服务器管理迭代参数的汇总和更新。在这种计算框架下可以利用数据集群天然的计算资源，实现分布式部署。这就形成了一个高效的混合的多语言的数据处理流。</p>
<h3 id="5-2-架构建议和总结"><a href="#5-2-架构建议和总结" class="headerlink" title="5.2 架构建议和总结"></a>5.2 架构建议和总结</h3><p>1、对于Python on Yarn架构下，采用“Yarn节点不配置Python环境”模式，便于Python环境的管理。这时候可以将Python环境zip文件上传至集群HDFS文件系统，避免每次提交任务都需要上传zip文件，但是不可避免集群内部HDFS文件系统分发到运行节点产生的网络IO。但比集群外部的上传效率高。</p>
<p>2、对于机器学习任务数据流建议采用混合多语言数据流方式，发挥各计算组件的优势。</p>
<p>3、对于分布式机器学习框架，建议结合集群的计算资源，直接在集群上展开分布式计算（例如Tensorflow计算框架）。而不是单独新建新的机器学习分布式集群。减少两个集群的数据搬运，并且使得数据和计算更加贴近，最重要的提高机器学习任务端到端的效率。</p>
<h2 id="参考文献及资料"><a href="#参考文献及资料" class="headerlink" title="参考文献及资料"></a>参考文献及资料</h2><p>1、Running Spark Python Applications，链接：<a href="https://www.cloudera.com/documentation/enterprise/5-9-x/topics/spark_python.html" target="_blank" rel="noopener">https://www.cloudera.com/documentation/enterprise/5-9-x/topics/spark_python.html</a></p>
<p>2、基于YARN集群构建运行PySpark Application，链接： <a href="http://shiyanjun.cn/archives/1738.html" target="_blank" rel="noopener">http://shiyanjun.cn/archives/1738.html</a></p>
<p>3、Running Spark on YARN，链接： <a href="https://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-yarn.html</a></p>
<p>4、Running Spark on Kubernetes，链接：<a href="https://spark.apache.org/docs/latest/running-on-kubernetes.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></p>
<p>5、Apache Spark Resource Management and YARN App Models，链接：<a href="https://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/" target="_blank" rel="noopener">https://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/</a></p>
<p>6、Spark On Yarn的两种模式yarn-cluster和yarn-client深度剖析，链接：<a href="https://www.cnblogs.com/ITtangtang/p/7967386.html" target="_blank" rel="noopener">https://www.cnblogs.com/ITtangtang/p/7967386.html</a></p>
<p>7、Introducing Skein: Deploy Python on Apache YARN the Easy Way，链接：<a href="https://jcrist.github.io/introducing-skein.html" target="_blank" rel="noopener">https://jcrist.github.io/introducing-skein.html</a></p>
<p>8、当Spark遇上TensorFlow分布式深度学习框架原理和实践，链接：<a href="https://juejin.im/post/5ad4b620f265da23a04a0ad0" target="_blank" rel="noopener">https://juejin.im/post/5ad4b620f265da23a04a0ad0</a></p>
<p>9、Spark On Yarn的优势，链接：<a href="https://www.cnblogs.com/ITtangtang/p/7967386.html" target="_blank" rel="noopener">https://www.cnblogs.com/ITtangtang/p/7967386.html</a></p>
<p>10、基于YARN集群构建运行PySpark Application，链接：<a href="http://www.uml.org.cn/bigdata/201711132.asp" target="_blank" rel="noopener">http://www.uml.org.cn/bigdata/201711132.asp</a></p>

      
    </div>

    

    <div>
      
        
<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">
  <p><span>本文标题:</span><a href="/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/">从Spark on Yarn到Python on Yarn</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 rong xiang 的个人博客">rong xiang</a></p>
  <p><span>发布时间:</span>2019年08月01日 - 19:08</p>
  <p><span>最后更新:</span>2020年03月22日 - 11:03</p>
  <p><span>原始链接:</span><a href="/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/" title="从Spark on Yarn到Python on Yarn">https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({   
          title: "",   
          text: '复制成功',   
          html: false,
          timer: 500,   
          showConfirmButton: false
        });
      });
    }));  
</script>

      
    </div>
    
    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/07/01/2019-07-01-TDengine时间序列数据库压力测试/" rel="next" title="TDengine时间序列数据库压力测试">
                <i class="fa fa-chevron-left"></i> TDengine时间序列数据库压力测试
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/08/08/2019-08-08-Helm简介和安装部署/" rel="prev" title="Helm简介和安装部署">
                Helm简介和安装部署 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar/person.png" alt="rong xiang">
            
              <p class="site-author-name" itemprop="name">rong xiang</p>
              <p class="site-description motion-element" itemprop="description">Keep a Pure Curiosity</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">33</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/zjrongxiang" title="GitHub &rarr; https://github.com/zjrongxiang" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:rongxiang1986@163.com" title="E-Mail &rarr; mailto:rongxiang1986@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="http://weibo.com/u/1971060643" title="Weibo &rarr; http://weibo.com/u/1971060643" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Link
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://weibo.com/fly51fly?refer_flag=1005055010_" title="https://weibo.com/fly51fly?refer_flag=1005055010_" rel="noopener" target="_blank">爱生活爱可可</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#目录"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">2.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第一部分-Apache-Spark运行模式"><span class="nav-number">3.</span> <span class="nav-text">第一部分 Apache Spark运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-本地模式（单节点模式）"><span class="nav-number">3.1.</span> <span class="nav-text">1.1 本地模式（单节点模式）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-本地伪集群模式（单节点模式）"><span class="nav-number">3.2.</span> <span class="nav-text">1.2 本地伪集群模式（单节点模式）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-Standalone模式（集群模式）"><span class="nav-number">3.3.</span> <span class="nav-text">1.3 Standalone模式（集群模式）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-1-构架部署"><span class="nav-number">3.3.1.</span> <span class="nav-text">1.3.1 构架部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-2-作业运行模式"><span class="nav-number">3.3.2.</span> <span class="nav-text">1.3.2 作业运行模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-1-Client模式"><span class="nav-number">3.3.3.</span> <span class="nav-text">1.5.1 Client模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-5-2-Cluster模式"><span class="nav-number">3.3.4.</span> <span class="nav-text">1.5.2 Cluster模式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-Spark-on-Yarn（集群模式）"><span class="nav-number">3.4.</span> <span class="nav-text">1.4 Spark on Yarn（集群模式）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-Spark-on-Mesos（集群模式）"><span class="nav-number">3.5.</span> <span class="nav-text">1.5 Spark on Mesos（集群模式）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二部分-Spark-on-Yarn"><span class="nav-number">4.</span> <span class="nav-text">第二部分 Spark on Yarn</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Client模式"><span class="nav-number">4.1.</span> <span class="nav-text">2.1 Client模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Cluster模式"><span class="nav-number">4.2.</span> <span class="nav-text">2.2 Cluster模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-两种模式的比较"><span class="nav-number">4.3.</span> <span class="nav-text">2.3 两种模式的比较</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三部分-Pyspark-Application原理"><span class="nav-number">5.</span> <span class="nav-text">第三部分 Pyspark Application原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第四部分-Python-on-Yarn配置及运行"><span class="nav-number">6.</span> <span class="nav-text">第四部分 Python on Yarn配置及运行</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Yarn节点配置Python环境"><span class="nav-number">6.1.</span> <span class="nav-text">4.1 Yarn节点配置Python环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Yarn节点不配置Python环境"><span class="nav-number">6.2.</span> <span class="nav-text">4.2 Yarn节点不配置Python环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-一个机器学习任务栗子"><span class="nav-number">6.3.</span> <span class="nav-text">4.3 一个机器学习任务栗子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第五部分-总结"><span class="nav-number">7.</span> <span class="nav-text">第五部分 总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-混合多语言数据流"><span class="nav-number">7.1.</span> <span class="nav-text">5.1 混合多语言数据流</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-架构建议和总结"><span class="nav-number">7.2.</span> <span class="nav-text">5.2 架构建议和总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献及资料"><span class="nav-number">8.</span> <span class="nav-text">参考文献及资料</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">rong xiang</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v6.7.0</div>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=6.7.0"></script>




  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  
  
    
  <script id="dsq-count-scr" src="https://https-zjrongxiang-github-io.disqus.com/count.js" async></script>


<script>
  var disqus_config = function () {
    this.page.url = "https://zjrongxiang.github.io/2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/";
    this.page.identifier = "2019/08/01/2019-01-28-从Spark on Yarn到Python on Yarn/";
    this.page.title = '从Spark on Yarn到Python on Yarn';
    };
  function loadComments () {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-zjrongxiang-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', '' + +new Date());
    (d.head || d.body).appendChild(s);
  }
  
    loadComments();
  
</script>

  





  

  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap');
      $(e).after($wrap);
      $wrap.append($('<button>').addClass('copy-btn').append('Copy').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text();
        }).toArray().join('\n');
        var ta = document.createElement('textarea');
        var range = document.createRange(); //For Chrome
        var sel = window.getSelection(); //For Chrome
        var yPosition = window.pageYOffset || document.documentElement.scrollTop;
        ta.style.top = yPosition + 'px'; //Prevent page scroll
        ta.style.position = 'absolute';
        ta.style.opacity = '0';
        ta.value = code;
        ta.textContent = code; //For FireFox
        ta.contentEditable = true;
        ta.readOnly = false;
        document.body.appendChild(ta);
        range.selectNode(ta);
        sel.removeAllRanges();
        sel.addRange(range);
        ta.setSelectionRange(0, code.length);
        var result = document.execCommand('copy');
        
          if (result) $(this).text('Copied');
          else $(this).text('Copy failed');
        
        ta.blur(); //For iOS
        $(this).blur();
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn');
        setTimeout(function () {
          $b.text('Copy');
        }, 300);
      }).append(e);
    })
  </script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  
  

  
  

  


</body>
</html>
